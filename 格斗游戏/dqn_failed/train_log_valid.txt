Tensor(shape=[1], dtype=Float32, value=[ 1.33333344e-03])
train_episode: 0
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 207. you lose.
Episode 0: loss is 0.642, rewards is -10.19
Tensor(shape=[1], dtype=Float32, value=[ 2.66666687e-03])
train_episode: 1
can't receive signals within 60 seconds. let's terminate gym env.
Episode 1: loss is 0.522, rewards is 6.26
Tensor(shape=[1], dtype=Float32, value=[ 4.00000019e-03])
train_episode: 2
At the end, own_hp 210: opp_hp 143. you win.
Episode 2: loss is 0.212, rewards is 6.72
Tensor(shape=[1], dtype=Float32, value=[ 5.33333374e-03])
train_episode: 3
At the end, own_hp 220: opp_hp 368. you lose.
Episode 3: loss is 0.015, rewards is -14.92
Tensor(shape=[1], dtype=Float32, value=[ 6.66666683e-03])
train_episode: 4
At the end, own_hp 287: opp_hp 345. you lose.
Episode 4: loss is 0.471, rewards is -6.0
Tensor(shape=[1], dtype=Float32, value=[ 8.00000038e-03])
train_episode: 5
At the end, own_hp 243: opp_hp 335. you lose.
Episode 5: loss is 0.261, rewards is -9.84
Tensor(shape=[1], dtype=Float32, value=[ 9.33333393e-03])
train_episode: 6
At the end, own_hp 250: opp_hp 352. you lose.
Episode 6: loss is 0.052, rewards is -10.23
Tensor(shape=[1], dtype=Float32, value=[ 1.06666675e-02])
train_episode: 7
can't receive signals within 60 seconds. let's terminate gym env.
Episode 7: loss is 0.333, rewards is -0.02
Tensor(shape=[1], dtype=Float32, value=[ 1.20000001e-02])
train_episode: 8
can't receive signals within 60 seconds. let's terminate gym env.
Episode 8: loss is 0.04, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 1.33333337e-02])
train_episode: 9
At the end, own_hp 338: opp_hp 325. you win.
Episode 9: loss is 0.008, rewards is 1.33
Tensor(shape=[1], dtype=Float32, value=[ 1.46666672e-02])
train_episode: 10
At the end, own_hp 108: opp_hp 282. you lose.
Episode 10: loss is 0.008, rewards is -17.52
0
1
2
evaluate begin
At the end, own_hp 328: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 297: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 10 total rewards is -12.463
Tensor(shape=[1], dtype=Float32, value=[ 1.60000008e-02])
-----------------------------------------
train_episode: 11
At the end, own_hp 165: opp_hp 164. you win.
Episode 11: loss is 0.197, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 1.73333343e-02])
train_episode: 12
At the end, own_hp 0: opp_hp 375. you lose.
Episode 12: loss is 0.298, rewards is -34.24
Tensor(shape=[1], dtype=Float32, value=[ 1.86666679e-02])
train_episode: 13
At the end, own_hp 145: opp_hp 320. you lose.
Episode 13: loss is 0.023, rewards is -17.73
Tensor(shape=[1], dtype=Float32, value=[ 1.99999996e-02])
train_episode: 14
At the end, own_hp 205: opp_hp 272. you lose.
Episode 14: loss is 0.236, rewards is -6.57
Tensor(shape=[1], dtype=Float32, value=[ 2.13333350e-02])
train_episode: 15
can't receive signals within 60 seconds. let's terminate gym env.
Episode 15: loss is 0.066, rewards is -0.96
Tensor(shape=[1], dtype=Float32, value=[ 2.26666685e-02])
train_episode: 16
At the end, own_hp 0: opp_hp 385. you lose.
Episode 16: loss is 0.092, rewards is -37.69
Tensor(shape=[1], dtype=Float32, value=[ 2.40000002e-02])
train_episode: 17
At the end, own_hp 225: opp_hp 273. you lose.
Episode 17: loss is 0.123, rewards is -0.96
Tensor(shape=[1], dtype=Float32, value=[ 2.53333338e-02])
train_episode: 18
At the end, own_hp 0: opp_hp 390. you lose.
Episode 18: loss is 0.071, rewards is -37.93
Tensor(shape=[1], dtype=Float32, value=[ 2.66666673e-02])
train_episode: 19
At the end, own_hp 0: opp_hp 375. you lose.
Episode 19: loss is 0.225, rewards is -36.48
Tensor(shape=[1], dtype=Float32, value=[ 2.80000009e-02])
train_episode: 20
can't receive signals within 60 seconds. let's terminate gym env.
Episode 20: loss is 0.132, rewards is 0.0
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 20 total rewards is -14.007
Tensor(shape=[1], dtype=Float32, value=[ 2.93333344e-02])
-----------------------------------------
train_episode: 21
At the end, own_hp 205: opp_hp 295. you lose.
Episode 21: loss is 0.226, rewards is -9.13
Tensor(shape=[1], dtype=Float32, value=[ 3.06666680e-02])
train_episode: 22
can't receive signals within 60 seconds. let's terminate gym env.
Episode 22: loss is 0.274, rewards is -11.2
Tensor(shape=[1], dtype=Float32, value=[ 3.20000015e-02])
train_episode: 23
At the end, own_hp 141: opp_hp 305. you lose.
Episode 23: loss is 0.0, rewards is -16.48
Tensor(shape=[1], dtype=Float32, value=[ 3.33333351e-02])
train_episode: 24
can't receive signals within 60 seconds. let's terminate gym env.
Episode 24: loss is 0.111, rewards is 1.48
Tensor(shape=[1], dtype=Float32, value=[ 3.46666686e-02])
train_episode: 25
can't receive signals within 60 seconds. let's terminate gym env.
Episode 25: loss is 0.123, rewards is -0.01
Tensor(shape=[1], dtype=Float32, value=[ 3.60000022e-02])
train_episode: 26
can't receive signals within 60 seconds. let's terminate gym env.
Episode 26: loss is 0.007, rewards is -0.46
Tensor(shape=[1], dtype=Float32, value=[ 3.73333357e-02])
train_episode: 27
At the end, own_hp 0: opp_hp 370. you lose.
Episode 27: loss is 0.071, rewards is -35.66
Tensor(shape=[1], dtype=Float32, value=[ 3.86666656e-02])
train_episode: 28
At the end, own_hp 0: opp_hp 395. you lose.
Episode 28: loss is 0.271, rewards is -34.75
Tensor(shape=[1], dtype=Float32, value=[ 3.99999991e-02])
train_episode: 29
At the end, own_hp 0: opp_hp 400. you lose.
Episode 29: loss is 0.091, rewards is -39.17
Tensor(shape=[1], dtype=Float32, value=[ 4.13333327e-02])
train_episode: 30
At the end, own_hp 225: opp_hp 235. you lose.
Episode 30: loss is 0.064, rewards is -1.43
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 275: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 30 total rewards is -14.787
Tensor(shape=[1], dtype=Float32, value=[ 4.26666699e-02])
-----------------------------------------
train_episode: 31
can't receive signals within 60 seconds. let's terminate gym env.
Episode 31: loss is 0.097, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 4.39999998e-02])
train_episode: 32
can't receive signals within 60 seconds. let's terminate gym env.
Episode 32: loss is 0.651, rewards is 0.13
Tensor(shape=[1], dtype=Float32, value=[ 4.53333370e-02])
train_episode: 33
At the end, own_hp 203: opp_hp 362. you lose.
Episode 33: loss is 0.202, rewards is -15.73
Tensor(shape=[1], dtype=Float32, value=[ 4.66666669e-02])
train_episode: 34
At the end, own_hp 230: opp_hp 261. you lose.
Episode 34: loss is 0.351, rewards is -3.97
Tensor(shape=[1], dtype=Float32, value=[ 4.80000004e-02])
train_episode: 35
At the end, own_hp 0: opp_hp 370. you lose.
Episode 35: loss is 0.008, rewards is -26.5
Tensor(shape=[1], dtype=Float32, value=[ 4.93333340e-02])
train_episode: 36
can't receive signals within 60 seconds. let's terminate gym env.
Episode 36: loss is 0.008, rewards is -24.36
Tensor(shape=[1], dtype=Float32, value=[ 5.06666675e-02])
train_episode: 37
can't receive signals within 60 seconds. let's terminate gym env.
Episode 37: loss is 0.101, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 5.20000011e-02])
train_episode: 38
At the end, own_hp 165: opp_hp 273. you lose.
Episode 38: loss is 0.302, rewards is -10.83
Tensor(shape=[1], dtype=Float32, value=[ 5.33333346e-02])
train_episode: 39
can't receive signals within 60 seconds. let's terminate gym env.
Episode 39: loss is 0.102, rewards is -0.1
Tensor(shape=[1], dtype=Float32, value=[ 5.46666682e-02])
train_episode: 40
can't receive signals within 60 seconds. let's terminate gym env.
Episode 40: loss is 0.031, rewards is 0.01
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 40 total rewards is -13.707
Tensor(shape=[1], dtype=Float32, value=[ 5.60000017e-02])
-----------------------------------------
train_episode: 41
can't receive signals within 60 seconds. let's terminate gym env.
Episode 41: loss is 0.044, rewards is 0.01
Tensor(shape=[1], dtype=Float32, value=[ 5.73333353e-02])
train_episode: 42
At the end, own_hp 173: opp_hp 223. you lose.
Episode 42: loss is 0.325, rewards is -2.45
Tensor(shape=[1], dtype=Float32, value=[ 5.86666688e-02])
train_episode: 43
At the end, own_hp 180: opp_hp 287. you lose.
Episode 43: loss is 0.101, rewards is -10.95
Tensor(shape=[1], dtype=Float32, value=[ 6.00000024e-02])
train_episode: 44
At the end, own_hp 140: opp_hp 265. you lose.
Episode 44: loss is 0.0, rewards is -12.53
Tensor(shape=[1], dtype=Float32, value=[ 6.13333359e-02])
train_episode: 45
can't receive signals within 60 seconds. let's terminate gym env.
Episode 45: loss is 0.008, rewards is -13.26
Tensor(shape=[1], dtype=Float32, value=[ 6.26666695e-02])
train_episode: 46
At the end, own_hp 0: opp_hp 388. you lose.
Episode 46: loss is 0.21, rewards is -28.53
Tensor(shape=[1], dtype=Float32, value=[ 6.40000030e-02])
train_episode: 47
At the end, own_hp 0: opp_hp 395. you lose.
Episode 47: loss is 0.416, rewards is -38.25
Tensor(shape=[1], dtype=Float32, value=[ 6.53333366e-02])
train_episode: 48
can't receive signals within 60 seconds. let's terminate gym env.
Episode 48: loss is 0.085, rewards is -5.72
Tensor(shape=[1], dtype=Float32, value=[ 6.66666701e-02])
train_episode: 49
At the end, own_hp 188: opp_hp 290. you lose.
Episode 49: loss is 0.015, rewards is -10.13
Tensor(shape=[1], dtype=Float32, value=[ 6.80000037e-02])
train_episode: 50
At the end, own_hp 0: opp_hp 345. you lose.
Episode 50: loss is 0.085, rewards is -32.92
0
1
2
evaluate begin
At the end, own_hp 270: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 50 total rewards is -7.390
Tensor(shape=[1], dtype=Float32, value=[ 6.93333372e-02])
-----------------------------------------
train_episode: 51
At the end, own_hp 187: opp_hp 302. you lose.
Episode 51: loss is 0.155, rewards is -11.84
Tensor(shape=[1], dtype=Float32, value=[ 7.06666708e-02])
train_episode: 52
At the end, own_hp 0: opp_hp 395. you lose.
Episode 52: loss is 0.04, rewards is -35.67
Tensor(shape=[1], dtype=Float32, value=[ 7.20000044e-02])
train_episode: 53
can't receive signals within 60 seconds. let's terminate gym env.
Episode 53: loss is 0.016, rewards is -0.02
Tensor(shape=[1], dtype=Float32, value=[ 7.33333379e-02])
train_episode: 54
At the end, own_hp 167: opp_hp 250. you lose.
Episode 54: loss is 0.09, rewards is -8.63
Tensor(shape=[1], dtype=Float32, value=[ 7.46666715e-02])
train_episode: 55
At the end, own_hp 0: opp_hp 385. you lose.
Episode 55: loss is 0.197, rewards is -38.37
Tensor(shape=[1], dtype=Float32, value=[ 7.60000050e-02])
train_episode: 56
At the end, own_hp 0: opp_hp 380. you lose.
Episode 56: loss is 0.331, rewards is -37.28
Tensor(shape=[1], dtype=Float32, value=[ 7.73333311e-02])
train_episode: 57
At the end, own_hp 225: opp_hp 347. you lose.
Episode 57: loss is 0.047, rewards is -12.41
Tensor(shape=[1], dtype=Float32, value=[ 7.86666721e-02])
train_episode: 58
At the end, own_hp 0: opp_hp 392. you lose.
Episode 58: loss is 0.214, rewards is -37.12
Tensor(shape=[1], dtype=Float32, value=[ 7.99999982e-02])
train_episode: 59
At the end, own_hp 251: opp_hp 342. you lose.
Episode 59: loss is 0.0, rewards is -8.13
Tensor(shape=[1], dtype=Float32, value=[ 8.13333392e-02])
train_episode: 60
At the end, own_hp 230: opp_hp 242. you lose.
Episode 60: loss is 0.086, rewards is -2.21
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 60 total rewards is -0.503
Tensor(shape=[1], dtype=Float32, value=[ 8.26666653e-02])
-----------------------------------------
train_episode: 61
At the end, own_hp 110: opp_hp 303. you lose.
Episode 61: loss is 0.247, rewards is -17.55
Tensor(shape=[1], dtype=Float32, value=[ 8.40000063e-02])
train_episode: 62
At the end, own_hp 157: opp_hp 207. you lose.
Episode 62: loss is 0.124, rewards is -3.16
Tensor(shape=[1], dtype=Float32, value=[ 8.53333399e-02])
train_episode: 63
can't receive signals within 60 seconds. let's terminate gym env.
Episode 63: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 8.66666660e-02])
train_episode: 64
can't receive signals within 60 seconds. let's terminate gym env.
Episode 64: loss is 0.42, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 8.79999995e-02])
train_episode: 65
can't receive signals within 60 seconds. let's terminate gym env.
Episode 65: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 8.93333405e-02])
train_episode: 66
At the end, own_hp 0: opp_hp 395. you lose.
Episode 66: loss is 0.135, rewards is -38.19
Tensor(shape=[1], dtype=Float32, value=[ 9.06666741e-02])
train_episode: 67
At the end, own_hp 240: opp_hp 343. you lose.
Episode 67: loss is 0.046, rewards is -10.58
Tensor(shape=[1], dtype=Float32, value=[ 9.20000002e-02])
train_episode: 68
At the end, own_hp 0: opp_hp 365. you lose.
Episode 68: loss is 0.079, rewards is -34.62
Tensor(shape=[1], dtype=Float32, value=[ 9.33333337e-02])
train_episode: 69
At the end, own_hp 170: opp_hp 353. you lose.
Episode 69: loss is 0.071, rewards is -18.33
Tensor(shape=[1], dtype=Float32, value=[ 9.46666747e-02])
train_episode: 70
At the end, own_hp 200: opp_hp 330. you lose.
Episode 70: loss is 0.06, rewards is -13.01
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 265: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 70 total rewards is -21.257
Tensor(shape=[1], dtype=Float32, value=[ 9.60000008e-02])
-----------------------------------------
train_episode: 71
At the end, own_hp 258: opp_hp 335. you lose.
Episode 71: loss is 0.084, rewards is -7.8
Tensor(shape=[1], dtype=Float32, value=[ 9.73333344e-02])
train_episode: 72
can't receive signals within 60 seconds. let's terminate gym env.
Episode 72: loss is 0.044, rewards is -5.85
Tensor(shape=[1], dtype=Float32, value=[ 9.86666679e-02])
train_episode: 73
can't receive signals within 60 seconds. let's terminate gym env.
Episode 73: loss is 0.008, rewards is -0.85
Tensor(shape=[1], dtype=Float32, value=[ 1.00000009e-01])
train_episode: 74
At the end, own_hp 0: opp_hp 400. you lose.
Episode 74: loss is 0.344, rewards is -37.86
Tensor(shape=[1], dtype=Float32, value=[ 1.01333335e-01])
train_episode: 75
At the end, own_hp 185: opp_hp 317. you lose.
Episode 75: loss is 0.0, rewards is -13.33
Tensor(shape=[1], dtype=Float32, value=[ 1.02666669e-01])
train_episode: 76
At the end, own_hp 130: opp_hp 245. you lose.
Episode 76: loss is 0.089, rewards is -10.94
Tensor(shape=[1], dtype=Float32, value=[ 1.04000002e-01])
train_episode: 77
At the end, own_hp 162: opp_hp 163. you lose.
Episode 77: loss is 0.317, rewards is -0.97
Tensor(shape=[1], dtype=Float32, value=[ 1.05333343e-01])
train_episode: 78
At the end, own_hp 230: opp_hp 360. you lose.
Episode 78: loss is 0.183, rewards is -12.97
Tensor(shape=[1], dtype=Float32, value=[ 1.06666669e-01])
train_episode: 79
can't receive signals within 60 seconds. let's terminate gym env.
Episode 79: loss is 0.366, rewards is -0.72
Tensor(shape=[1], dtype=Float32, value=[ 1.08000003e-01])
train_episode: 80
can't receive signals within 60 seconds. let's terminate gym env.
Episode 80: loss is 0.122, rewards is 0.02
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 258: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 80 total rewards is -25.297
Tensor(shape=[1], dtype=Float32, value=[ 1.09333336e-01])
-----------------------------------------
train_episode: 81
can't receive signals within 60 seconds. let's terminate gym env.
Episode 81: loss is 0.039, rewards is -3.03
Tensor(shape=[1], dtype=Float32, value=[ 1.10666662e-01])
train_episode: 82
At the end, own_hp 0: opp_hp 285. you lose.
Episode 82: loss is 0.046, rewards is -26.71
Tensor(shape=[1], dtype=Float32, value=[ 1.12000003e-01])
train_episode: 83
At the end, own_hp 132: opp_hp 315. you lose.
Episode 83: loss is 0.179, rewards is -17.48
Tensor(shape=[1], dtype=Float32, value=[ 1.13333337e-01])
train_episode: 84
At the end, own_hp 0: opp_hp 395. you lose.
Episode 84: loss is 0.064, rewards is -38.94
Tensor(shape=[1], dtype=Float32, value=[ 1.14666671e-01])
train_episode: 85
At the end, own_hp 168: opp_hp 225. you lose.
Episode 85: loss is 0.222, rewards is -5.97
Tensor(shape=[1], dtype=Float32, value=[ 1.15999997e-01])
train_episode: 86
At the end, own_hp 0: opp_hp 390. you lose.
Episode 86: loss is 0.053, rewards is -38.25
Tensor(shape=[1], dtype=Float32, value=[ 1.17333338e-01])
train_episode: 87
At the end, own_hp 155: opp_hp 298. you lose.
Episode 87: loss is 0.107, rewards is -14.72
Tensor(shape=[1], dtype=Float32, value=[ 1.18666671e-01])
train_episode: 88
At the end, own_hp 0: opp_hp 343. you lose.
Episode 88: loss is 0.045, rewards is -24.55
Tensor(shape=[1], dtype=Float32, value=[ 1.20000005e-01])
train_episode: 89
At the end, own_hp 0: opp_hp 345. you lose.
Episode 89: loss is 0.211, rewards is -26.74
Tensor(shape=[1], dtype=Float32, value=[ 1.21333331e-01])
train_episode: 90
At the end, own_hp 0: opp_hp 355. you lose.
Episode 90: loss is 0.008, rewards is -34.19
0
1
2
evaluate begin
At the end, own_hp 37: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 275: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 90 total rewards is -26.213
Tensor(shape=[1], dtype=Float32, value=[ 1.22666672e-01])
-----------------------------------------
train_episode: 91
At the end, own_hp 155: opp_hp 303. you lose.
Episode 91: loss is 0.085, rewards is -14.99
Tensor(shape=[1], dtype=Float32, value=[ 1.24000005e-01])
train_episode: 92
At the end, own_hp 0: opp_hp 385. you lose.
Episode 92: loss is 0.063, rewards is -38.37
Tensor(shape=[1], dtype=Float32, value=[ 1.25333339e-01])
train_episode: 93
At the end, own_hp 185: opp_hp 320. you lose.
Episode 93: loss is 0.102, rewards is -14.06
Tensor(shape=[1], dtype=Float32, value=[ 1.26666665e-01])
train_episode: 94
can't receive signals within 60 seconds. let's terminate gym env.
Episode 94: loss is 0.0, rewards is -0.5
Tensor(shape=[1], dtype=Float32, value=[ 1.28000006e-01])
train_episode: 95
At the end, own_hp 140: opp_hp 130. you win.
Episode 95: loss is 0.225, rewards is 1.23
Tensor(shape=[1], dtype=Float32, value=[ 1.29333347e-01])
train_episode: 96
At the end, own_hp 0: opp_hp 353. you lose.
Episode 96: loss is 0.232, rewards is -34.53
Tensor(shape=[1], dtype=Float32, value=[ 1.30666673e-01])
train_episode: 97
At the end, own_hp 155: opp_hp 188. you lose.
Episode 97: loss is 0.03, rewards is -3.96
Tensor(shape=[1], dtype=Float32, value=[ 1.31999999e-01])
train_episode: 98
At the end, own_hp 0: opp_hp 365. you lose.
Episode 98: loss is 0.218, rewards is -36.12
Tensor(shape=[1], dtype=Float32, value=[ 1.33333340e-01])
train_episode: 99
At the end, own_hp 0: opp_hp 375. you lose.
Episode 99: loss is 0.008, rewards is -36.34
Tensor(shape=[1], dtype=Float32, value=[ 1.34666681e-01])
train_episode: 100
At the end, own_hp 155: opp_hp 125. you win.
Episode 100: loss is 0.427, rewards is 2.51
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 282: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 100 total rewards is -2.900
Tensor(shape=[1], dtype=Float32, value=[ 1.36000007e-01])
-----------------------------------------
train_episode: 101
At the end, own_hp 0: opp_hp 395. you lose.
Episode 101: loss is 0.215, rewards is -39.17
Tensor(shape=[1], dtype=Float32, value=[ 1.37333333e-01])
train_episode: 102
can't receive signals within 60 seconds. let's terminate gym env.
Episode 102: loss is 0.02, rewards is 0.04
Tensor(shape=[1], dtype=Float32, value=[ 1.38666674e-01])
train_episode: 103
At the end, own_hp 180: opp_hp 325. you lose.
Episode 103: loss is 0.81, rewards is -16.84
Tensor(shape=[1], dtype=Float32, value=[ 1.40000001e-01])
train_episode: 104
can't receive signals within 60 seconds. let's terminate gym env.
Episode 104: loss is 0.207, rewards is -22.1
Tensor(shape=[1], dtype=Float32, value=[ 1.41333342e-01])
train_episode: 105
At the end, own_hp 205: opp_hp 322. you lose.
Episode 105: loss is 0.127, rewards is -11.89
Tensor(shape=[1], dtype=Float32, value=[ 1.42666668e-01])
train_episode: 106
At the end, own_hp 0: opp_hp 400. you lose.
Episode 106: loss is 0.186, rewards is -31.05
Tensor(shape=[1], dtype=Float32, value=[ 1.44000009e-01])
train_episode: 107
At the end, own_hp 257: opp_hp 260. you lose.
Episode 107: loss is 0.053, rewards is -0.95
Tensor(shape=[1], dtype=Float32, value=[ 1.45333335e-01])
train_episode: 108
At the end, own_hp 0: opp_hp 360. you lose.
Episode 108: loss is 0.008, rewards is -31.45
Tensor(shape=[1], dtype=Float32, value=[ 1.46666676e-01])
train_episode: 109
At the end, own_hp 162: opp_hp 224. you lose.
Episode 109: loss is 0.127, rewards is -5.09
Tensor(shape=[1], dtype=Float32, value=[ 1.48000002e-01])
train_episode: 110
At the end, own_hp 0: opp_hp 335. you lose.
Episode 110: loss is 0.007, rewards is -31.1
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 110 total rewards is 0.070
Tensor(shape=[1], dtype=Float32, value=[ 1.49333343e-01])
-----------------------------------------
train_episode: 111
At the end, own_hp 0: opp_hp 355. you lose.
Episode 111: loss is 0.061, rewards is -34.71
Tensor(shape=[1], dtype=Float32, value=[ 1.50666669e-01])
train_episode: 112
At the end, own_hp 0: opp_hp 355. you lose.
Episode 112: loss is 0.073, rewards is -34.55
Tensor(shape=[1], dtype=Float32, value=[ 1.52000010e-01])
train_episode: 113
At the end, own_hp 0: opp_hp 337. you lose.
Episode 113: loss is 0.093, rewards is -32.73
Tensor(shape=[1], dtype=Float32, value=[ 1.53333336e-01])
train_episode: 114
At the end, own_hp 263: opp_hp 332. you lose.
Episode 114: loss is 0.227, rewards is -7.16
Tensor(shape=[1], dtype=Float32, value=[ 1.54666662e-01])
train_episode: 115
At the end, own_hp 135: opp_hp 274. you lose.
Episode 115: loss is 0.041, rewards is -14.44
Tensor(shape=[1], dtype=Float32, value=[ 1.56000003e-01])
train_episode: 116
At the end, own_hp 0: opp_hp 380. you lose.
Episode 116: loss is 0.091, rewards is -34.33
Tensor(shape=[1], dtype=Float32, value=[ 1.57333344e-01])
train_episode: 117
At the end, own_hp 272: opp_hp 232. you win.
Episode 117: loss is 0.197, rewards is 3.47
Tensor(shape=[1], dtype=Float32, value=[ 1.58666670e-01])
train_episode: 118
At the end, own_hp 0: opp_hp 215. you lose.
Episode 118: loss is 0.051, rewards is -11.39
Tensor(shape=[1], dtype=Float32, value=[ 1.59999996e-01])
train_episode: 119
At the end, own_hp 160: opp_hp 245. you lose.
Episode 119: loss is 0.223, rewards is -9.35
Tensor(shape=[1], dtype=Float32, value=[ 1.61333337e-01])
train_episode: 120
At the end, own_hp 160: opp_hp 275. you lose.
Episode 120: loss is 0.066, rewards is -12.09
0
1
2
evaluate begin
At the end, own_hp 24: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 47: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 120 total rewards is -32.577
Tensor(shape=[1], dtype=Float32, value=[ 1.62666678e-01])
-----------------------------------------
train_episode: 121
At the end, own_hp 0: opp_hp 395. you lose.
Episode 121: loss is 0.775, rewards is -38.21
Tensor(shape=[1], dtype=Float32, value=[ 1.64000005e-01])
train_episode: 122
At the end, own_hp 0: opp_hp 350. you lose.
Episode 122: loss is 0.248, rewards is -34.06
Tensor(shape=[1], dtype=Float32, value=[ 1.65333331e-01])
train_episode: 123
At the end, own_hp 0: opp_hp 388. you lose.
Episode 123: loss is 0.0, rewards is -37.93
Tensor(shape=[1], dtype=Float32, value=[ 1.66666672e-01])
train_episode: 124
At the end, own_hp 0: opp_hp 385. you lose.
Episode 124: loss is 0.323, rewards is -37.01
Tensor(shape=[1], dtype=Float32, value=[ 1.68000013e-01])
train_episode: 125
can't receive signals within 60 seconds. let's terminate gym env.
Episode 125: loss is 0.05, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 1.69333339e-01])
train_episode: 126
At the end, own_hp 149: opp_hp 275. you lose.
Episode 126: loss is 0.432, rewards is -12.82
Tensor(shape=[1], dtype=Float32, value=[ 1.70666680e-01])
train_episode: 127
can't receive signals within 60 seconds. let's terminate gym env.
Episode 127: loss is 0.205, rewards is -3.42
Tensor(shape=[1], dtype=Float32, value=[ 1.71999991e-01])
train_episode: 128
At the end, own_hp 0: opp_hp 370. you lose.
Episode 128: loss is 0.248, rewards is -35.03
Tensor(shape=[1], dtype=Float32, value=[ 1.73333332e-01])
train_episode: 129
At the end, own_hp 179: opp_hp 300. you lose.
Episode 129: loss is 0.218, rewards is -11.53
Tensor(shape=[1], dtype=Float32, value=[ 1.74666673e-01])
train_episode: 130
At the end, own_hp 255: opp_hp 325. you lose.
Episode 130: loss is 4.095, rewards is -7.49
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 24: opp_hp 400. you lose.
At the end, own_hp 267: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 130 total rewards is -17.957
Tensor(shape=[1], dtype=Float32, value=[ 1.75999999e-01])
-----------------------------------------
train_episode: 131
At the end, own_hp 180: opp_hp 303. you lose.
Episode 131: loss is 0.048, rewards is -12.71
Tensor(shape=[1], dtype=Float32, value=[ 1.77333340e-01])
train_episode: 132
At the end, own_hp 210: opp_hp 350. you lose.
Episode 132: loss is 0.261, rewards is -14.23
Tensor(shape=[1], dtype=Float32, value=[ 1.78666681e-01])
train_episode: 133
At the end, own_hp 242: opp_hp 312. you lose.
Episode 133: loss is 0.053, rewards is -7.07
Tensor(shape=[1], dtype=Float32, value=[ 1.80000007e-01])
train_episode: 134
can't receive signals within 60 seconds. let's terminate gym env.
Episode 134: loss is 0.159, rewards is -15.82
Tensor(shape=[1], dtype=Float32, value=[ 1.81333348e-01])
train_episode: 135
can't receive signals within 60 seconds. let's terminate gym env.
Episode 135: loss is 0.539, rewards is 0.17
Tensor(shape=[1], dtype=Float32, value=[ 1.82666659e-01])
train_episode: 136
At the end, own_hp 197: opp_hp 295. you lose.
Episode 136: loss is 0.143, rewards is -10.21
Tensor(shape=[1], dtype=Float32, value=[ 1.84000000e-01])
train_episode: 137
At the end, own_hp 240: opp_hp 267. you lose.
Episode 137: loss is 0.315, rewards is -3.19
Tensor(shape=[1], dtype=Float32, value=[ 1.85333341e-01])
train_episode: 138
At the end, own_hp 0: opp_hp 395. you lose.
Episode 138: loss is 0.27, rewards is -39.05
Tensor(shape=[1], dtype=Float32, value=[ 1.86666667e-01])
train_episode: 139
At the end, own_hp 137: opp_hp 335. you lose.
Episode 139: loss is 0.509, rewards is -19.74
Tensor(shape=[1], dtype=Float32, value=[ 1.88000008e-01])
train_episode: 140
At the end, own_hp 0: opp_hp 400. you lose.
Episode 140: loss is 0.083, rewards is -38.01
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 290: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 140 total rewards is -3.910
Tensor(shape=[1], dtype=Float32, value=[ 1.89333349e-01])
-----------------------------------------
train_episode: 141
At the end, own_hp 155: opp_hp 325. you lose.
Episode 141: loss is 0.154, rewards is -15.28
Tensor(shape=[1], dtype=Float32, value=[ 1.90666676e-01])
train_episode: 142
At the end, own_hp 0: opp_hp 395. you lose.
Episode 142: loss is 0.016, rewards is -39.16
Tensor(shape=[1], dtype=Float32, value=[ 1.92000002e-01])
train_episode: 143
At the end, own_hp 0: opp_hp 395. you lose.
Episode 143: loss is 0.274, rewards is -37.48
Tensor(shape=[1], dtype=Float32, value=[ 1.93333328e-01])
train_episode: 144
can't receive signals within 60 seconds. let's terminate gym env.
Episode 144: loss is 0.111, rewards is -8.29
Tensor(shape=[1], dtype=Float32, value=[ 1.94666669e-01])
train_episode: 145
At the end, own_hp 160: opp_hp 340. you lose.
Episode 145: loss is 0.134, rewards is -18.34
Tensor(shape=[1], dtype=Float32, value=[ 1.96000010e-01])
train_episode: 146
At the end, own_hp 0: opp_hp 395. you lose.
Episode 146: loss is 0.218, rewards is -39.11
Tensor(shape=[1], dtype=Float32, value=[ 1.97333336e-01])
train_episode: 147
At the end, own_hp 0: opp_hp 400. you lose.
Episode 147: loss is 0.543, rewards is -38.71
Tensor(shape=[1], dtype=Float32, value=[ 1.98666677e-01])
train_episode: 148
At the end, own_hp 245: opp_hp 278. you lose.
Episode 148: loss is 0.083, rewards is -3.15
Tensor(shape=[1], dtype=Float32, value=[ 2.00000018e-01])
train_episode: 149
At the end, own_hp 150: opp_hp 307. you lose.
Episode 149: loss is 0.112, rewards is -15.92
Tensor(shape=[1], dtype=Float32, value=[ 2.01333329e-01])
train_episode: 150
can't receive signals within 60 seconds. let's terminate gym env.
Episode 150: loss is 0.106, rewards is -0.04
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 150 total rewards is -11.967
Tensor(shape=[1], dtype=Float32, value=[ 2.02666670e-01])
-----------------------------------------
train_episode: 151
At the end, own_hp 0: opp_hp 345. you lose.
Episode 151: loss is 0.106, rewards is -32.93
Tensor(shape=[1], dtype=Float32, value=[ 2.03999996e-01])
train_episode: 152
At the end, own_hp 223: opp_hp 235. you lose.
Episode 152: loss is 0.151, rewards is -2.77
Tensor(shape=[1], dtype=Float32, value=[ 2.05333337e-01])
train_episode: 153
can't receive signals within 60 seconds. let's terminate gym env.
Episode 153: loss is 0.054, rewards is 0.05
Tensor(shape=[1], dtype=Float32, value=[ 2.06666678e-01])
train_episode: 154
At the end, own_hp 165: opp_hp 323. you lose.
Episode 154: loss is 0.04, rewards is -15.82
Tensor(shape=[1], dtype=Float32, value=[ 2.08000004e-01])
train_episode: 155
At the end, own_hp 0: opp_hp 400. you lose.
Episode 155: loss is 0.077, rewards is -28.74
Tensor(shape=[1], dtype=Float32, value=[ 2.09333345e-01])
train_episode: 156
At the end, own_hp 0: opp_hp 252. you lose.
Episode 156: loss is 0.089, rewards is -22.96
Tensor(shape=[1], dtype=Float32, value=[ 2.10666686e-01])
train_episode: 157
At the end, own_hp 0: opp_hp 330. you lose.
Episode 157: loss is 0.149, rewards is -30.97
Tensor(shape=[1], dtype=Float32, value=[ 2.11999997e-01])
train_episode: 158
At the end, own_hp 115: opp_hp 285. you lose.
Episode 158: loss is 0.186, rewards is -16.98
Tensor(shape=[1], dtype=Float32, value=[ 2.13333338e-01])
train_episode: 159
At the end, own_hp 0: opp_hp 400. you lose.
Episode 159: loss is 0.098, rewards is -39.04
Tensor(shape=[1], dtype=Float32, value=[ 2.14666665e-01])
train_episode: 160
can't receive signals within 60 seconds. let's terminate gym env.
Episode 160: loss is 0.105, rewards is -3.12
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 160 total rewards is -0.590
Tensor(shape=[1], dtype=Float32, value=[ 2.16000006e-01])
-----------------------------------------
train_episode: 161
At the end, own_hp 0: opp_hp 400. you lose.
Episode 161: loss is 0.02, rewards is -39.12
Tensor(shape=[1], dtype=Float32, value=[ 2.17333347e-01])
train_episode: 162
At the end, own_hp 0: opp_hp 360. you lose.
Episode 162: loss is 0.031, rewards is -35.54
Tensor(shape=[1], dtype=Float32, value=[ 2.18666673e-01])
train_episode: 163
At the end, own_hp 275: opp_hp 345. you lose.
Episode 163: loss is 0.0, rewards is -7.05
Tensor(shape=[1], dtype=Float32, value=[ 2.20000014e-01])
train_episode: 164
At the end, own_hp 67: opp_hp 119. you lose.
Episode 164: loss is 0.062, rewards is -5.75
Tensor(shape=[1], dtype=Float32, value=[ 2.21333325e-01])
train_episode: 165
At the end, own_hp 0: opp_hp 355. you lose.
Episode 165: loss is 0.045, rewards is -32.48
Tensor(shape=[1], dtype=Float32, value=[ 2.22666666e-01])
train_episode: 166
can't receive signals within 60 seconds. let's terminate gym env.
Episode 166: loss is 0.614, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 2.24000007e-01])
train_episode: 167
can't receive signals within 60 seconds. let's terminate gym env.
Episode 167: loss is 0.032, rewards is 0.25
Tensor(shape=[1], dtype=Float32, value=[ 2.25333333e-01])
train_episode: 168
At the end, own_hp 225: opp_hp 250. you lose.
Episode 168: loss is 0.0, rewards is -2.16
Tensor(shape=[1], dtype=Float32, value=[ 2.26666674e-01])
train_episode: 169
At the end, own_hp 177: opp_hp 278. you lose.
Episode 169: loss is 0.044, rewards is -10.22
Tensor(shape=[1], dtype=Float32, value=[ 2.28000015e-01])
train_episode: 170
At the end, own_hp 0: opp_hp 380. you lose.
Episode 170: loss is 0.008, rewards is -27.86
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 170 total rewards is -27.013
Tensor(shape=[1], dtype=Float32, value=[ 2.29333341e-01])
-----------------------------------------
train_episode: 171
At the end, own_hp 0: opp_hp 350. you lose.
Episode 171: loss is 0.0, rewards is -33.01
Tensor(shape=[1], dtype=Float32, value=[ 2.30666667e-01])
train_episode: 172
can't receive signals within 60 seconds. let's terminate gym env.
Episode 172: loss is 0.048, rewards is -5.11
Tensor(shape=[1], dtype=Float32, value=[ 2.31999993e-01])
train_episode: 173
can't receive signals within 60 seconds. let's terminate gym env.
Episode 173: loss is 0.437, rewards is -0.81
Tensor(shape=[1], dtype=Float32, value=[ 2.33333334e-01])
train_episode: 174
At the end, own_hp 220: opp_hp 203. you win.
Episode 174: loss is 0.133, rewards is 1.85
Tensor(shape=[1], dtype=Float32, value=[ 2.34666675e-01])
train_episode: 175
At the end, own_hp 255: opp_hp 215. you win.
Episode 175: loss is 0.153, rewards is 3.09
Tensor(shape=[1], dtype=Float32, value=[ 2.36000001e-01])
train_episode: 176
At the end, own_hp 0: opp_hp 318. you lose.
Episode 176: loss is 0.127, rewards is -30.78
Tensor(shape=[1], dtype=Float32, value=[ 2.37333342e-01])
train_episode: 177
At the end, own_hp 155: opp_hp 206. you lose.
Episode 177: loss is 0.164, rewards is -6.23
Tensor(shape=[1], dtype=Float32, value=[ 2.38666683e-01])
train_episode: 178
At the end, own_hp 147: opp_hp 240. you lose.
Episode 178: loss is 0.187, rewards is -9.6
Tensor(shape=[1], dtype=Float32, value=[ 2.40000010e-01])
train_episode: 179
can't receive signals within 60 seconds. let's terminate gym env.
Episode 179: loss is 0.18, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 2.41333336e-01])
train_episode: 180
At the end, own_hp 260: opp_hp 320. you lose.
Episode 180: loss is 0.123, rewards is -5.74
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 180 total rewards is -6.323
Tensor(shape=[1], dtype=Float32, value=[ 2.42666662e-01])
-----------------------------------------
train_episode: 181
At the end, own_hp 215: opp_hp 225. you lose.
Episode 181: loss is 0.031, rewards is -1.13
Tensor(shape=[1], dtype=Float32, value=[ 2.44000003e-01])
train_episode: 182
At the end, own_hp 218: opp_hp 312. you lose.
Episode 182: loss is 0.0, rewards is -8.02
Tensor(shape=[1], dtype=Float32, value=[ 2.45333344e-01])
train_episode: 183
At the end, own_hp 225: opp_hp 245. you lose.
Episode 183: loss is 0.061, rewards is -2.5
Tensor(shape=[1], dtype=Float32, value=[ 2.46666670e-01])
train_episode: 184
At the end, own_hp 0: opp_hp 310. you lose.
Episode 184: loss is 0.16, rewards is -29.9
Tensor(shape=[1], dtype=Float32, value=[ 2.48000011e-01])
train_episode: 185
At the end, own_hp 0: opp_hp 375. you lose.
Episode 185: loss is 0.016, rewards is -34.71
Tensor(shape=[1], dtype=Float32, value=[ 2.49333352e-01])
train_episode: 186
can't receive signals within 60 seconds. let's terminate gym env.
Episode 186: loss is 0.061, rewards is -11.39
Tensor(shape=[1], dtype=Float32, value=[ 2.50666678e-01])
train_episode: 187
can't receive signals within 60 seconds. let's terminate gym env.
Episode 187: loss is 0.048, rewards is -18.67
Tensor(shape=[1], dtype=Float32, value=[ 2.52000004e-01])
train_episode: 188
At the end, own_hp 0: opp_hp 340. you lose.
Episode 188: loss is 0.092, rewards is -33.02
Tensor(shape=[1], dtype=Float32, value=[ 2.53333330e-01])
train_episode: 189
At the end, own_hp 35: opp_hp 131. you lose.
Episode 189: loss is 0.139, rewards is -10.48
Tensor(shape=[1], dtype=Float32, value=[ 2.54666686e-01])
train_episode: 190
At the end, own_hp 0: opp_hp 340. you lose.
Episode 190: loss is 0.158, rewards is -33.42
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 190 total rewards is -8.263
Tensor(shape=[1], dtype=Float32, value=[ 2.56000012e-01])
-----------------------------------------
train_episode: 191
At the end, own_hp 185: opp_hp 240. you lose.
Episode 191: loss is 0.138, rewards is -6.42
Tensor(shape=[1], dtype=Float32, value=[ 2.57333338e-01])
train_episode: 192
At the end, own_hp 128: opp_hp 258. you lose.
Episode 192: loss is 0.173, rewards is -13.36
Tensor(shape=[1], dtype=Float32, value=[ 2.58666694e-01])
train_episode: 193
At the end, own_hp 0: opp_hp 300. you lose.
Episode 193: loss is 0.06, rewards is -30.6
Tensor(shape=[1], dtype=Float32, value=[ 2.59999990e-01])
train_episode: 194
At the end, own_hp 0: opp_hp 382. you lose.
Episode 194: loss is 0.008, rewards is -36.98
Tensor(shape=[1], dtype=Float32, value=[ 2.61333346e-01])
train_episode: 195
can't receive signals within 60 seconds. let's terminate gym env.
Episode 195: loss is 0.125, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 2.62666672e-01])
train_episode: 196
can't receive signals within 60 seconds. let's terminate gym env.
Episode 196: loss is 0.075, rewards is -0.01
Tensor(shape=[1], dtype=Float32, value=[ 2.63999999e-01])
train_episode: 197
At the end, own_hp 180: opp_hp 315. you lose.
Episode 197: loss is 0.465, rewards is -13.78
Tensor(shape=[1], dtype=Float32, value=[ 2.65333354e-01])
train_episode: 198
can't receive signals within 60 seconds. let's terminate gym env.
Episode 198: loss is 0.184, rewards is -14.93
Tensor(shape=[1], dtype=Float32, value=[ 2.66666681e-01])
train_episode: 199
can't receive signals within 60 seconds. let's terminate gym env.
Episode 199: loss is 0.239, rewards is -4.29
Tensor(shape=[1], dtype=Float32, value=[ 2.68000007e-01])
train_episode: 200
can't receive signals within 60 seconds. let's terminate gym env.
Episode 200: loss is 0.038, rewards is 0.06
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 221: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 200 total rewards is -5.070
Tensor(shape=[1], dtype=Float32, value=[ 2.69333363e-01])
-----------------------------------------
train_episode: 201
At the end, own_hp 0: opp_hp 400. you lose.
Episode 201: loss is 0.165, rewards is -38.96
Tensor(shape=[1], dtype=Float32, value=[ 2.70666659e-01])
train_episode: 202
At the end, own_hp 265: opp_hp 190. you win.
Episode 202: loss is 0.099, rewards is 6.94
Tensor(shape=[1], dtype=Float32, value=[ 2.72000015e-01])
train_episode: 203
At the end, own_hp 0: opp_hp 250. you lose.
Episode 203: loss is 0.063, rewards is -23.54
Tensor(shape=[1], dtype=Float32, value=[ 2.73333341e-01])
train_episode: 204
can't receive signals within 60 seconds. let's terminate gym env.
Episode 204: loss is 0.02, rewards is -0.01
Tensor(shape=[1], dtype=Float32, value=[ 2.74666667e-01])
train_episode: 205
can't receive signals within 60 seconds. let's terminate gym env.
Episode 205: loss is 0.162, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 2.76000023e-01])
train_episode: 206
At the end, own_hp 0: opp_hp 382. you lose.
Episode 206: loss is 0.085, rewards is -37.58
Tensor(shape=[1], dtype=Float32, value=[ 2.77333349e-01])
train_episode: 207
At the end, own_hp 225: opp_hp 185. you win.
Episode 207: loss is 0.062, rewards is 4.07
Tensor(shape=[1], dtype=Float32, value=[ 2.78666675e-01])
train_episode: 208
At the end, own_hp 218: opp_hp 334. you lose.
Episode 208: loss is 0.064, rewards is -11.75
Tensor(shape=[1], dtype=Float32, value=[ 2.80000001e-01])
train_episode: 209
At the end, own_hp 0: opp_hp 350. you lose.
Episode 209: loss is 0.052, rewards is -30.86
Tensor(shape=[1], dtype=Float32, value=[ 2.81333327e-01])
train_episode: 210
At the end, own_hp 160: opp_hp 261. you lose.
Episode 210: loss is 0.008, rewards is -10.67
0
1
2
evaluate begin
At the end, own_hp 211: opp_hp 400. you lose.
At the end, own_hp 260: opp_hp 400. you lose.
At the end, own_hp 282: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 210 total rewards is -11.867
Tensor(shape=[1], dtype=Float32, value=[ 2.82666683e-01])
-----------------------------------------
train_episode: 211
At the end, own_hp 0: opp_hp 390. you lose.
Episode 211: loss is 0.125, rewards is -30.22
Tensor(shape=[1], dtype=Float32, value=[ 2.84000009e-01])
train_episode: 212
At the end, own_hp 0: opp_hp 377. you lose.
Episode 212: loss is 0.082, rewards is -33.49
Tensor(shape=[1], dtype=Float32, value=[ 2.85333335e-01])
train_episode: 213
At the end, own_hp 0: opp_hp 350. you lose.
Episode 213: loss is 0.077, rewards is -29.34
Tensor(shape=[1], dtype=Float32, value=[ 2.86666691e-01])
train_episode: 214
At the end, own_hp 151: opp_hp 106. you win.
Episode 214: loss is 0.304, rewards is 5.52
Tensor(shape=[1], dtype=Float32, value=[ 2.88000017e-01])
train_episode: 215
At the end, own_hp 135: opp_hp 187. you lose.
Episode 215: loss is 0.126, rewards is -5.91
Tensor(shape=[1], dtype=Float32, value=[ 2.89333344e-01])
train_episode: 216
can't receive signals within 60 seconds. let's terminate gym env.
Episode 216: loss is 0.108, rewards is -5.36
Tensor(shape=[1], dtype=Float32, value=[ 2.90666670e-01])
train_episode: 217
At the end, own_hp 0: opp_hp 390. you lose.
Episode 217: loss is 0.0, rewards is -34.84
Tensor(shape=[1], dtype=Float32, value=[ 2.91999996e-01])
train_episode: 218
At the end, own_hp 165: opp_hp 280. you lose.
Episode 218: loss is 0.016, rewards is -11.61
Tensor(shape=[1], dtype=Float32, value=[ 2.93333352e-01])
train_episode: 219
At the end, own_hp 240: opp_hp 220. you win.
Episode 219: loss is 0.114, rewards is 1.63
Tensor(shape=[1], dtype=Float32, value=[ 2.94666678e-01])
train_episode: 220
can't receive signals within 60 seconds. let's terminate gym env.
Episode 220: loss is 0.007, rewards is -23.97
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 220 total rewards is -1.737
Tensor(shape=[1], dtype=Float32, value=[ 2.96000004e-01])
-----------------------------------------
train_episode: 221
can't receive signals within 60 seconds. let's terminate gym env.
Episode 221: loss is 0.0, rewards is -8.57
Tensor(shape=[1], dtype=Float32, value=[ 2.97333360e-01])
train_episode: 222
can't receive signals within 60 seconds. let's terminate gym env.
Episode 222: loss is 0.181, rewards is 0.02
Tensor(shape=[1], dtype=Float32, value=[ 2.98666686e-01])
train_episode: 223
can't receive signals within 60 seconds. let's terminate gym env.
Episode 223: loss is 0.135, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 3.00000012e-01])
train_episode: 224
At the end, own_hp 232: opp_hp 230. you win.
Episode 224: loss is 0.199, rewards is -0.64
Tensor(shape=[1], dtype=Float32, value=[ 3.01333338e-01])
train_episode: 225
can't receive signals within 60 seconds. let's terminate gym env.
Episode 225: loss is 0.098, rewards is 1.21
Tensor(shape=[1], dtype=Float32, value=[ 3.02666664e-01])
train_episode: 226
can't receive signals within 60 seconds. let's terminate gym env.
Episode 226: loss is 0.0, rewards is -7.03
Tensor(shape=[1], dtype=Float32, value=[ 3.04000020e-01])
train_episode: 227
can't receive signals within 60 seconds. let's terminate gym env.
Episode 227: loss is 4.495, rewards is 0.03
Tensor(shape=[1], dtype=Float32, value=[ 3.05333346e-01])
train_episode: 228
At the end, own_hp 150: opp_hp 222. you lose.
Episode 228: loss is 0.369, rewards is -7.65
Tensor(shape=[1], dtype=Float32, value=[ 3.06666672e-01])
train_episode: 229
At the end, own_hp 0: opp_hp 355. you lose.
Episode 229: loss is 0.045, rewards is -34.57
Tensor(shape=[1], dtype=Float32, value=[ 3.08000028e-01])
train_episode: 230
can't receive signals within 60 seconds. let's terminate gym env.
Episode 230: loss is 0.044, rewards is -18.32
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 257: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 230 total rewards is -9.330
Tensor(shape=[1], dtype=Float32, value=[ 3.09333324e-01])
-----------------------------------------
train_episode: 231
can't receive signals within 60 seconds. let's terminate gym env.
Episode 231: loss is 0.032, rewards is -3.11
Tensor(shape=[1], dtype=Float32, value=[ 3.10666680e-01])
train_episode: 232
can't receive signals within 60 seconds. let's terminate gym env.
Episode 232: loss is 0.142, rewards is -0.29
Tensor(shape=[1], dtype=Float32, value=[ 3.12000006e-01])
train_episode: 233
At the end, own_hp 0: opp_hp 293. you lose.
Episode 233: loss is 0.0, rewards is -27.81
Tensor(shape=[1], dtype=Float32, value=[ 3.13333333e-01])
train_episode: 234
At the end, own_hp 175: opp_hp 187. you lose.
Episode 234: loss is 0.0, rewards is 1.39
Tensor(shape=[1], dtype=Float32, value=[ 3.14666688e-01])
train_episode: 235
At the end, own_hp 178: opp_hp 205. you lose.
Episode 235: loss is 4.559, rewards is -2.86
Tensor(shape=[1], dtype=Float32, value=[ 3.16000015e-01])
train_episode: 236
can't receive signals within 60 seconds. let's terminate gym env.
Episode 236: loss is 0.046, rewards is 0.67
Tensor(shape=[1], dtype=Float32, value=[ 3.17333341e-01])
train_episode: 237
At the end, own_hp 0: opp_hp 328. you lose.
Episode 237: loss is 0.317, rewards is -22.01
Tensor(shape=[1], dtype=Float32, value=[ 3.18666667e-01])
train_episode: 238
At the end, own_hp 0: opp_hp 192. you lose.
Episode 238: loss is 0.189, rewards is -18.0
Tensor(shape=[1], dtype=Float32, value=[ 3.19999993e-01])
train_episode: 239
can't receive signals within 60 seconds. let's terminate gym env.
Episode 239: loss is 0.076, rewards is 1.05
Tensor(shape=[1], dtype=Float32, value=[ 3.21333349e-01])
train_episode: 240
At the end, own_hp 165: opp_hp 205. you lose.
Episode 240: loss is 0.024, rewards is -2.96
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 70: opp_hp 400. you lose.
At the end, own_hp 300: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 240 total rewards is -21.557
Tensor(shape=[1], dtype=Float32, value=[ 3.22666675e-01])
-----------------------------------------
train_episode: 241
can't receive signals within 60 seconds. let's terminate gym env.
Episode 241: loss is 0.157, rewards is -10.39
Tensor(shape=[1], dtype=Float32, value=[ 3.24000001e-01])
train_episode: 242
At the end, own_hp 0: opp_hp 335. you lose.
Episode 242: loss is 0.076, rewards is -32.49
Tensor(shape=[1], dtype=Float32, value=[ 3.25333357e-01])
train_episode: 243
At the end, own_hp 190: opp_hp 253. you lose.
Episode 243: loss is 0.0, rewards is -5.07
Tensor(shape=[1], dtype=Float32, value=[ 3.26666683e-01])
train_episode: 244
can't receive signals within 60 seconds. let's terminate gym env.
Episode 244: loss is 0.0, rewards is -0.01
Tensor(shape=[1], dtype=Float32, value=[ 3.28000009e-01])
train_episode: 245
can't receive signals within 60 seconds. let's terminate gym env.
Episode 245: loss is 0.052, rewards is 0.02
Tensor(shape=[1], dtype=Float32, value=[ 3.29333335e-01])
train_episode: 246
At the end, own_hp 0: opp_hp 370. you lose.
Episode 246: loss is 0.05, rewards is -34.73
Tensor(shape=[1], dtype=Float32, value=[ 3.30666661e-01])
train_episode: 247
At the end, own_hp 145: opp_hp 227. you lose.
Episode 247: loss is 0.032, rewards is -11.21
Tensor(shape=[1], dtype=Float32, value=[ 3.32000017e-01])
train_episode: 248
At the end, own_hp 0: opp_hp 355. you lose.
Episode 248: loss is 0.0, rewards is -33.06
Tensor(shape=[1], dtype=Float32, value=[ 3.33333343e-01])
train_episode: 249
At the end, own_hp 135: opp_hp 250. you lose.
Episode 249: loss is 0.636, rewards is -14.23
Tensor(shape=[1], dtype=Float32, value=[ 3.34666669e-01])
train_episode: 250
At the end, own_hp 215: opp_hp 272. you lose.
Episode 250: loss is 0.061, rewards is -6.23
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 327: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 250 total rewards is -7.630
Tensor(shape=[1], dtype=Float32, value=[ 3.36000025e-01])
-----------------------------------------
train_episode: 251
At the end, own_hp 0: opp_hp 400. you lose.
Episode 251: loss is 0.161, rewards is -39.74
Tensor(shape=[1], dtype=Float32, value=[ 3.37333322e-01])
train_episode: 252
At the end, own_hp 0: opp_hp 365. you lose.
Episode 252: loss is 0.16, rewards is -36.09
Tensor(shape=[1], dtype=Float32, value=[ 3.38666677e-01])
train_episode: 253
can't receive signals within 60 seconds. let's terminate gym env.
Episode 253: loss is 0.017, rewards is 6.39
Tensor(shape=[1], dtype=Float32, value=[ 3.40000004e-01])
train_episode: 254
At the end, own_hp 0: opp_hp 385. you lose.
Episode 254: loss is 0.0, rewards is -38.05
Tensor(shape=[1], dtype=Float32, value=[ 3.41333359e-01])
train_episode: 255
At the end, own_hp 52: opp_hp 227. you lose.
Episode 255: loss is 0.145, rewards is -14.18
Tensor(shape=[1], dtype=Float32, value=[ 3.42666686e-01])
train_episode: 256
At the end, own_hp 0: opp_hp 395. you lose.
Episode 256: loss is 0.084, rewards is -36.9
Tensor(shape=[1], dtype=Float32, value=[ 3.43999982e-01])
train_episode: 257
At the end, own_hp 272: opp_hp 271. you win.
Episode 257: loss is 0.174, rewards is -0.84
Tensor(shape=[1], dtype=Float32, value=[ 3.45333338e-01])
train_episode: 258
can't receive signals within 60 seconds. let's terminate gym env.
Episode 258: loss is 0.023, rewards is 0.12
Tensor(shape=[1], dtype=Float32, value=[ 3.46666664e-01])
train_episode: 259
can't receive signals within 60 seconds. let's terminate gym env.
Episode 259: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 3.48000020e-01])
train_episode: 260
At the end, own_hp 190: opp_hp 340. you lose.
Episode 260: loss is 0.494, rewards is -14.06
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 281: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 260 total rewards is -26.703
Tensor(shape=[1], dtype=Float32, value=[ 3.49333346e-01])
-----------------------------------------
train_episode: 261
can't receive signals within 60 seconds. let's terminate gym env.
Episode 261: loss is 0.036, rewards is -26.58
Tensor(shape=[1], dtype=Float32, value=[ 3.50666702e-01])
train_episode: 262
can't receive signals within 60 seconds. let's terminate gym env.
Episode 262: loss is 0.2, rewards is 0.03
Tensor(shape=[1], dtype=Float32, value=[ 3.51999998e-01])
train_episode: 263
At the end, own_hp 182: opp_hp 291. you lose.
Episode 263: loss is 0.021, rewards is -9.9
Tensor(shape=[1], dtype=Float32, value=[ 3.53333324e-01])
train_episode: 264
At the end, own_hp 245: opp_hp 335. you lose.
Episode 264: loss is 0.008, rewards is -10.01
Tensor(shape=[1], dtype=Float32, value=[ 3.54666680e-01])
train_episode: 265
At the end, own_hp 0: opp_hp 365. you lose.
Episode 265: loss is 0.031, rewards is -35.07
Tensor(shape=[1], dtype=Float32, value=[ 3.56000006e-01])
train_episode: 266
can't receive signals within 60 seconds. let's terminate gym env.
Episode 266: loss is 0.161, rewards is -0.07
Tensor(shape=[1], dtype=Float32, value=[ 3.57333362e-01])
train_episode: 267
can't receive signals within 60 seconds. let's terminate gym env.
Episode 267: loss is 0.051, rewards is 0.39
Tensor(shape=[1], dtype=Float32, value=[ 3.58666658e-01])
train_episode: 268
can't receive signals within 60 seconds. let's terminate gym env.
Episode 268: loss is 0.048, rewards is 0.02
Tensor(shape=[1], dtype=Float32, value=[ 3.60000014e-01])
train_episode: 269
can't receive signals within 60 seconds. let's terminate gym env.
Episode 269: loss is 0.0, rewards is 0.04
Tensor(shape=[1], dtype=Float32, value=[ 3.61333340e-01])
train_episode: 270
At the end, own_hp 295: opp_hp 265. you win.
Episode 270: loss is 0.092, rewards is 3.02
0
1
2
evaluate begin
At the end, own_hp 239: opp_hp 400. you lose.
At the end, own_hp 22: opp_hp 400. you lose.
At the end, own_hp 303: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 270 total rewards is -18.443
Tensor(shape=[1], dtype=Float32, value=[ 3.62666696e-01])
-----------------------------------------
train_episode: 271
At the end, own_hp 202: opp_hp 143. you win.
Episode 271: loss is 0.07, rewards is 7.05
Tensor(shape=[1], dtype=Float32, value=[ 3.64000022e-01])
train_episode: 272
At the end, own_hp 0: opp_hp 370. you lose.
Episode 272: loss is 0.241, rewards is -35.34
Tensor(shape=[1], dtype=Float32, value=[ 3.65333319e-01])
train_episode: 273
At the end, own_hp 0: opp_hp 378. you lose.
Episode 273: loss is 0.153, rewards is -35.91
Tensor(shape=[1], dtype=Float32, value=[ 3.66666675e-01])
train_episode: 274
At the end, own_hp 0: opp_hp 370. you lose.
Episode 274: loss is 0.008, rewards is -36.49
Tensor(shape=[1], dtype=Float32, value=[ 3.68000001e-01])
train_episode: 275
can't receive signals within 60 seconds. let's terminate gym env.
Episode 275: loss is 0.038, rewards is -8.04
Tensor(shape=[1], dtype=Float32, value=[ 3.69333357e-01])
train_episode: 276
At the end, own_hp 0: opp_hp 300. you lose.
Episode 276: loss is 0.0, rewards is -23.84
Tensor(shape=[1], dtype=Float32, value=[ 3.70666683e-01])
train_episode: 277
At the end, own_hp 0: opp_hp 380. you lose.
Episode 277: loss is 0.172, rewards is -36.04
Tensor(shape=[1], dtype=Float32, value=[ 3.72000039e-01])
train_episode: 278
At the end, own_hp 197: opp_hp 240. you lose.
Episode 278: loss is 0.06, rewards is -8.27
Tensor(shape=[1], dtype=Float32, value=[ 3.73333335e-01])
train_episode: 279
At the end, own_hp 66: opp_hp 195. you lose.
Episode 279: loss is 0.001, rewards is -13.62
Tensor(shape=[1], dtype=Float32, value=[ 3.74666661e-01])
train_episode: 280
can't receive signals within 60 seconds. let's terminate gym env.
Episode 280: loss is 0.031, rewards is 2.54
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 280 total rewards is 0.143
Tensor(shape=[1], dtype=Float32, value=[ 3.76000017e-01])
-----------------------------------------
train_episode: 281
can't receive signals within 60 seconds. let's terminate gym env.
Episode 281: loss is 0.031, rewards is 0.03
Tensor(shape=[1], dtype=Float32, value=[ 3.77333343e-01])
train_episode: 282
can't receive signals within 60 seconds. let's terminate gym env.
Episode 282: loss is 0.181, rewards is 0.02
Tensor(shape=[1], dtype=Float32, value=[ 3.78666699e-01])
train_episode: 283
At the end, own_hp 182: opp_hp 155. you win.
Episode 283: loss is 0.0, rewards is -10.72
Tensor(shape=[1], dtype=Float32, value=[ 3.79999995e-01])
train_episode: 284
can't receive signals within 60 seconds. let's terminate gym env.
Episode 284: loss is 0.045, rewards is -24.26
Tensor(shape=[1], dtype=Float32, value=[ 3.81333351e-01])
train_episode: 285
At the end, own_hp 0: opp_hp 375. you lose.
Episode 285: loss is 0.18, rewards is -36.93
Tensor(shape=[1], dtype=Float32, value=[ 3.82666677e-01])
train_episode: 286
At the end, own_hp 0: opp_hp 380. you lose.
Episode 286: loss is 0.137, rewards is -30.21
Tensor(shape=[1], dtype=Float32, value=[ 3.84000003e-01])
train_episode: 287
At the end, own_hp 203: opp_hp 170. you win.
Episode 287: loss is 0.054, rewards is 3.28
Tensor(shape=[1], dtype=Float32, value=[ 3.85333359e-01])
train_episode: 288
At the end, own_hp 0: opp_hp 215. you lose.
Episode 288: loss is 0.133, rewards is -20.46
Tensor(shape=[1], dtype=Float32, value=[ 3.86666656e-01])
train_episode: 289
At the end, own_hp 220: opp_hp 143. you win.
Episode 289: loss is 0.0, rewards is 7.76
Tensor(shape=[1], dtype=Float32, value=[ 3.88000011e-01])
train_episode: 290
At the end, own_hp 0: opp_hp 395. you lose.
Episode 290: loss is 0.322, rewards is -37.38
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 302: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 290 total rewards is -12.017
Tensor(shape=[1], dtype=Float32, value=[ 3.89333338e-01])
-----------------------------------------
train_episode: 291
At the end, own_hp 222: opp_hp 207. you win.
Episode 291: loss is 0.064, rewards is 0.72
Tensor(shape=[1], dtype=Float32, value=[ 3.90666693e-01])
train_episode: 292
can't receive signals within 60 seconds. let's terminate gym env.
Episode 292: loss is 0.033, rewards is -0.63
Tensor(shape=[1], dtype=Float32, value=[ 3.92000020e-01])
train_episode: 293
can't receive signals within 60 seconds. let's terminate gym env.
Episode 293: loss is 0.195, rewards is 3.8
Tensor(shape=[1], dtype=Float32, value=[ 3.93333316e-01])
train_episode: 294
At the end, own_hp 0: opp_hp 305. you lose.
Episode 294: loss is 0.153, rewards is -25.84
Tensor(shape=[1], dtype=Float32, value=[ 3.94666672e-01])
train_episode: 295
At the end, own_hp 140: opp_hp 138. you win.
Episode 295: loss is 0.066, rewards is -0.66
Tensor(shape=[1], dtype=Float32, value=[ 3.95999998e-01])
train_episode: 296
At the end, own_hp 205: opp_hp 245. you lose.
Episode 296: loss is 0.032, rewards is -5.13
Tensor(shape=[1], dtype=Float32, value=[ 3.97333354e-01])
train_episode: 297
At the end, own_hp 143: opp_hp 155. you lose.
Episode 297: loss is 0.1, rewards is 0.14
Tensor(shape=[1], dtype=Float32, value=[ 3.98666680e-01])
train_episode: 298
can't receive signals within 60 seconds. let's terminate gym env.
Episode 298: loss is 0.0, rewards is 1.0
Tensor(shape=[1], dtype=Float32, value=[ 4.00000036e-01])
train_episode: 299
At the end, own_hp 255: opp_hp 255. you lose.
Episode 299: loss is 0.008, rewards is -0.22
Tensor(shape=[1], dtype=Float32, value=[ 4.01333332e-01])
train_episode: 300
At the end, own_hp 224: opp_hp 93. you win.
Episode 300: loss is 0.151, rewards is 12.27
0
1
2
evaluate begin
At the end, own_hp 293: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 300 total rewards is -14.353
Tensor(shape=[1], dtype=Float32, value=[ 4.02666658e-01])
-----------------------------------------
train_episode: 301
can't receive signals within 60 seconds. let's terminate gym env.
Episode 301: loss is 0.0, rewards is -23.29
Tensor(shape=[1], dtype=Float32, value=[ 4.04000014e-01])
train_episode: 302
At the end, own_hp 212: opp_hp 340. you lose.
Episode 302: loss is 0.072, rewards is -13.22
Tensor(shape=[1], dtype=Float32, value=[ 4.05333340e-01])
train_episode: 303
At the end, own_hp 230: opp_hp 130. you win.
Episode 303: loss is 0.0, rewards is 9.41
Tensor(shape=[1], dtype=Float32, value=[ 4.06666696e-01])
train_episode: 304
At the end, own_hp 0: opp_hp 220. you lose.
Episode 304: loss is 1.225, rewards is -18.87
Tensor(shape=[1], dtype=Float32, value=[ 4.07999992e-01])
train_episode: 305
can't receive signals within 60 seconds. let's terminate gym env.
Episode 305: loss is 0.076, rewards is 5.41
Tensor(shape=[1], dtype=Float32, value=[ 4.09333348e-01])
train_episode: 306
At the end, own_hp 210: opp_hp 275. you lose.
Episode 306: loss is 0.0, rewards is -6.68
Tensor(shape=[1], dtype=Float32, value=[ 4.10666674e-01])
train_episode: 307
At the end, own_hp 0: opp_hp 318. you lose.
Episode 307: loss is 0.007, rewards is -28.42
Tensor(shape=[1], dtype=Float32, value=[ 4.12000000e-01])
train_episode: 308
At the end, own_hp 185: opp_hp 245. you lose.
Episode 308: loss is 0.127, rewards is -5.95
Tensor(shape=[1], dtype=Float32, value=[ 4.13333356e-01])
train_episode: 309
At the end, own_hp 232: opp_hp 255. you lose.
Episode 309: loss is 0.098, rewards is -1.54
Tensor(shape=[1], dtype=Float32, value=[ 4.14666653e-01])
train_episode: 310
At the end, own_hp 0: opp_hp 385. you lose.
Episode 310: loss is 0.03, rewards is -33.86
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 303: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 310 total rewards is -14.890
Tensor(shape=[1], dtype=Float32, value=[ 4.16000009e-01])
-----------------------------------------
train_episode: 311
At the end, own_hp 0: opp_hp 390. you lose.
Episode 311: loss is 0.236, rewards is -33.25
Tensor(shape=[1], dtype=Float32, value=[ 4.17333335e-01])
train_episode: 312
At the end, own_hp 200: opp_hp 237. you lose.
Episode 312: loss is 0.054, rewards is -4.72
Tensor(shape=[1], dtype=Float32, value=[ 4.18666691e-01])
train_episode: 313
can't receive signals within 60 seconds. let's terminate gym env.
Episode 313: loss is 0.271, rewards is -7.84
Tensor(shape=[1], dtype=Float32, value=[ 4.20000017e-01])
train_episode: 314
At the end, own_hp 260: opp_hp 293. you lose.
Episode 314: loss is 0.045, rewards is -3.97
Tensor(shape=[1], dtype=Float32, value=[ 4.21333373e-01])
train_episode: 315
At the end, own_hp 0: opp_hp 385. you lose.
Episode 315: loss is 0.008, rewards is -37.34
Tensor(shape=[1], dtype=Float32, value=[ 4.22666669e-01])
train_episode: 316
At the end, own_hp 0: opp_hp 322. you lose.
Episode 316: loss is 0.016, rewards is -30.36
Tensor(shape=[1], dtype=Float32, value=[ 4.23999995e-01])
train_episode: 317
At the end, own_hp 267: opp_hp 243. you win.
Episode 317: loss is 0.0, rewards is 2.92
Tensor(shape=[1], dtype=Float32, value=[ 4.25333351e-01])
train_episode: 318
At the end, own_hp 0: opp_hp 315. you lose.
Episode 318: loss is 0.144, rewards is -32.93
Tensor(shape=[1], dtype=Float32, value=[ 4.26666677e-01])
train_episode: 319
At the end, own_hp 225: opp_hp 227. you lose.
Episode 319: loss is 0.208, rewards is 0.8
Tensor(shape=[1], dtype=Float32, value=[ 4.28000033e-01])
train_episode: 320
At the end, own_hp 200: opp_hp 315. you lose.
Episode 320: loss is 0.03, rewards is -12.45
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 272: opp_hp 400. you lose.
At the end, own_hp 287: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 320 total rewards is -15.513
Tensor(shape=[1], dtype=Float32, value=[ 4.29333329e-01])
-----------------------------------------
train_episode: 321
At the end, own_hp 0: opp_hp 345. you lose.
Episode 321: loss is 0.03, rewards is -31.22
Tensor(shape=[1], dtype=Float32, value=[ 4.30666685e-01])
train_episode: 322
At the end, own_hp 0: opp_hp 380. you lose.
Episode 322: loss is 0.031, rewards is -28.43
Tensor(shape=[1], dtype=Float32, value=[ 4.32000011e-01])
train_episode: 323
At the end, own_hp 190: opp_hp 256. you lose.
Episode 323: loss is 0.016, rewards is -6.51
Tensor(shape=[1], dtype=Float32, value=[ 4.33333337e-01])
train_episode: 324
At the end, own_hp 160: opp_hp 236. you lose.
Episode 324: loss is 0.045, rewards is -8.01
Tensor(shape=[1], dtype=Float32, value=[ 4.34666693e-01])
train_episode: 325
At the end, own_hp 0: opp_hp 380. you lose.
Episode 325: loss is 0.041, rewards is -37.03
Tensor(shape=[1], dtype=Float32, value=[ 4.35999990e-01])
train_episode: 326
can't receive signals within 60 seconds. let's terminate gym env.
Episode 326: loss is 0.572, rewards is -0.92
Tensor(shape=[1], dtype=Float32, value=[ 4.37333345e-01])
train_episode: 327
At the end, own_hp 90: opp_hp 99. you lose.
Episode 327: loss is 0.046, rewards is -1.0
Tensor(shape=[1], dtype=Float32, value=[ 4.38666672e-01])
train_episode: 328
At the end, own_hp 173: opp_hp 233. you lose.
Episode 328: loss is 0.74, rewards is -5.82
Tensor(shape=[1], dtype=Float32, value=[ 4.40000027e-01])
train_episode: 329
At the end, own_hp 118: opp_hp 292. you lose.
Episode 329: loss is 0.634, rewards is -17.59
Tensor(shape=[1], dtype=Float32, value=[ 4.41333354e-01])
train_episode: 330
can't receive signals within 60 seconds. let's terminate gym env.
Episode 330: loss is 0.409, rewards is 0.05
0
1
2
evaluate begin
At the end, own_hp 275: opp_hp 400. you lose.
At the end, own_hp 277: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 330 total rewards is -6.887
Tensor(shape=[1], dtype=Float32, value=[ 4.42666650e-01])
-----------------------------------------
train_episode: 331
At the end, own_hp 0: opp_hp 360. you lose.
Episode 331: loss is 0.086, rewards is -30.91
Tensor(shape=[1], dtype=Float32, value=[ 4.44000006e-01])
train_episode: 332
At the end, own_hp 260: opp_hp 270. you lose.
Episode 332: loss is 0.015, rewards is -1.42
Tensor(shape=[1], dtype=Float32, value=[ 4.45333332e-01])
train_episode: 333
At the end, own_hp 0: opp_hp 380. you lose.
Episode 333: loss is 0.052, rewards is -36.7
Tensor(shape=[1], dtype=Float32, value=[ 4.46666688e-01])
train_episode: 334
can't receive signals within 60 seconds. let's terminate gym env.
Episode 334: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 4.48000014e-01])
train_episode: 335
can't receive signals within 60 seconds. let's terminate gym env.
Episode 335: loss is 0.135, rewards is -3.46
Tensor(shape=[1], dtype=Float32, value=[ 4.49333370e-01])
train_episode: 336
At the end, own_hp 105: opp_hp 182. you lose.
Episode 336: loss is 0.154, rewards is -5.45
Tensor(shape=[1], dtype=Float32, value=[ 4.50666666e-01])
train_episode: 337
can't receive signals within 60 seconds. let's terminate gym env.
Episode 337: loss is 0.0, rewards is -29.15
Tensor(shape=[1], dtype=Float32, value=[ 4.51999992e-01])
train_episode: 338
can't receive signals within 60 seconds. let's terminate gym env.
Episode 338: loss is 0.047, rewards is -0.54
Tensor(shape=[1], dtype=Float32, value=[ 4.53333348e-01])
train_episode: 339
At the end, own_hp 270: opp_hp 198. you win.
Episode 339: loss is 0.045, rewards is 6.63
Tensor(shape=[1], dtype=Float32, value=[ 4.54666674e-01])
train_episode: 340
At the end, own_hp 210: opp_hp 211. you lose.
Episode 340: loss is 0.059, rewards is -0.45
0
1
2
evaluate begin
At the end, own_hp 279: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 340 total rewards is -14.887
Tensor(shape=[1], dtype=Float32, value=[ 4.56000030e-01])
-----------------------------------------
train_episode: 341
can't receive signals within 60 seconds. let's terminate gym env.
Episode 341: loss is 0.0, rewards is -0.01
Tensor(shape=[1], dtype=Float32, value=[ 4.57333326e-01])
train_episode: 342
At the end, own_hp 61: opp_hp 153. you lose.
Episode 342: loss is 0.503, rewards is -9.18
Tensor(shape=[1], dtype=Float32, value=[ 4.58666682e-01])
train_episode: 343
can't receive signals within 60 seconds. let's terminate gym env.
Episode 343: loss is 0.174, rewards is -6.33
Tensor(shape=[1], dtype=Float32, value=[ 4.60000008e-01])
train_episode: 344
At the end, own_hp 117: opp_hp 212. you lose.
Episode 344: loss is 0.047, rewards is -9.6
Tensor(shape=[1], dtype=Float32, value=[ 4.61333334e-01])
train_episode: 345
At the end, own_hp 0: opp_hp 380. you lose.
Episode 345: loss is 0.047, rewards is -36.36
Tensor(shape=[1], dtype=Float32, value=[ 4.62666690e-01])
train_episode: 346
At the end, own_hp 117: opp_hp 173. you lose.
Episode 346: loss is 0.008, rewards is -3.55
Tensor(shape=[1], dtype=Float32, value=[ 4.63999987e-01])
train_episode: 347
At the end, own_hp 0: opp_hp 310. you lose.
Episode 347: loss is 0.28, rewards is -29.54
Tensor(shape=[1], dtype=Float32, value=[ 4.65333343e-01])
train_episode: 348
At the end, own_hp 162: opp_hp 225. you lose.
Episode 348: loss is 0.0, rewards is -6.78
Tensor(shape=[1], dtype=Float32, value=[ 4.66666669e-01])
train_episode: 349
can't receive signals within 60 seconds. let's terminate gym env.
Episode 349: loss is 0.078, rewards is -20.67
Tensor(shape=[1], dtype=Float32, value=[ 4.68000025e-01])
train_episode: 350
At the end, own_hp 0: opp_hp 380. you lose.
Episode 350: loss is 0.008, rewards is -36.94
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 51: opp_hp 400. you lose.
At the end, own_hp 300: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 350 total rewards is -14.193
Tensor(shape=[1], dtype=Float32, value=[ 4.69333351e-01])
-----------------------------------------
train_episode: 351
At the end, own_hp 250: opp_hp 255. you lose.
Episode 351: loss is 0.008, rewards is -1.14
Tensor(shape=[1], dtype=Float32, value=[ 4.70666647e-01])
train_episode: 352
can't receive signals within 60 seconds. let's terminate gym env.
Episode 352: loss is 0.445, rewards is 0.15
Tensor(shape=[1], dtype=Float32, value=[ 4.72000003e-01])
train_episode: 353
can't receive signals within 60 seconds. let's terminate gym env.
Episode 353: loss is 0.092, rewards is 0.02
Tensor(shape=[1], dtype=Float32, value=[ 4.73333329e-01])
train_episode: 354
At the end, own_hp 0: opp_hp 385. you lose.
Episode 354: loss is 0.733, rewards is -38.12
Tensor(shape=[1], dtype=Float32, value=[ 4.74666685e-01])
train_episode: 355
can't receive signals within 60 seconds. let's terminate gym env.
Episode 355: loss is 0.016, rewards is -6.88
Tensor(shape=[1], dtype=Float32, value=[ 4.76000011e-01])
train_episode: 356
can't receive signals within 60 seconds. let's terminate gym env.
Episode 356: loss is 0.016, rewards is -6.4
Tensor(shape=[1], dtype=Float32, value=[ 4.77333367e-01])
train_episode: 357
At the end, own_hp 0: opp_hp 305. you lose.
Episode 357: loss is 0.049, rewards is -30.16
Tensor(shape=[1], dtype=Float32, value=[ 4.78666663e-01])
train_episode: 358
At the end, own_hp 0: opp_hp 335. you lose.
Episode 358: loss is 0.039, rewards is -22.99
Tensor(shape=[1], dtype=Float32, value=[ 4.80000019e-01])
train_episode: 359
can't receive signals within 60 seconds. let's terminate gym env.
Episode 359: loss is 0.032, rewards is -1.81
Tensor(shape=[1], dtype=Float32, value=[ 4.81333345e-01])
train_episode: 360
At the end, own_hp 173: opp_hp 235. you lose.
Episode 360: loss is 0.031, rewards is -6.89
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 360 total rewards is -1.100
Tensor(shape=[1], dtype=Float32, value=[ 4.82666671e-01])
-----------------------------------------
train_episode: 361
At the end, own_hp 172: opp_hp 156. you win.
Episode 361: loss is 0.076, rewards is 0.82
Tensor(shape=[1], dtype=Float32, value=[ 4.84000027e-01])
train_episode: 362
At the end, own_hp 175: opp_hp 250. you lose.
Episode 362: loss is 0.312, rewards is -7.88
Tensor(shape=[1], dtype=Float32, value=[ 4.85333323e-01])
train_episode: 363
At the end, own_hp 0: opp_hp 343. you lose.
Episode 363: loss is 0.052, rewards is -27.31
Tensor(shape=[1], dtype=Float32, value=[ 4.86666679e-01])
train_episode: 364
At the end, own_hp 102: opp_hp 103. you lose.
Episode 364: loss is 0.0, rewards is 0.21
Tensor(shape=[1], dtype=Float32, value=[ 4.88000005e-01])
train_episode: 365
At the end, own_hp 160: opp_hp 113. you win.
Episode 365: loss is 0.001, rewards is 1.57
Tensor(shape=[1], dtype=Float32, value=[ 4.89333361e-01])
train_episode: 366
can't receive signals within 60 seconds. let's terminate gym env.
Episode 366: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 4.90666687e-01])
train_episode: 367
can't receive signals within 60 seconds. let's terminate gym env.
Episode 367: loss is 0.473, rewards is -0.57
Tensor(shape=[1], dtype=Float32, value=[ 4.91999984e-01])
train_episode: 368
At the end, own_hp 0: opp_hp 275. you lose.
Episode 368: loss is 0.032, rewards is -27.25
Tensor(shape=[1], dtype=Float32, value=[ 4.93333340e-01])
train_episode: 369
At the end, own_hp 275: opp_hp 278. you lose.
Episode 369: loss is 0.178, rewards is 0.24
Tensor(shape=[1], dtype=Float32, value=[ 4.94666666e-01])
train_episode: 370
At the end, own_hp 185: opp_hp 206. you lose.
Episode 370: loss is 0.0, rewards is -2.38
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 370 total rewards is -20.243
Tensor(shape=[1], dtype=Float32, value=[ 4.96000022e-01])
-----------------------------------------
train_episode: 371
At the end, own_hp 0: opp_hp 385. you lose.
Episode 371: loss is 0.13, rewards is -37.58
Tensor(shape=[1], dtype=Float32, value=[ 4.97333348e-01])
train_episode: 372
At the end, own_hp 0: opp_hp 400. you lose.
Episode 372: loss is 0.167, rewards is -28.46
Tensor(shape=[1], dtype=Float32, value=[ 4.98666704e-01])
train_episode: 373
At the end, own_hp 155: opp_hp 175. you lose.
Episode 373: loss is 0.084, rewards is -2.43
Tensor(shape=[1], dtype=Float32, value=[ 5.00000000e-01])
train_episode: 374
can't receive signals within 60 seconds. let's terminate gym env.
Episode 374: loss is 0.083, rewards is -6.02
Tensor(shape=[1], dtype=Float32, value=[ 5.01333356e-01])
train_episode: 375
At the end, own_hp 120: opp_hp 160. you lose.
Episode 375: loss is 0.043, rewards is -4.77
Tensor(shape=[1], dtype=Float32, value=[ 5.02666712e-01])
train_episode: 376
can't receive signals within 60 seconds. let's terminate gym env.
Episode 376: loss is 0.059, rewards is -28.02
Tensor(shape=[1], dtype=Float32, value=[ 5.04000008e-01])
train_episode: 377
At the end, own_hp 205: opp_hp 265. you lose.
Episode 377: loss is 0.502, rewards is -6.86
Tensor(shape=[1], dtype=Float32, value=[ 5.05333364e-01])
train_episode: 378
At the end, own_hp 172: opp_hp 257. you lose.
Episode 378: loss is 0.0, rewards is -8.5
Tensor(shape=[1], dtype=Float32, value=[ 5.06666660e-01])
train_episode: 379
At the end, own_hp 0: opp_hp 390. you lose.
Episode 379: loss is 0.067, rewards is -37.9
Tensor(shape=[1], dtype=Float32, value=[ 5.08000016e-01])
train_episode: 380
At the end, own_hp 0: opp_hp 325. you lose.
Episode 380: loss is 0.08, rewards is -31.08
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 380 total rewards is -0.020
Tensor(shape=[1], dtype=Float32, value=[ 5.09333372e-01])
-----------------------------------------
train_episode: 381
At the end, own_hp 240: opp_hp 176. you win.
Episode 381: loss is 0.028, rewards is 6.89
Tensor(shape=[1], dtype=Float32, value=[ 5.10666668e-01])
train_episode: 382
At the end, own_hp 240: opp_hp 262. you lose.
Episode 382: loss is 0.384, rewards is -2.46
Tensor(shape=[1], dtype=Float32, value=[ 5.12000024e-01])
train_episode: 383
At the end, own_hp 290: opp_hp 227. you win.
Episode 383: loss is 0.048, rewards is 2.65
Tensor(shape=[1], dtype=Float32, value=[ 5.13333321e-01])
train_episode: 384
At the end, own_hp 0: opp_hp 270. you lose.
Episode 384: loss is 0.068, rewards is -25.97
Tensor(shape=[1], dtype=Float32, value=[ 5.14666677e-01])
train_episode: 385
At the end, own_hp 155: opp_hp 175. you lose.
Episode 385: loss is 0.008, rewards is -1.93
Tensor(shape=[1], dtype=Float32, value=[ 5.16000032e-01])
train_episode: 386
At the end, own_hp 0: opp_hp 385. you lose.
Episode 386: loss is 0.711, rewards is -37.67
Tensor(shape=[1], dtype=Float32, value=[ 5.17333388e-01])
train_episode: 387
At the end, own_hp 0: opp_hp 385. you lose.
Episode 387: loss is 0.008, rewards is -30.04
Tensor(shape=[1], dtype=Float32, value=[ 5.18666685e-01])
train_episode: 388
can't receive signals within 60 seconds. let's terminate gym env.
Episode 388: loss is 0.008, rewards is -1.88
Tensor(shape=[1], dtype=Float32, value=[ 5.19999981e-01])
train_episode: 389
At the end, own_hp 245: opp_hp 305. you lose.
Episode 389: loss is 0.515, rewards is -7.56
Tensor(shape=[1], dtype=Float32, value=[ 5.21333337e-01])
train_episode: 390
At the end, own_hp 235: opp_hp 289. you lose.
Episode 390: loss is 0.008, rewards is -5.45
0
1
2
evaluate begin
At the end, own_hp 206: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 390 total rewards is -6.070
Tensor(shape=[1], dtype=Float32, value=[ 5.22666693e-01])
-----------------------------------------
train_episode: 391
At the end, own_hp 0: opp_hp 400. you lose.
Episode 391: loss is 0.032, rewards is -37.94
Tensor(shape=[1], dtype=Float32, value=[ 5.24000049e-01])
train_episode: 392
can't receive signals within 60 seconds. let's terminate gym env.
Episode 392: loss is 0.193, rewards is -1.99
Tensor(shape=[1], dtype=Float32, value=[ 5.25333345e-01])
train_episode: 393
can't receive signals within 60 seconds. let's terminate gym env.
Episode 393: loss is 0.241, rewards is -10.49
Tensor(shape=[1], dtype=Float32, value=[ 5.26666701e-01])
train_episode: 394
can't receive signals within 60 seconds. let's terminate gym env.
Episode 394: loss is 0.033, rewards is 0.05
Tensor(shape=[1], dtype=Float32, value=[ 5.27999997e-01])
train_episode: 395
At the end, own_hp 165: opp_hp 182. you lose.
Episode 395: loss is 0.178, rewards is -1.98
Tensor(shape=[1], dtype=Float32, value=[ 5.29333353e-01])
train_episode: 396
At the end, own_hp 0: opp_hp 342. you lose.
Episode 396: loss is 0.244, rewards is -25.19
Tensor(shape=[1], dtype=Float32, value=[ 5.30666709e-01])
train_episode: 397
At the end, own_hp 240: opp_hp 247. you lose.
Episode 397: loss is 0.078, rewards is -0.78
Tensor(shape=[1], dtype=Float32, value=[ 5.32000005e-01])
train_episode: 398
At the end, own_hp 207: opp_hp 255. you lose.
Episode 398: loss is 0.163, rewards is -5.37
Tensor(shape=[1], dtype=Float32, value=[ 5.33333361e-01])
train_episode: 399
At the end, own_hp 0: opp_hp 385. you lose.
Episode 399: loss is 0.008, rewards is -26.76
Tensor(shape=[1], dtype=Float32, value=[ 5.34666657e-01])
train_episode: 400
At the end, own_hp 0: opp_hp 390. you lose.
Episode 400: loss is 0.457, rewards is -38.04
0
1
2
evaluate begin
At the end, own_hp 22: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 45: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 400 total rewards is -22.547
Tensor(shape=[1], dtype=Float32, value=[ 5.36000013e-01])
-----------------------------------------
train_episode: 401
can't receive signals within 60 seconds. let's terminate gym env.
Episode 401: loss is 0.158, rewards is -20.95
Tensor(shape=[1], dtype=Float32, value=[ 5.37333369e-01])
train_episode: 402
can't receive signals within 60 seconds. let's terminate gym env.
Episode 402: loss is 0.008, rewards is -0.96
Tensor(shape=[1], dtype=Float32, value=[ 5.38666725e-01])
train_episode: 403
can't receive signals within 60 seconds. let's terminate gym env.
Episode 403: loss is 4.536, rewards is 0.02
Tensor(shape=[1], dtype=Float32, value=[ 5.40000021e-01])
train_episode: 404
At the end, own_hp 0: opp_hp 358. you lose.
Episode 404: loss is 0.538, rewards is -34.79
Tensor(shape=[1], dtype=Float32, value=[ 5.41333318e-01])
train_episode: 405
At the end, own_hp 165: opp_hp 259. you lose.
Episode 405: loss is 0.125, rewards is -10.31
Tensor(shape=[1], dtype=Float32, value=[ 5.42666674e-01])
train_episode: 406
At the end, own_hp 132: opp_hp 122. you win.
Episode 406: loss is 0.009, rewards is 0.4
Tensor(shape=[1], dtype=Float32, value=[ 5.44000030e-01])
train_episode: 407
At the end, own_hp 125: opp_hp 207. you lose.
Episode 407: loss is 0.015, rewards is -8.35
Tensor(shape=[1], dtype=Float32, value=[ 5.45333385e-01])
train_episode: 408
At the end, own_hp 0: opp_hp 365. you lose.
Episode 408: loss is 0.03, rewards is -35.9
Tensor(shape=[1], dtype=Float32, value=[ 5.46666682e-01])
train_episode: 409
At the end, own_hp 0: opp_hp 356. you lose.
Episode 409: loss is 0.539, rewards is -24.99
Tensor(shape=[1], dtype=Float32, value=[ 5.48000038e-01])
train_episode: 410
At the end, own_hp 0: opp_hp 322. you lose.
Episode 410: loss is 0.0, rewards is -29.87
0
1
2
evaluate begin
At the end, own_hp 267: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 410 total rewards is -4.010
Tensor(shape=[1], dtype=Float32, value=[ 5.49333334e-01])
-----------------------------------------
train_episode: 411
At the end, own_hp 115: opp_hp 181. you lose.
Episode 411: loss is 0.71, rewards is -6.61
Tensor(shape=[1], dtype=Float32, value=[ 5.50666690e-01])
train_episode: 412
can't receive signals within 60 seconds. let's terminate gym env.
Episode 412: loss is 0.126, rewards is 0.19
Tensor(shape=[1], dtype=Float32, value=[ 5.52000046e-01])
train_episode: 413
can't receive signals within 60 seconds. let's terminate gym env.
Episode 413: loss is 0.069, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 5.53333342e-01])
train_episode: 414
At the end, own_hp 0: opp_hp 355. you lose.
Episode 414: loss is 0.122, rewards is -33.03
Tensor(shape=[1], dtype=Float32, value=[ 5.54666698e-01])
train_episode: 415
At the end, own_hp 0: opp_hp 372. you lose.
Episode 415: loss is 0.106, rewards is -35.93
Tensor(shape=[1], dtype=Float32, value=[ 5.55999994e-01])
train_episode: 416
can't receive signals within 60 seconds. let's terminate gym env.
Episode 416: loss is 0.08, rewards is 0.13
Tensor(shape=[1], dtype=Float32, value=[ 5.57333350e-01])
train_episode: 417
At the end, own_hp 0: opp_hp 375. you lose.
Episode 417: loss is 0.471, rewards is -36.21
Tensor(shape=[1], dtype=Float32, value=[ 5.58666706e-01])
train_episode: 418
can't receive signals within 60 seconds. let's terminate gym env.
Episode 418: loss is 0.048, rewards is -4.51
Tensor(shape=[1], dtype=Float32, value=[ 5.60000002e-01])
train_episode: 419
At the end, own_hp 250: opp_hp 205. you win.
Episode 419: loss is 0.046, rewards is 1.81
Tensor(shape=[1], dtype=Float32, value=[ 5.61333358e-01])
train_episode: 420
can't receive signals within 60 seconds. let's terminate gym env.
Episode 420: loss is 0.094, rewards is 1.5
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 420 total rewards is 0.070
Tensor(shape=[1], dtype=Float32, value=[ 5.62666655e-01])
-----------------------------------------
train_episode: 421
At the end, own_hp 0: opp_hp 313. you lose.
Episode 421: loss is 0.031, rewards is -20.06
Tensor(shape=[1], dtype=Float32, value=[ 5.64000010e-01])
train_episode: 422
At the end, own_hp 182: opp_hp 124. you win.
Episode 422: loss is 0.008, rewards is 3.23
Tensor(shape=[1], dtype=Float32, value=[ 5.65333366e-01])
train_episode: 423
At the end, own_hp 165: opp_hp 168. you lose.
Episode 423: loss is 0.001, rewards is -0.26
Tensor(shape=[1], dtype=Float32, value=[ 5.66666722e-01])
train_episode: 424
can't receive signals within 60 seconds. let's terminate gym env.
Episode 424: loss is 0.0, rewards is -6.5
Tensor(shape=[1], dtype=Float32, value=[ 5.68000019e-01])
train_episode: 425
At the end, own_hp 190: opp_hp 190. you lose.
Episode 425: loss is 0.0, rewards is -0.8
Tensor(shape=[1], dtype=Float32, value=[ 5.69333315e-01])
train_episode: 426
At the end, own_hp 125: opp_hp 154. you lose.
Episode 426: loss is 0.15, rewards is -4.19
Tensor(shape=[1], dtype=Float32, value=[ 5.70666671e-01])
train_episode: 427
At the end, own_hp 119: opp_hp 93. you win.
Episode 427: loss is 0.185, rewards is 1.99
Tensor(shape=[1], dtype=Float32, value=[ 5.72000027e-01])
train_episode: 428
can't receive signals within 60 seconds. let's terminate gym env.
Episode 428: loss is 0.171, rewards is 0.08
Tensor(shape=[1], dtype=Float32, value=[ 5.73333383e-01])
train_episode: 429
At the end, own_hp 0: opp_hp 375. you lose.
Episode 429: loss is 0.249, rewards is -29.58
Tensor(shape=[1], dtype=Float32, value=[ 5.74666679e-01])
train_episode: 430
At the end, own_hp 0: opp_hp 245. you lose.
Episode 430: loss is 0.406, rewards is -24.23
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 430 total rewards is -0.090
Tensor(shape=[1], dtype=Float32, value=[ 5.76000035e-01])
-----------------------------------------
train_episode: 431
At the end, own_hp 165: opp_hp 221. you lose.
Episode 431: loss is 0.052, rewards is -5.99
Tensor(shape=[1], dtype=Float32, value=[ 5.77333331e-01])
train_episode: 432
At the end, own_hp 0: opp_hp 395. you lose.
Episode 432: loss is 0.0, rewards is -36.35
Tensor(shape=[1], dtype=Float32, value=[ 5.78666687e-01])
train_episode: 433
can't receive signals within 60 seconds. let's terminate gym env.
Episode 433: loss is 0.071, rewards is 0.01
Tensor(shape=[1], dtype=Float32, value=[ 5.80000043e-01])
train_episode: 434
can't receive signals within 60 seconds. let's terminate gym env.
Episode 434: loss is 0.045, rewards is 0.02
Tensor(shape=[1], dtype=Float32, value=[ 5.81333339e-01])
train_episode: 435
At the end, own_hp 0: opp_hp 400. you lose.
Episode 435: loss is 0.158, rewards is -30.84
Tensor(shape=[1], dtype=Float32, value=[ 5.82666695e-01])
train_episode: 436
can't receive signals within 60 seconds. let's terminate gym env.
Episode 436: loss is 0.632, rewards is -9.66
Tensor(shape=[1], dtype=Float32, value=[ 5.83999991e-01])
train_episode: 437
At the end, own_hp 150: opp_hp 102. you win.
Episode 437: loss is 0.0, rewards is 4.29
Tensor(shape=[1], dtype=Float32, value=[ 5.85333347e-01])
train_episode: 438
At the end, own_hp 295: opp_hp 299. you lose.
Episode 438: loss is 0.0, rewards is -0.86
Tensor(shape=[1], dtype=Float32, value=[ 5.86666703e-01])
train_episode: 439
At the end, own_hp 178: opp_hp 250. you lose.
Episode 439: loss is 0.038, rewards is -6.75
Tensor(shape=[1], dtype=Float32, value=[ 5.88000059e-01])
train_episode: 440
can't receive signals within 60 seconds. let's terminate gym env.
Episode 440: loss is 0.0, rewards is -0.04
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 440 total rewards is -24.207
Tensor(shape=[1], dtype=Float32, value=[ 5.89333355e-01])
-----------------------------------------
train_episode: 441
can't receive signals within 60 seconds. let's terminate gym env.
Episode 441: loss is 0.016, rewards is -1.03
Tensor(shape=[1], dtype=Float32, value=[ 5.90666652e-01])
train_episode: 442
can't receive signals within 60 seconds. let's terminate gym env.
Episode 442: loss is 0.532, rewards is -4.16
Tensor(shape=[1], dtype=Float32, value=[ 5.92000008e-01])
train_episode: 443
can't receive signals within 60 seconds. let's terminate gym env.
Episode 443: loss is 0.223, rewards is -0.11
Tensor(shape=[1], dtype=Float32, value=[ 5.93333364e-01])
train_episode: 444
can't receive signals within 60 seconds. let's terminate gym env.
Episode 444: loss is 0.73, rewards is 0.01
Tensor(shape=[1], dtype=Float32, value=[ 5.94666719e-01])
train_episode: 445
can't receive signals within 60 seconds. let's terminate gym env.
Episode 445: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 5.96000016e-01])
train_episode: 446
At the end, own_hp 0: opp_hp 380. you lose.
Episode 446: loss is 0.009, rewards is -36.63
Tensor(shape=[1], dtype=Float32, value=[ 5.97333372e-01])
train_episode: 447
At the end, own_hp 0: opp_hp 385. you lose.
Episode 447: loss is 0.173, rewards is -38.11
Tensor(shape=[1], dtype=Float32, value=[ 5.98666668e-01])
train_episode: 448
can't receive signals within 60 seconds. let's terminate gym env.
Episode 448: loss is 0.066, rewards is 2.39
Tensor(shape=[1], dtype=Float32, value=[ 6.00000024e-01])
train_episode: 449
At the end, own_hp 85: opp_hp 0. you win.
Episode 449: loss is 0.273, rewards is 6.76
Tensor(shape=[1], dtype=Float32, value=[ 6.01333380e-01])
train_episode: 450
At the end, own_hp 235: opp_hp 250. you lose.
Episode 450: loss is 0.24, rewards is -2.07
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 450 total rewards is -12.650
Tensor(shape=[1], dtype=Float32, value=[ 6.02666676e-01])
-----------------------------------------
train_episode: 451
At the end, own_hp 240: opp_hp 235. you win.
Episode 451: loss is 0.576, rewards is -0.1
Tensor(shape=[1], dtype=Float32, value=[ 6.04000032e-01])
train_episode: 452
can't receive signals within 60 seconds. let's terminate gym env.
Episode 452: loss is 0.008, rewards is -35.14
Tensor(shape=[1], dtype=Float32, value=[ 6.05333328e-01])
train_episode: 453
can't receive signals within 60 seconds. let's terminate gym env.
Episode 453: loss is 0.098, rewards is -0.94
Tensor(shape=[1], dtype=Float32, value=[ 6.06666684e-01])
train_episode: 454
can't receive signals within 60 seconds. let's terminate gym env.
Episode 454: loss is 0.12, rewards is -0.05
Tensor(shape=[1], dtype=Float32, value=[ 6.08000040e-01])
train_episode: 455
At the end, own_hp 167: opp_hp 207. you lose.
Episode 455: loss is 0.039, rewards is -3.65
Tensor(shape=[1], dtype=Float32, value=[ 6.09333336e-01])
train_episode: 456
At the end, own_hp 135: opp_hp 130. you win.
Episode 456: loss is 0.499, rewards is 0.38
Tensor(shape=[1], dtype=Float32, value=[ 6.10666692e-01])
train_episode: 457
At the end, own_hp 165: opp_hp 195. you lose.
Episode 457: loss is 0.508, rewards is -3.22
Tensor(shape=[1], dtype=Float32, value=[ 6.11999989e-01])
train_episode: 458
At the end, own_hp 190: opp_hp 255. you lose.
Episode 458: loss is 0.053, rewards is -7.32
Tensor(shape=[1], dtype=Float32, value=[ 6.13333344e-01])
train_episode: 459
At the end, own_hp 198: opp_hp 204. you lose.
Episode 459: loss is 0.262, rewards is -0.39
Tensor(shape=[1], dtype=Float32, value=[ 6.14666700e-01])
train_episode: 460
At the end, own_hp 150: opp_hp 246. you lose.
Episode 460: loss is 0.044, rewards is -11.08
0
1
2
evaluate begin
At the end, own_hp 309: opp_hp 400. you lose.
At the end, own_hp 210: opp_hp 400. you lose.
At the end, own_hp 3: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 460 total rewards is -18.997
Tensor(shape=[1], dtype=Float32, value=[ 6.16000056e-01])
-----------------------------------------
train_episode: 461
At the end, own_hp 187: opp_hp 140. you win.
Episode 461: loss is 0.008, rewards is 4.86
Tensor(shape=[1], dtype=Float32, value=[ 6.17333353e-01])
train_episode: 462
At the end, own_hp 0: opp_hp 333. you lose.
Episode 462: loss is 4.17, rewards is -32.57
Tensor(shape=[1], dtype=Float32, value=[ 6.18666649e-01])
train_episode: 463
can't receive signals within 60 seconds. let's terminate gym env.
Episode 463: loss is 0.039, rewards is -8.38
Tensor(shape=[1], dtype=Float32, value=[ 6.20000005e-01])
train_episode: 464
At the end, own_hp 85: opp_hp 182. you lose.
Episode 464: loss is 0.031, rewards is -10.53
Tensor(shape=[1], dtype=Float32, value=[ 6.21333361e-01])
train_episode: 465
At the end, own_hp 0: opp_hp 355. you lose.
Episode 465: loss is 0.141, rewards is -34.48
Tensor(shape=[1], dtype=Float32, value=[ 6.22666717e-01])
train_episode: 466
At the end, own_hp 0: opp_hp 395. you lose.
Episode 466: loss is 0.168, rewards is -39.0
Tensor(shape=[1], dtype=Float32, value=[ 6.24000013e-01])
train_episode: 467
At the end, own_hp 0: opp_hp 385. you lose.
Episode 467: loss is 0.008, rewards is -36.5
Tensor(shape=[1], dtype=Float32, value=[ 6.25333369e-01])
train_episode: 468
At the end, own_hp 0: opp_hp 365. you lose.
Episode 468: loss is 0.063, rewards is -35.45
Tensor(shape=[1], dtype=Float32, value=[ 6.26666665e-01])
train_episode: 469
At the end, own_hp 0: opp_hp 330. you lose.
Episode 469: loss is 0.0, rewards is -31.93
Tensor(shape=[1], dtype=Float32, value=[ 6.28000021e-01])
train_episode: 470
At the end, own_hp 0: opp_hp 358. you lose.
Episode 470: loss is 0.008, rewards is -34.23
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 470 total rewards is -0.887
Tensor(shape=[1], dtype=Float32, value=[ 6.29333377e-01])
-----------------------------------------
train_episode: 471
At the end, own_hp 0: opp_hp 345. you lose.
Episode 471: loss is 0.048, rewards is -32.7
Tensor(shape=[1], dtype=Float32, value=[ 6.30666673e-01])
train_episode: 472
At the end, own_hp 220: opp_hp 136. you win.
Episode 472: loss is 0.252, rewards is 10.98
Tensor(shape=[1], dtype=Float32, value=[ 6.32000029e-01])
train_episode: 473
At the end, own_hp 0: opp_hp 208. you lose.
Episode 473: loss is 0.047, rewards is -12.84
Tensor(shape=[1], dtype=Float32, value=[ 6.33333325e-01])
train_episode: 474
At the end, own_hp 0: opp_hp 345. you lose.
Episode 474: loss is 0.039, rewards is -25.31
Tensor(shape=[1], dtype=Float32, value=[ 6.34666681e-01])
train_episode: 475
At the end, own_hp 0: opp_hp 385. you lose.
Episode 475: loss is 0.214, rewards is -37.96
Tensor(shape=[1], dtype=Float32, value=[ 6.36000037e-01])
train_episode: 476
can't receive signals within 60 seconds. let's terminate gym env.
Episode 476: loss is 0.169, rewards is -3.68
Tensor(shape=[1], dtype=Float32, value=[ 6.37333333e-01])
train_episode: 477
can't receive signals within 60 seconds. let's terminate gym env.
Episode 477: loss is 0.05, rewards is -0.21
Tensor(shape=[1], dtype=Float32, value=[ 6.38666689e-01])
train_episode: 478
At the end, own_hp 0: opp_hp 385. you lose.
Episode 478: loss is 0.0, rewards is -38.36
Tensor(shape=[1], dtype=Float32, value=[ 6.39999986e-01])
train_episode: 479
At the end, own_hp 142: opp_hp 129. you win.
Episode 479: loss is 0.008, rewards is 2.08
Tensor(shape=[1], dtype=Float32, value=[ 6.41333342e-01])
train_episode: 480
At the end, own_hp 75: opp_hp 193. you lose.
Episode 480: loss is 0.145, rewards is -11.34
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 270: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 480 total rewards is -27.093
Tensor(shape=[1], dtype=Float32, value=[ 6.42666698e-01])
-----------------------------------------
train_episode: 481
At the end, own_hp 143: opp_hp 225. you lose.
Episode 481: loss is 0.077, rewards is -9.0
Tensor(shape=[1], dtype=Float32, value=[ 6.44000053e-01])
train_episode: 482
At the end, own_hp 115: opp_hp 180. you lose.
Episode 482: loss is 0.008, rewards is -7.25
Tensor(shape=[1], dtype=Float32, value=[ 6.45333350e-01])
train_episode: 483
At the end, own_hp 0: opp_hp 360. you lose.
Episode 483: loss is 0.09, rewards is -35.55
Tensor(shape=[1], dtype=Float32, value=[ 6.46666706e-01])
train_episode: 484
At the end, own_hp 0: opp_hp 380. you lose.
Episode 484: loss is 0.031, rewards is -31.84
Tensor(shape=[1], dtype=Float32, value=[ 6.48000002e-01])
train_episode: 485
At the end, own_hp 265: opp_hp 189. you win.
Episode 485: loss is 0.246, rewards is 4.75
Tensor(shape=[1], dtype=Float32, value=[ 6.49333358e-01])
train_episode: 486
At the end, own_hp 200: opp_hp 298. you lose.
Episode 486: loss is 0.274, rewards is -10.56
Tensor(shape=[1], dtype=Float32, value=[ 6.50666714e-01])
train_episode: 487
At the end, own_hp 0: opp_hp 358. you lose.
Episode 487: loss is 0.5, rewards is -34.07
Tensor(shape=[1], dtype=Float32, value=[ 6.52000010e-01])
train_episode: 488
can't receive signals within 60 seconds. let's terminate gym env.
Episode 488: loss is 0.093, rewards is 0.44
Tensor(shape=[1], dtype=Float32, value=[ 6.53333366e-01])
train_episode: 489
At the end, own_hp 223: opp_hp 166. you win.
Episode 489: loss is 0.0, rewards is 5.59
Tensor(shape=[1], dtype=Float32, value=[ 6.54666662e-01])
train_episode: 490
At the end, own_hp 0: opp_hp 235. you lose.
Episode 490: loss is 0.155, rewards is -12.58
0
1
2
evaluate begin
At the end, own_hp 307: opp_hp 400. you lose.
At the end, own_hp 297: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 490 total rewards is -16.243
Tensor(shape=[1], dtype=Float32, value=[ 6.56000018e-01])
-----------------------------------------
train_episode: 491
At the end, own_hp 0: opp_hp 295. you lose.
Episode 491: loss is 0.021, rewards is -28.47
Tensor(shape=[1], dtype=Float32, value=[ 6.57333374e-01])
train_episode: 492
At the end, own_hp 0: opp_hp 332. you lose.
Episode 492: loss is 0.149, rewards is -34.25
Tensor(shape=[1], dtype=Float32, value=[ 6.58666670e-01])
train_episode: 493
can't receive signals within 60 seconds. let's terminate gym env.
Episode 493: loss is 0.156, rewards is -0.75
Tensor(shape=[1], dtype=Float32, value=[ 6.60000026e-01])
train_episode: 494
At the end, own_hp 0: opp_hp 350. you lose.
Episode 494: loss is 0.056, rewards is -23.31
Tensor(shape=[1], dtype=Float32, value=[ 6.61333323e-01])
train_episode: 495
At the end, own_hp 0: opp_hp 380. you lose.
Episode 495: loss is 0.054, rewards is -36.26
Tensor(shape=[1], dtype=Float32, value=[ 6.62666678e-01])
train_episode: 496
At the end, own_hp 114: opp_hp 228. you lose.
Episode 496: loss is 0.007, rewards is -12.87
Tensor(shape=[1], dtype=Float32, value=[ 6.64000034e-01])
train_episode: 497
At the end, own_hp 0: opp_hp 390. you lose.
Episode 497: loss is 0.0, rewards is -34.58
Tensor(shape=[1], dtype=Float32, value=[ 6.65333390e-01])
train_episode: 498
can't receive signals within 60 seconds. let's terminate gym env.
Episode 498: loss is 0.033, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 6.66666687e-01])
train_episode: 499
can't receive signals within 60 seconds. let's terminate gym env.
Episode 499: loss is 0.053, rewards is 0.93
Tensor(shape=[1], dtype=Float32, value=[ 6.67999983e-01])
train_episode: 500
can't receive signals within 60 seconds. let's terminate gym env.
Episode 500: loss is 0.038, rewards is 2.72
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 1: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 500 total rewards is -23.623
Tensor(shape=[1], dtype=Float32, value=[ 6.69333339e-01])
-----------------------------------------
train_episode: 501
can't receive signals within 60 seconds. let's terminate gym env.
Episode 501: loss is 0.123, rewards is 1.22
Tensor(shape=[1], dtype=Float32, value=[ 6.70666695e-01])
train_episode: 502
At the end, own_hp 258: opp_hp 161. you win.
Episode 502: loss is 0.02, rewards is 9.62
Tensor(shape=[1], dtype=Float32, value=[ 6.72000051e-01])
train_episode: 503
can't receive signals within 60 seconds. let's terminate gym env.
Episode 503: loss is 0.043, rewards is -2.9
Tensor(shape=[1], dtype=Float32, value=[ 6.73333347e-01])
train_episode: 504
At the end, own_hp 227: opp_hp 203. you win.
Episode 504: loss is 0.151, rewards is 1.33
Tensor(shape=[1], dtype=Float32, value=[ 6.74666643e-01])
train_episode: 505
At the end, own_hp 0: opp_hp 285. you lose.
Episode 505: loss is 0.082, rewards is -27.68
Tensor(shape=[1], dtype=Float32, value=[ 6.76000059e-01])
train_episode: 506
At the end, own_hp 180: opp_hp 300. you lose.
Episode 506: loss is 0.008, rewards is -11.37
Tensor(shape=[1], dtype=Float32, value=[ 6.77333355e-01])
train_episode: 507
At the end, own_hp 250: opp_hp 247. you win.
Episode 507: loss is 0.031, rewards is 0.69
Tensor(shape=[1], dtype=Float32, value=[ 6.78666711e-01])
train_episode: 508
At the end, own_hp 242: opp_hp 195. you win.
Episode 508: loss is 0.048, rewards is 2.1
Tensor(shape=[1], dtype=Float32, value=[ 6.80000007e-01])
train_episode: 509
At the end, own_hp 150: opp_hp 108. you win.
Episode 509: loss is 0.236, rewards is 4.83
Tensor(shape=[1], dtype=Float32, value=[ 6.81333303e-01])
train_episode: 510
At the end, own_hp 183: opp_hp 229. you lose.
Episode 510: loss is 0.041, rewards is -4.65
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 510 total rewards is -24.750
Tensor(shape=[1], dtype=Float32, value=[ 6.82666719e-01])
-----------------------------------------
train_episode: 511
can't receive signals within 60 seconds. let's terminate gym env.
Episode 511: loss is 0.008, rewards is -20.67
Tensor(shape=[1], dtype=Float32, value=[ 6.84000015e-01])
train_episode: 512
can't receive signals within 60 seconds. let's terminate gym env.
Episode 512: loss is 0.134, rewards is 0.08
Tensor(shape=[1], dtype=Float32, value=[ 6.85333371e-01])
train_episode: 513
At the end, own_hp 222: opp_hp 215. you win.
Episode 513: loss is 0.045, rewards is 0.71
Tensor(shape=[1], dtype=Float32, value=[ 6.86666667e-01])
train_episode: 514
At the end, own_hp 215: opp_hp 287. you lose.
Episode 514: loss is 0.032, rewards is -6.73
Tensor(shape=[1], dtype=Float32, value=[ 6.87999964e-01])
train_episode: 515
At the end, own_hp 0: opp_hp 362. you lose.
Episode 515: loss is 0.0, rewards is -35.62
Tensor(shape=[1], dtype=Float32, value=[ 6.89333379e-01])
train_episode: 516
can't receive signals within 60 seconds. let's terminate gym env.
Episode 516: loss is 0.047, rewards is 1.52
Tensor(shape=[1], dtype=Float32, value=[ 6.90666676e-01])
train_episode: 517
At the end, own_hp 174: opp_hp 198. you lose.
Episode 517: loss is 0.04, rewards is -2.35
Tensor(shape=[1], dtype=Float32, value=[ 6.92000031e-01])
train_episode: 518
At the end, own_hp 207: opp_hp 335. you lose.
Episode 518: loss is 0.161, rewards is -14.25
Tensor(shape=[1], dtype=Float32, value=[ 6.93333328e-01])
train_episode: 519
At the end, own_hp 0: opp_hp 395. you lose.
Episode 519: loss is 0.0, rewards is -35.25
Tensor(shape=[1], dtype=Float32, value=[ 6.94666743e-01])
train_episode: 520
At the end, own_hp 0: opp_hp 385. you lose.
Episode 520: loss is 0.111, rewards is -37.51
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 520 total rewards is 0.360
Tensor(shape=[1], dtype=Float32, value=[ 6.96000040e-01])
-----------------------------------------
train_episode: 521
At the end, own_hp 235: opp_hp 270. you lose.
Episode 521: loss is 0.339, rewards is -3.53
Tensor(shape=[1], dtype=Float32, value=[ 6.97333336e-01])
train_episode: 522
At the end, own_hp 175: opp_hp 238. you lose.
Episode 522: loss is 0.0, rewards is -3.97
Tensor(shape=[1], dtype=Float32, value=[ 6.98666692e-01])
train_episode: 523
At the end, own_hp 0: opp_hp 339. you lose.
Episode 523: loss is 0.054, rewards is -32.18
Tensor(shape=[1], dtype=Float32, value=[ 6.99999988e-01])
train_episode: 524
At the end, own_hp 0: opp_hp 365. you lose.
Episode 524: loss is 0.077, rewards is -35.37
Tensor(shape=[1], dtype=Float32, value=[ 7.01333404e-01])
train_episode: 525
At the end, own_hp 260: opp_hp 277. you lose.
Episode 525: loss is 0.008, rewards is -2.87
Tensor(shape=[1], dtype=Float32, value=[ 7.02666700e-01])
train_episode: 526
can't receive signals within 60 seconds. let's terminate gym env.
Episode 526: loss is 0.196, rewards is -5.4
Tensor(shape=[1], dtype=Float32, value=[ 7.03999996e-01])
train_episode: 527
At the end, own_hp 0: opp_hp 343. you lose.
Episode 527: loss is 0.0, rewards is -33.08
Tensor(shape=[1], dtype=Float32, value=[ 7.05333352e-01])
train_episode: 528
At the end, own_hp 260: opp_hp 290. you lose.
Episode 528: loss is 0.0, rewards is -2.38
Tensor(shape=[1], dtype=Float32, value=[ 7.06666648e-01])
train_episode: 529
At the end, own_hp 0: opp_hp 285. you lose.
Episode 529: loss is 0.031, rewards is -17.73
Tensor(shape=[1], dtype=Float32, value=[ 7.08000064e-01])
train_episode: 530
At the end, own_hp 0: opp_hp 185. you lose.
Episode 530: loss is 0.059, rewards is -17.61
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 530 total rewards is -11.993
Tensor(shape=[1], dtype=Float32, value=[ 7.09333360e-01])
-----------------------------------------
train_episode: 531
At the end, own_hp 155: opp_hp 207. you lose.
Episode 531: loss is 0.0, rewards is -5.82
Tensor(shape=[1], dtype=Float32, value=[ 7.10666656e-01])
train_episode: 532
At the end, own_hp 0: opp_hp 345. you lose.
Episode 532: loss is 0.0, rewards is -33.46
Tensor(shape=[1], dtype=Float32, value=[ 7.12000012e-01])
train_episode: 533
At the end, own_hp 200: opp_hp 143. you win.
Episode 533: loss is 0.498, rewards is 6.82
Tensor(shape=[1], dtype=Float32, value=[ 7.13333368e-01])
train_episode: 534
can't receive signals within 60 seconds. let's terminate gym env.
Episode 534: loss is 0.13, rewards is 0.93
Tensor(shape=[1], dtype=Float32, value=[ 7.14666724e-01])
train_episode: 535
can't receive signals within 60 seconds. let's terminate gym env.
Episode 535: loss is 0.04, rewards is -0.02
Tensor(shape=[1], dtype=Float32, value=[ 7.16000021e-01])
train_episode: 536
At the end, own_hp 0: opp_hp 363. you lose.
Episode 536: loss is 0.142, rewards is -35.98
Tensor(shape=[1], dtype=Float32, value=[ 7.17333317e-01])
train_episode: 537
At the end, own_hp 0: opp_hp 345. you lose.
Episode 537: loss is 0.008, rewards is -32.46
Tensor(shape=[1], dtype=Float32, value=[ 7.18666673e-01])
train_episode: 538
At the end, own_hp 0: opp_hp 325. you lose.
Episode 538: loss is 0.131, rewards is -28.28
Tensor(shape=[1], dtype=Float32, value=[ 7.20000029e-01])
train_episode: 539
At the end, own_hp 0: opp_hp 330. you lose.
Episode 539: loss is 0.007, rewards is -28.64
Tensor(shape=[1], dtype=Float32, value=[ 7.21333385e-01])
train_episode: 540
At the end, own_hp 247: opp_hp 218. you win.
Episode 540: loss is 0.001, rewards is 4.63
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 225: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 540 total rewards is -6.993
Tensor(shape=[1], dtype=Float32, value=[ 7.22666681e-01])
-----------------------------------------
train_episode: 541
At the end, own_hp 180: opp_hp 125. you win.
Episode 541: loss is 0.04, rewards is 5.74
Tensor(shape=[1], dtype=Float32, value=[ 7.23999977e-01])
train_episode: 542
At the end, own_hp 0: opp_hp 365. you lose.
Episode 542: loss is 0.008, rewards is -34.87
Tensor(shape=[1], dtype=Float32, value=[ 7.25333393e-01])
train_episode: 543
At the end, own_hp 0: opp_hp 370. you lose.
Episode 543: loss is 0.26, rewards is -35.06
Tensor(shape=[1], dtype=Float32, value=[ 7.26666689e-01])
train_episode: 544
At the end, own_hp 215: opp_hp 137. you win.
Episode 544: loss is 0.0, rewards is 8.44
Tensor(shape=[1], dtype=Float32, value=[ 7.28000045e-01])
train_episode: 545
At the end, own_hp 0: opp_hp 318. you lose.
Episode 545: loss is 0.167, rewards is -30.03
Tensor(shape=[1], dtype=Float32, value=[ 7.29333341e-01])
train_episode: 546
At the end, own_hp 195: opp_hp 246. you lose.
Episode 546: loss is 0.12, rewards is -4.87
Tensor(shape=[1], dtype=Float32, value=[ 7.30666637e-01])
train_episode: 547
At the end, own_hp 0: opp_hp 335. you lose.
Episode 547: loss is 0.125, rewards is -33.23
Tensor(shape=[1], dtype=Float32, value=[ 7.32000053e-01])
train_episode: 548
At the end, own_hp 225: opp_hp 238. you lose.
Episode 548: loss is 0.223, rewards is -1.36
Tensor(shape=[1], dtype=Float32, value=[ 7.33333349e-01])
train_episode: 549
At the end, own_hp 0: opp_hp 345. you lose.
Episode 549: loss is 0.808, rewards is -32.64
Tensor(shape=[1], dtype=Float32, value=[ 7.34666705e-01])
train_episode: 550
can't receive signals within 60 seconds. let's terminate gym env.
Episode 550: loss is 0.007, rewards is -30.91
0
1
2
evaluate begin
At the end, own_hp 250: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 550 total rewards is -27.343
Tensor(shape=[1], dtype=Float32, value=[ 7.36000001e-01])
-----------------------------------------
train_episode: 551
At the end, own_hp 0: opp_hp 375. you lose.
Episode 551: loss is 0.048, rewards is -36.12
Tensor(shape=[1], dtype=Float32, value=[ 7.37333298e-01])
train_episode: 552
At the end, own_hp 0: opp_hp 260. you lose.
Episode 552: loss is 0.0, rewards is -24.6
Tensor(shape=[1], dtype=Float32, value=[ 7.38666713e-01])
train_episode: 553
At the end, own_hp 120: opp_hp 69. you win.
Episode 553: loss is 0.251, rewards is 4.79
Tensor(shape=[1], dtype=Float32, value=[ 7.40000010e-01])
train_episode: 554
At the end, own_hp 0: opp_hp 350. you lose.
Episode 554: loss is 0.404, rewards is -33.8
Tensor(shape=[1], dtype=Float32, value=[ 7.41333365e-01])
train_episode: 555
At the end, own_hp 0: opp_hp 395. you lose.
Episode 555: loss is 0.063, rewards is -39.16
Tensor(shape=[1], dtype=Float32, value=[ 7.42666662e-01])
train_episode: 556
can't receive signals within 60 seconds. let's terminate gym env.
Episode 556: loss is 0.181, rewards is -10.5
Tensor(shape=[1], dtype=Float32, value=[ 7.44000077e-01])
train_episode: 557
At the end, own_hp 0: opp_hp 380. you lose.
Episode 557: loss is 0.275, rewards is -37.04
Tensor(shape=[1], dtype=Float32, value=[ 7.45333374e-01])
train_episode: 558
At the end, own_hp 0: opp_hp 360. you lose.
Episode 558: loss is 0.323, rewards is -31.61
Tensor(shape=[1], dtype=Float32, value=[ 7.46666670e-01])
train_episode: 559
At the end, own_hp 0: opp_hp 345. you lose.
Episode 559: loss is 0.0, rewards is -30.21
Tensor(shape=[1], dtype=Float32, value=[ 7.48000026e-01])
train_episode: 560
At the end, own_hp 192: opp_hp 84. you win.
Episode 560: loss is 0.04, rewards is 10.93
0
1
2
evaluate begin
At the end, own_hp 215: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 560 total rewards is -6.073
Tensor(shape=[1], dtype=Float32, value=[ 7.49333322e-01])
-----------------------------------------
train_episode: 561
At the end, own_hp 0: opp_hp 375. you lose.
Episode 561: loss is 0.034, rewards is -36.84
Tensor(shape=[1], dtype=Float32, value=[ 7.50666738e-01])
train_episode: 562
At the end, own_hp 0: opp_hp 380. you lose.
Episode 562: loss is 0.001, rewards is -29.88
Tensor(shape=[1], dtype=Float32, value=[ 7.52000034e-01])
train_episode: 563
At the end, own_hp 0: opp_hp 273. you lose.
Episode 563: loss is 0.15, rewards is -27.25
Tensor(shape=[1], dtype=Float32, value=[ 7.53333330e-01])
train_episode: 564
At the end, own_hp 210: opp_hp 255. you lose.
Episode 564: loss is 0.125, rewards is -4.33
Tensor(shape=[1], dtype=Float32, value=[ 7.54666686e-01])
train_episode: 565
At the end, own_hp 100: opp_hp 118. you lose.
Episode 565: loss is 0.044, rewards is 1.78
Tensor(shape=[1], dtype=Float32, value=[ 7.55999982e-01])
train_episode: 566
can't receive signals within 60 seconds. let's terminate gym env.
Episode 566: loss is 0.0, rewards is 1.46
Tensor(shape=[1], dtype=Float32, value=[ 7.57333398e-01])
train_episode: 567
At the end, own_hp 0: opp_hp 310. you lose.
Episode 567: loss is 0.032, rewards is -28.88
Tensor(shape=[1], dtype=Float32, value=[ 7.58666694e-01])
train_episode: 568
At the end, own_hp 59: opp_hp 182. you lose.
Episode 568: loss is 0.074, rewards is -12.52
Tensor(shape=[1], dtype=Float32, value=[ 7.59999990e-01])
train_episode: 569
At the end, own_hp 251: opp_hp 285. you lose.
Episode 569: loss is 0.396, rewards is -4.5
Tensor(shape=[1], dtype=Float32, value=[ 7.61333346e-01])
train_episode: 570
At the end, own_hp 0: opp_hp 285. you lose.
Episode 570: loss is 0.007, rewards is -28.97
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 570 total rewards is -14.367
Tensor(shape=[1], dtype=Float32, value=[ 7.62666702e-01])
-----------------------------------------
train_episode: 571
can't receive signals within 60 seconds. let's terminate gym env.
Episode 571: loss is 0.232, rewards is -11.97
Tensor(shape=[1], dtype=Float32, value=[ 7.64000058e-01])
train_episode: 572
At the end, own_hp 77: opp_hp 175. you lose.
Episode 572: loss is 0.276, rewards is -9.55
Tensor(shape=[1], dtype=Float32, value=[ 7.65333354e-01])
train_episode: 573
At the end, own_hp 0: opp_hp 345. you lose.
Episode 573: loss is 0.492, rewards is -31.43
Tensor(shape=[1], dtype=Float32, value=[ 7.66666651e-01])
train_episode: 574
At the end, own_hp 260: opp_hp 222. you win.
Episode 574: loss is 0.0, rewards is 2.07
Tensor(shape=[1], dtype=Float32, value=[ 7.68000007e-01])
train_episode: 575
At the end, own_hp 0: opp_hp 362. you lose.
Episode 575: loss is 0.0, rewards is -30.83
Tensor(shape=[1], dtype=Float32, value=[ 7.69333363e-01])
train_episode: 576
At the end, own_hp 245: opp_hp 223. you win.
Episode 576: loss is 0.0, rewards is 2.48
Tensor(shape=[1], dtype=Float32, value=[ 7.70666718e-01])
train_episode: 577
can't receive signals within 60 seconds. let's terminate gym env.
Episode 577: loss is 0.053, rewards is -5.73
Tensor(shape=[1], dtype=Float32, value=[ 7.72000015e-01])
train_episode: 578
At the end, own_hp 133: opp_hp 155. you lose.
Episode 578: loss is 0.462, rewards is -2.86
Tensor(shape=[1], dtype=Float32, value=[ 7.73333311e-01])
train_episode: 579
can't receive signals within 60 seconds. let's terminate gym env.
Episode 579: loss is 0.0, rewards is 0.2
Tensor(shape=[1], dtype=Float32, value=[ 7.74666667e-01])
train_episode: 580
can't receive signals within 60 seconds. let's terminate gym env.
Episode 580: loss is 0.008, rewards is 0.06
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 226: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 580 total rewards is -17.387
Tensor(shape=[1], dtype=Float32, value=[ 7.76000023e-01])
-----------------------------------------
train_episode: 581
At the end, own_hp 0: opp_hp 175. you lose.
Episode 581: loss is 0.0, rewards is -15.34
Tensor(shape=[1], dtype=Float32, value=[ 7.77333379e-01])
train_episode: 582
At the end, own_hp 244: opp_hp 160. you win.
Episode 582: loss is 0.553, rewards is 8.97
Tensor(shape=[1], dtype=Float32, value=[ 7.78666675e-01])
train_episode: 583
At the end, own_hp 145: opp_hp 93. you win.
Episode 583: loss is 0.125, rewards is 5.79
Tensor(shape=[1], dtype=Float32, value=[ 7.79999971e-01])
train_episode: 584
At the end, own_hp 195: opp_hp 180. you win.
Episode 584: loss is 0.008, rewards is 0.9
Tensor(shape=[1], dtype=Float32, value=[ 7.81333387e-01])
train_episode: 585
At the end, own_hp 230: opp_hp 235. you lose.
Episode 585: loss is 0.0, rewards is -1.02
Tensor(shape=[1], dtype=Float32, value=[ 7.82666683e-01])
train_episode: 586
At the end, own_hp 0: opp_hp 340. you lose.
Episode 586: loss is 0.696, rewards is -32.92
Tensor(shape=[1], dtype=Float32, value=[ 7.84000039e-01])
train_episode: 587
At the end, own_hp 0: opp_hp 385. you lose.
Episode 587: loss is 0.0, rewards is -36.2
Tensor(shape=[1], dtype=Float32, value=[ 7.85333335e-01])
train_episode: 588
At the end, own_hp 0: opp_hp 375. you lose.
Episode 588: loss is 0.048, rewards is -33.17
Tensor(shape=[1], dtype=Float32, value=[ 7.86666632e-01])
train_episode: 589
At the end, own_hp 0: opp_hp 320. you lose.
Episode 589: loss is 0.104, rewards is -31.15
Tensor(shape=[1], dtype=Float32, value=[ 7.88000047e-01])
train_episode: 590
At the end, own_hp 128: opp_hp 212. you lose.
Episode 590: loss is 0.129, rewards is -9.43
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 590 total rewards is 0.133
Tensor(shape=[1], dtype=Float32, value=[ 7.89333344e-01])
-----------------------------------------
train_episode: 591
At the end, own_hp 0: opp_hp 375. you lose.
Episode 591: loss is 0.233, rewards is -30.42
Tensor(shape=[1], dtype=Float32, value=[ 7.90666699e-01])
train_episode: 592
At the end, own_hp 0: opp_hp 400. you lose.
Episode 592: loss is 0.149, rewards is -37.52
Tensor(shape=[1], dtype=Float32, value=[ 7.91999996e-01])
train_episode: 593
At the end, own_hp 155: opp_hp 230. you lose.
Episode 593: loss is 0.007, rewards is -7.27
Tensor(shape=[1], dtype=Float32, value=[ 7.93333411e-01])
train_episode: 594
At the end, own_hp 0: opp_hp 385. you lose.
Episode 594: loss is 0.097, rewards is -36.53
Tensor(shape=[1], dtype=Float32, value=[ 7.94666708e-01])
train_episode: 595
At the end, own_hp 200: opp_hp 197. you win.
Episode 595: loss is 0.045, rewards is -0.27
Tensor(shape=[1], dtype=Float32, value=[ 7.96000004e-01])
train_episode: 596
At the end, own_hp 218: opp_hp 270. you lose.
Episode 596: loss is 0.032, rewards is -5.97
Tensor(shape=[1], dtype=Float32, value=[ 7.97333360e-01])
train_episode: 597
At the end, own_hp 235: opp_hp 168. you win.
Episode 597: loss is 0.03, rewards is 7.07
Tensor(shape=[1], dtype=Float32, value=[ 7.98666656e-01])
train_episode: 598
At the end, own_hp 0: opp_hp 330. you lose.
Episode 598: loss is 0.008, rewards is -30.27
Tensor(shape=[1], dtype=Float32, value=[ 8.00000072e-01])
train_episode: 599
At the end, own_hp 0: opp_hp 380. you lose.
Episode 599: loss is 0.156, rewards is -29.83
Tensor(shape=[1], dtype=Float32, value=[ 8.01333368e-01])
train_episode: 600
At the end, own_hp 192: opp_hp 150. you win.
Episode 600: loss is 0.044, rewards is 2.44
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 600 total rewards is -0.703
Tensor(shape=[1], dtype=Float32, value=[ 8.02666664e-01])
-----------------------------------------
train_episode: 601
At the end, own_hp 0: opp_hp 348. you lose.
Episode 601: loss is 0.126, rewards is -33.7
Tensor(shape=[1], dtype=Float32, value=[ 8.04000020e-01])
train_episode: 602
At the end, own_hp 0: opp_hp 355. you lose.
Episode 602: loss is 0.0, rewards is -25.63
Tensor(shape=[1], dtype=Float32, value=[ 8.05333316e-01])
train_episode: 603
can't receive signals within 60 seconds. let's terminate gym env.
Episode 603: loss is 0.008, rewards is 0.08
Tensor(shape=[1], dtype=Float32, value=[ 8.06666732e-01])
train_episode: 604
can't receive signals within 60 seconds. let's terminate gym env.
Episode 604: loss is 0.151, rewards is 4.06
Tensor(shape=[1], dtype=Float32, value=[ 8.08000028e-01])
train_episode: 605
can't receive signals within 60 seconds. let's terminate gym env.
Episode 605: loss is 0.133, rewards is 0.15
Tensor(shape=[1], dtype=Float32, value=[ 8.09333324e-01])
train_episode: 606
At the end, own_hp 0: opp_hp 140. you lose.
Episode 606: loss is 0.076, rewards is -12.03
Tensor(shape=[1], dtype=Float32, value=[ 8.10666680e-01])
train_episode: 607
At the end, own_hp 0: opp_hp 315. you lose.
Episode 607: loss is 0.001, rewards is -31.01
Tensor(shape=[1], dtype=Float32, value=[ 8.12000036e-01])
train_episode: 608
At the end, own_hp 0: opp_hp 337. you lose.
Episode 608: loss is 0.027, rewards is -31.98
Tensor(shape=[1], dtype=Float32, value=[ 8.13333392e-01])
train_episode: 609
At the end, own_hp 232: opp_hp 155. you win.
Episode 609: loss is 0.0, rewards is 7.31
Tensor(shape=[1], dtype=Float32, value=[ 8.14666688e-01])
train_episode: 610
can't receive signals within 60 seconds. let's terminate gym env.
Episode 610: loss is 0.126, rewards is -0.13
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 610 total rewards is -0.827
Tensor(shape=[1], dtype=Float32, value=[ 8.15999985e-01])
-----------------------------------------
train_episode: 611
At the end, own_hp 240: opp_hp 230. you win.
Episode 611: loss is 0.08, rewards is 0.59
Tensor(shape=[1], dtype=Float32, value=[ 8.17333341e-01])
train_episode: 612
At the end, own_hp 108: opp_hp 162. you lose.
Episode 612: loss is 0.032, rewards is -4.77
Tensor(shape=[1], dtype=Float32, value=[ 8.18666697e-01])
train_episode: 613
At the end, own_hp 0: opp_hp 214. you lose.
Episode 613: loss is 0.21, rewards is -16.8
Tensor(shape=[1], dtype=Float32, value=[ 8.20000052e-01])
train_episode: 614
At the end, own_hp 0: opp_hp 310. you lose.
Episode 614: loss is 4.488, rewards is -19.85
Tensor(shape=[1], dtype=Float32, value=[ 8.21333349e-01])
train_episode: 615
At the end, own_hp 280: opp_hp 162. you win.
Episode 615: loss is 0.0, rewards is 11.41
Tensor(shape=[1], dtype=Float32, value=[ 8.22666645e-01])
train_episode: 616
At the end, own_hp 160: opp_hp 158. you win.
Episode 616: loss is 0.046, rewards is 0.85
Tensor(shape=[1], dtype=Float32, value=[ 8.24000001e-01])
train_episode: 617
At the end, own_hp 275: opp_hp 247. you win.
Episode 617: loss is 0.054, rewards is 3.73
Tensor(shape=[1], dtype=Float32, value=[ 8.25333357e-01])
train_episode: 618
can't receive signals within 60 seconds. let's terminate gym env.
Episode 618: loss is 0.033, rewards is -3.63
Tensor(shape=[1], dtype=Float32, value=[ 8.26666713e-01])
train_episode: 619
can't receive signals within 60 seconds. let's terminate gym env.
Episode 619: loss is 0.037, rewards is -28.8
Tensor(shape=[1], dtype=Float32, value=[ 8.28000009e-01])
train_episode: 620
can't receive signals within 60 seconds. let's terminate gym env.
Episode 620: loss is 0.0, rewards is -0.02
0
1
2
evaluate begin
At the end, own_hp 204: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 620 total rewards is -17.770
Tensor(shape=[1], dtype=Float32, value=[ 8.29333305e-01])
-----------------------------------------
train_episode: 621
At the end, own_hp 0: opp_hp 315. you lose.
Episode 621: loss is 0.0, rewards is -31.25
Tensor(shape=[1], dtype=Float32, value=[ 8.30666721e-01])
train_episode: 622
At the end, own_hp 0: opp_hp 270. you lose.
Episode 622: loss is 0.112, rewards is -24.27
Tensor(shape=[1], dtype=Float32, value=[ 8.32000017e-01])
train_episode: 623
At the end, own_hp 0: opp_hp 330. you lose.
Episode 623: loss is 0.045, rewards is -31.06
Tensor(shape=[1], dtype=Float32, value=[ 8.33333373e-01])
train_episode: 624
At the end, own_hp 245: opp_hp 260. you lose.
Episode 624: loss is 0.15, rewards is -2.49
Tensor(shape=[1], dtype=Float32, value=[ 8.34666669e-01])
train_episode: 625
At the end, own_hp 227: opp_hp 213. you win.
Episode 625: loss is 0.015, rewards is 1.22
Tensor(shape=[1], dtype=Float32, value=[ 8.35999966e-01])
train_episode: 626
can't receive signals within 60 seconds. let's terminate gym env.
Episode 626: loss is 0.0, rewards is -8.84
Tensor(shape=[1], dtype=Float32, value=[ 8.37333381e-01])
train_episode: 627
At the end, own_hp 252: opp_hp 235. you win.
Episode 627: loss is 0.031, rewards is 2.73
Tensor(shape=[1], dtype=Float32, value=[ 8.38666677e-01])
train_episode: 628
At the end, own_hp 0: opp_hp 365. you lose.
Episode 628: loss is 0.182, rewards is -35.93
Tensor(shape=[1], dtype=Float32, value=[ 8.40000033e-01])
train_episode: 629
At the end, own_hp 145: opp_hp 190. you lose.
Episode 629: loss is 0.046, rewards is -4.38
Tensor(shape=[1], dtype=Float32, value=[ 8.41333330e-01])
train_episode: 630
At the end, own_hp 246: opp_hp 243. you win.
Episode 630: loss is 0.204, rewards is -0.96
0
1
2
evaluate begin
At the end, own_hp 292: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 630 total rewards is -16.617
Tensor(shape=[1], dtype=Float32, value=[ 8.42666745e-01])
-----------------------------------------
train_episode: 631
can't receive signals within 60 seconds. let's terminate gym env.
Episode 631: loss is 0.0, rewards is 0.02
Tensor(shape=[1], dtype=Float32, value=[ 8.44000041e-01])
train_episode: 632
can't receive signals within 60 seconds. let's terminate gym env.
Episode 632: loss is 0.106, rewards is 0.01
Tensor(shape=[1], dtype=Float32, value=[ 8.45333338e-01])
train_episode: 633
At the end, own_hp 0: opp_hp 375. you lose.
Episode 633: loss is 0.009, rewards is -36.99
Tensor(shape=[1], dtype=Float32, value=[ 8.46666694e-01])
train_episode: 634
At the end, own_hp 225: opp_hp 210. you win.
Episode 634: loss is 0.093, rewards is 1.92
Tensor(shape=[1], dtype=Float32, value=[ 8.47999990e-01])
train_episode: 635
At the end, own_hp 0: opp_hp 350. you lose.
Episode 635: loss is 0.166, rewards is -35.64
Tensor(shape=[1], dtype=Float32, value=[ 8.49333405e-01])
train_episode: 636
At the end, own_hp 0: opp_hp 335. you lose.
Episode 636: loss is 0.116, rewards is -32.53
Tensor(shape=[1], dtype=Float32, value=[ 8.50666702e-01])
train_episode: 637
At the end, own_hp 202: opp_hp 145. you win.
Episode 637: loss is 0.045, rewards is 5.19
Tensor(shape=[1], dtype=Float32, value=[ 8.51999998e-01])
train_episode: 638
At the end, own_hp 100: opp_hp 150. you lose.
Episode 638: loss is 0.222, rewards is -5.61
Tensor(shape=[1], dtype=Float32, value=[ 8.53333354e-01])
train_episode: 639
At the end, own_hp 240: opp_hp 181. you win.
Episode 639: loss is 0.031, rewards is 5.15
Tensor(shape=[1], dtype=Float32, value=[ 8.54666650e-01])
train_episode: 640
At the end, own_hp 0: opp_hp 287. you lose.
Episode 640: loss is 0.009, rewards is -27.25
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 263: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 640 total rewards is -15.120
Tensor(shape=[1], dtype=Float32, value=[ 8.56000066e-01])
-----------------------------------------
train_episode: 641
can't receive signals within 60 seconds. let's terminate gym env.
Episode 641: loss is 0.071, rewards is 3.63
Tensor(shape=[1], dtype=Float32, value=[ 8.57333362e-01])
train_episode: 642
At the end, own_hp 0: opp_hp 340. you lose.
Episode 642: loss is 0.188, rewards is -31.7
Tensor(shape=[1], dtype=Float32, value=[ 8.58666658e-01])
train_episode: 643
can't receive signals within 60 seconds. let's terminate gym env.
Episode 643: loss is 0.052, rewards is 5.51
Tensor(shape=[1], dtype=Float32, value=[ 8.60000014e-01])
train_episode: 644
At the end, own_hp 0: opp_hp 395. you lose.
Episode 644: loss is 0.242, rewards is -36.96
Tensor(shape=[1], dtype=Float32, value=[ 8.61333370e-01])
train_episode: 645
At the end, own_hp 0: opp_hp 325. you lose.
Episode 645: loss is 0.074, rewards is -31.6
Tensor(shape=[1], dtype=Float32, value=[ 8.62666726e-01])
train_episode: 646
At the end, own_hp 0: opp_hp 395. you lose.
Episode 646: loss is 0.008, rewards is -34.36
Tensor(shape=[1], dtype=Float32, value=[ 8.64000022e-01])
train_episode: 647
At the end, own_hp 0: opp_hp 235. you lose.
Episode 647: loss is 0.054, rewards is -21.89
Tensor(shape=[1], dtype=Float32, value=[ 8.65333319e-01])
train_episode: 648
At the end, own_hp 160: opp_hp 136. you win.
Episode 648: loss is 0.033, rewards is 2.79
Tensor(shape=[1], dtype=Float32, value=[ 8.66666675e-01])
train_episode: 649
At the end, own_hp 145: opp_hp 273. you lose.
Episode 649: loss is 0.0, rewards is -12.77
Tensor(shape=[1], dtype=Float32, value=[ 8.68000031e-01])
train_episode: 650
At the end, own_hp 260: opp_hp 126. you win.
Episode 650: loss is 0.07, rewards is 13.1
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 650 total rewards is -12.213
Tensor(shape=[1], dtype=Float32, value=[ 8.69333386e-01])
-----------------------------------------
train_episode: 651
At the end, own_hp 168: opp_hp 35. you win.
Episode 651: loss is 0.017, rewards is 13.63
Tensor(shape=[1], dtype=Float32, value=[ 8.70666683e-01])
train_episode: 652
can't receive signals within 60 seconds. let's terminate gym env.
Episode 652: loss is 0.048, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 8.71999979e-01])
train_episode: 653
can't receive signals within 60 seconds. let's terminate gym env.
Episode 653: loss is 0.0, rewards is 0.19
Tensor(shape=[1], dtype=Float32, value=[ 8.73333335e-01])
train_episode: 654
can't receive signals within 60 seconds. let's terminate gym env.
Episode 654: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 8.74666691e-01])
train_episode: 655
At the end, own_hp 100: opp_hp 137. you lose.
Episode 655: loss is 0.0, rewards is -3.39
Tensor(shape=[1], dtype=Float32, value=[ 8.76000047e-01])
train_episode: 656
At the end, own_hp 155: opp_hp 163. you lose.
Episode 656: loss is 0.008, rewards is -1.14
Tensor(shape=[1], dtype=Float32, value=[ 8.77333343e-01])
train_episode: 657
At the end, own_hp 0: opp_hp 370. you lose.
Episode 657: loss is 0.543, rewards is -26.28
Tensor(shape=[1], dtype=Float32, value=[ 8.78666639e-01])
train_episode: 658
At the end, own_hp 0: opp_hp 395. you lose.
Episode 658: loss is 0.008, rewards is -28.01
Tensor(shape=[1], dtype=Float32, value=[ 8.80000055e-01])
train_episode: 659
At the end, own_hp 0: opp_hp 330. you lose.
Episode 659: loss is 0.0, rewards is -33.22
Tensor(shape=[1], dtype=Float32, value=[ 8.81333351e-01])
train_episode: 660
can't receive signals within 60 seconds. let's terminate gym env.
Episode 660: loss is 0.076, rewards is -3.23
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 660 total rewards is -23.887
Tensor(shape=[1], dtype=Float32, value=[ 8.82666707e-01])
-----------------------------------------
train_episode: 661
can't receive signals within 60 seconds. let's terminate gym env.
Episode 661: loss is 0.149, rewards is -1.19
Tensor(shape=[1], dtype=Float32, value=[ 8.84000003e-01])
train_episode: 662
At the end, own_hp 155: opp_hp 188. you lose.
Episode 662: loss is 0.035, rewards is -3.4
Tensor(shape=[1], dtype=Float32, value=[ 8.85333300e-01])
train_episode: 663
At the end, own_hp 229: opp_hp 200. you win.
Episode 663: loss is 0.0, rewards is -0.65
Tensor(shape=[1], dtype=Float32, value=[ 8.86666715e-01])
train_episode: 664
At the end, own_hp 220: opp_hp 205. you win.
Episode 664: loss is 0.008, rewards is 2.06
Tensor(shape=[1], dtype=Float32, value=[ 8.88000011e-01])
train_episode: 665
At the end, own_hp 260: opp_hp 178. you win.
Episode 665: loss is 0.165, rewards is 8.15
Tensor(shape=[1], dtype=Float32, value=[ 8.89333367e-01])
train_episode: 666
can't receive signals within 60 seconds. let's terminate gym env.
Episode 666: loss is 0.008, rewards is -11.76
Tensor(shape=[1], dtype=Float32, value=[ 8.90666664e-01])
train_episode: 667
can't receive signals within 60 seconds. let's terminate gym env.
Episode 667: loss is 0.329, rewards is 0.7
Tensor(shape=[1], dtype=Float32, value=[ 8.92000079e-01])
train_episode: 668
At the end, own_hp 173: opp_hp 213. you lose.
Episode 668: loss is 0.0, rewards is -5.65
Tensor(shape=[1], dtype=Float32, value=[ 8.93333375e-01])
train_episode: 669
can't receive signals within 60 seconds. let's terminate gym env.
Episode 669: loss is 0.032, rewards is -18.96
Tensor(shape=[1], dtype=Float32, value=[ 8.94666672e-01])
train_episode: 670
At the end, own_hp 150: opp_hp 222. you lose.
Episode 670: loss is 0.008, rewards is -4.81
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 64: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 670 total rewards is -21.917
Tensor(shape=[1], dtype=Float32, value=[ 8.96000028e-01])
-----------------------------------------
train_episode: 671
At the end, own_hp 235: opp_hp 190. you win.
Episode 671: loss is 0.039, rewards is 3.77
Tensor(shape=[1], dtype=Float32, value=[ 8.97333324e-01])
train_episode: 672
At the end, own_hp 0: opp_hp 395. you lose.
Episode 672: loss is 0.0, rewards is -38.31
Tensor(shape=[1], dtype=Float32, value=[ 8.98666739e-01])
train_episode: 673
At the end, own_hp 213: opp_hp 200. you win.
Episode 673: loss is 0.0, rewards is 1.33
Tensor(shape=[1], dtype=Float32, value=[ 9.00000036e-01])
train_episode: 674
can't receive signals within 60 seconds. let's terminate gym env.
Episode 674: loss is 0.008, rewards is -10.92
Tensor(shape=[1], dtype=Float32, value=[ 9.01333332e-01])
train_episode: 675
At the end, own_hp 0: opp_hp 213. you lose.
Episode 675: loss is 0.0, rewards is -19.89
Tensor(shape=[1], dtype=Float32, value=[ 9.02666688e-01])
train_episode: 676
At the end, own_hp 0: opp_hp 370. you lose.
Episode 676: loss is 0.008, rewards is -34.23
Tensor(shape=[1], dtype=Float32, value=[ 9.03999984e-01])
train_episode: 677
At the end, own_hp 0: opp_hp 370. you lose.
Episode 677: loss is 0.241, rewards is -30.15
Tensor(shape=[1], dtype=Float32, value=[ 9.05333400e-01])
train_episode: 678
At the end, own_hp 0: opp_hp 390. you lose.
Episode 678: loss is 0.198, rewards is -38.87
Tensor(shape=[1], dtype=Float32, value=[ 9.06666696e-01])
train_episode: 679
At the end, own_hp 185: opp_hp 187. you lose.
Episode 679: loss is 0.529, rewards is -0.9
Tensor(shape=[1], dtype=Float32, value=[ 9.07999992e-01])
train_episode: 680
At the end, own_hp 190: opp_hp 65. you win.
Episode 680: loss is 0.053, rewards is 11.63
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 680 total rewards is -17.703
Tensor(shape=[1], dtype=Float32, value=[ 9.09333348e-01])
-----------------------------------------
train_episode: 681
can't receive signals within 60 seconds. let's terminate gym env.
Episode 681: loss is 0.031, rewards is -4.86
Tensor(shape=[1], dtype=Float32, value=[ 9.10666704e-01])
train_episode: 682
At the end, own_hp 0: opp_hp 238. you lose.
Episode 682: loss is 0.046, rewards is -20.38
Tensor(shape=[1], dtype=Float32, value=[ 9.12000060e-01])
train_episode: 683
At the end, own_hp 0: opp_hp 350. you lose.
Episode 683: loss is 0.001, rewards is -33.56
Tensor(shape=[1], dtype=Float32, value=[ 9.13333356e-01])
train_episode: 684
At the end, own_hp 160: opp_hp 248. you lose.
Episode 684: loss is 0.0, rewards is -7.81
Tensor(shape=[1], dtype=Float32, value=[ 9.14666653e-01])
train_episode: 685
can't receive signals within 60 seconds. let's terminate gym env.
Episode 685: loss is 0.052, rewards is -8.21
Tensor(shape=[1], dtype=Float32, value=[ 9.16000009e-01])
train_episode: 686
At the end, own_hp 150: opp_hp 220. you lose.
Episode 686: loss is 0.016, rewards is -7.89
Tensor(shape=[1], dtype=Float32, value=[ 9.17333364e-01])
train_episode: 687
At the end, own_hp 0: opp_hp 325. you lose.
Episode 687: loss is 0.015, rewards is -31.18
Tensor(shape=[1], dtype=Float32, value=[ 9.18666720e-01])
train_episode: 688
can't receive signals within 60 seconds. let's terminate gym env.
Episode 688: loss is 0.047, rewards is -1.49
Tensor(shape=[1], dtype=Float32, value=[ 9.20000017e-01])
train_episode: 689
At the end, own_hp 240: opp_hp 201. you win.
Episode 689: loss is 0.051, rewards is 3.91
Tensor(shape=[1], dtype=Float32, value=[ 9.21333313e-01])
train_episode: 690
At the end, own_hp 0: opp_hp 277. you lose.
Episode 690: loss is 0.001, rewards is -16.85
0
1
2
evaluate begin
At the end, own_hp 290: opp_hp 400. you lose.
At the end, own_hp 248: opp_hp 400. you lose.
At the end, own_hp 254: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 690 total rewards is -11.323
Tensor(shape=[1], dtype=Float32, value=[ 9.22666669e-01])
-----------------------------------------
train_episode: 691
At the end, own_hp 62: opp_hp 108. you lose.
Episode 691: loss is 0.047, rewards is -7.22
Tensor(shape=[1], dtype=Float32, value=[ 9.24000025e-01])
train_episode: 692
At the end, own_hp 140: opp_hp 166. you lose.
Episode 692: loss is 0.176, rewards is -2.89
Tensor(shape=[1], dtype=Float32, value=[ 9.25333381e-01])
train_episode: 693
At the end, own_hp 160: opp_hp 120. you win.
Episode 693: loss is 0.008, rewards is 4.21
Tensor(shape=[1], dtype=Float32, value=[ 9.26666677e-01])
train_episode: 694
At the end, own_hp 0: opp_hp 325. you lose.
Episode 694: loss is 0.028, rewards is -30.43
Tensor(shape=[1], dtype=Float32, value=[ 9.27999973e-01])
train_episode: 695
At the end, own_hp 190: opp_hp 182. you win.
Episode 695: loss is 0.0, rewards is 1.96
Tensor(shape=[1], dtype=Float32, value=[ 9.29333389e-01])
train_episode: 696
At the end, own_hp 0: opp_hp 270. you lose.
Episode 696: loss is 0.009, rewards is -25.5
Tensor(shape=[1], dtype=Float32, value=[ 9.30666685e-01])
train_episode: 697
At the end, own_hp 0: opp_hp 378. you lose.
Episode 697: loss is 0.113, rewards is -36.5
Tensor(shape=[1], dtype=Float32, value=[ 9.32000041e-01])
train_episode: 698
At the end, own_hp 0: opp_hp 340. you lose.
Episode 698: loss is 0.064, rewards is -32.94
Tensor(shape=[1], dtype=Float32, value=[ 9.33333337e-01])
train_episode: 699
At the end, own_hp 164: opp_hp 148. you win.
Episode 699: loss is 0.0, rewards is 5.12
Tensor(shape=[1], dtype=Float32, value=[ 9.34666634e-01])
train_episode: 700
At the end, own_hp 260: opp_hp 264. you lose.
Episode 700: loss is 0.043, rewards is -0.96
0
1
2
evaluate begin
At the end, own_hp 251: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 700 total rewards is -11.037
Tensor(shape=[1], dtype=Float32, value=[ 9.36000049e-01])
-----------------------------------------
train_episode: 701
can't receive signals within 60 seconds. let's terminate gym env.
Episode 701: loss is 0.151, rewards is 0.48
Tensor(shape=[1], dtype=Float32, value=[ 9.37333345e-01])
train_episode: 702
At the end, own_hp 175: opp_hp 172. you win.
Episode 702: loss is 0.009, rewards is 1.83
Tensor(shape=[1], dtype=Float32, value=[ 9.38666701e-01])
train_episode: 703
At the end, own_hp 238: opp_hp 205. you win.
Episode 703: loss is 0.082, rewards is 3.08
Tensor(shape=[1], dtype=Float32, value=[ 9.39999998e-01])
train_episode: 704
can't receive signals within 60 seconds. let's terminate gym env.
Episode 704: loss is 0.031, rewards is -1.56
Tensor(shape=[1], dtype=Float32, value=[ 9.41333294e-01])
train_episode: 705
can't receive signals within 60 seconds. let's terminate gym env.
Episode 705: loss is 0.0, rewards is -1.15
Tensor(shape=[1], dtype=Float32, value=[ 9.42666709e-01])
train_episode: 706
can't receive signals within 60 seconds. let's terminate gym env.
Episode 706: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 9.44000006e-01])
train_episode: 707
At the end, own_hp 250: opp_hp 188. you win.
Episode 707: loss is 0.027, rewards is 6.08
Tensor(shape=[1], dtype=Float32, value=[ 9.45333362e-01])
train_episode: 708
At the end, own_hp 0: opp_hp 270. you lose.
Episode 708: loss is 0.039, rewards is -19.74
Tensor(shape=[1], dtype=Float32, value=[ 9.46666658e-01])
train_episode: 709
At the end, own_hp 0: opp_hp 380. you lose.
Episode 709: loss is 0.032, rewards is -30.33
Tensor(shape=[1], dtype=Float32, value=[ 9.48000073e-01])
train_episode: 710
At the end, own_hp 228: opp_hp 285. you lose.
Episode 710: loss is 0.07, rewards is -6.06
0
1
2
evaluate begin
At the end, own_hp 16: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 710 total rewards is -11.770
Tensor(shape=[1], dtype=Float32, value=[ 9.49333370e-01])
-----------------------------------------
train_episode: 711
At the end, own_hp 160: opp_hp 197. you lose.
Episode 711: loss is 4.534, rewards is -4.26
Tensor(shape=[1], dtype=Float32, value=[ 9.50666666e-01])
train_episode: 712
At the end, own_hp 195: opp_hp 163. you win.
Episode 712: loss is 0.031, rewards is 2.47
Tensor(shape=[1], dtype=Float32, value=[ 9.52000022e-01])
train_episode: 713
At the end, own_hp 160: opp_hp 180. you lose.
Episode 713: loss is 0.0, rewards is -1.27
Tensor(shape=[1], dtype=Float32, value=[ 9.53333318e-01])
train_episode: 714
can't receive signals within 60 seconds. let's terminate gym env.
Episode 714: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 9.54666734e-01])
train_episode: 715
At the end, own_hp 0: opp_hp 280. you lose.
Episode 715: loss is 0.0, rewards is -28.03
Tensor(shape=[1], dtype=Float32, value=[ 9.56000030e-01])
train_episode: 716
At the end, own_hp 220: opp_hp 145. you win.
Episode 716: loss is 0.008, rewards is 6.84
Tensor(shape=[1], dtype=Float32, value=[ 9.57333326e-01])
train_episode: 717
At the end, own_hp 195: opp_hp 218. you lose.
Episode 717: loss is 0.0, rewards is -2.63
Tensor(shape=[1], dtype=Float32, value=[ 9.58666682e-01])
train_episode: 718
At the end, own_hp 195: opp_hp 235. you lose.
Episode 718: loss is 0.064, rewards is -4.65
Tensor(shape=[1], dtype=Float32, value=[ 9.60000038e-01])
train_episode: 719
At the end, own_hp 98: opp_hp 220. you lose.
Episode 719: loss is 0.03, rewards is -12.34
Tensor(shape=[1], dtype=Float32, value=[ 9.61333394e-01])
train_episode: 720
At the end, own_hp 0: opp_hp 375. you lose.
Episode 720: loss is 0.046, rewards is -36.04
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 720 total rewards is -23.890
Tensor(shape=[1], dtype=Float32, value=[ 9.62666690e-01])
-----------------------------------------
train_episode: 721
At the end, own_hp 0: opp_hp 360. you lose.
Episode 721: loss is 0.212, rewards is -35.39
Tensor(shape=[1], dtype=Float32, value=[ 9.63999987e-01])
train_episode: 722
At the end, own_hp 0: opp_hp 315. you lose.
Episode 722: loss is 0.047, rewards is -30.45
Tensor(shape=[1], dtype=Float32, value=[ 9.65333343e-01])
train_episode: 723
At the end, own_hp 0: opp_hp 385. you lose.
Episode 723: loss is 0.044, rewards is -37.55
Tensor(shape=[1], dtype=Float32, value=[ 9.66666698e-01])
train_episode: 724
At the end, own_hp 0: opp_hp 375. you lose.
Episode 724: loss is 0.017, rewards is -36.96
Tensor(shape=[1], dtype=Float32, value=[ 9.68000054e-01])
train_episode: 725
can't receive signals within 60 seconds. let's terminate gym env.
Episode 725: loss is 0.0, rewards is -22.34
Tensor(shape=[1], dtype=Float32, value=[ 9.69333351e-01])
train_episode: 726
can't receive signals within 60 seconds. let's terminate gym env.
Episode 726: loss is 0.008, rewards is 0.11
Tensor(shape=[1], dtype=Float32, value=[ 9.70666647e-01])
train_episode: 727
can't receive signals within 60 seconds. let's terminate gym env.
Episode 727: loss is 0.04, rewards is 0.32
Tensor(shape=[1], dtype=Float32, value=[ 9.72000003e-01])
train_episode: 728
At the end, own_hp 167: opp_hp 225. you lose.
Episode 728: loss is 0.164, rewards is -6.28
Tensor(shape=[1], dtype=Float32, value=[ 9.73333359e-01])
train_episode: 729
can't receive signals within 60 seconds. let's terminate gym env.
Episode 729: loss is 0.196, rewards is -2.81
Tensor(shape=[1], dtype=Float32, value=[ 9.74666715e-01])
train_episode: 730
At the end, own_hp 0: opp_hp 368. you lose.
Episode 730: loss is 0.064, rewards is -36.37
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 730 total rewards is -10.873
Tensor(shape=[1], dtype=Float32, value=[ 9.76000011e-01])
-----------------------------------------
train_episode: 731
At the end, own_hp 145: opp_hp 165. you lose.
Episode 731: loss is 0.0, rewards is -2.57
Tensor(shape=[1], dtype=Float32, value=[ 9.77333307e-01])
train_episode: 732
At the end, own_hp 219: opp_hp 203. you win.
Episode 732: loss is 0.246, rewards is 1.15
Tensor(shape=[1], dtype=Float32, value=[ 9.78666723e-01])
train_episode: 733
At the end, own_hp 0: opp_hp 308. you lose.
Episode 733: loss is 0.028, rewards is -30.14
Tensor(shape=[1], dtype=Float32, value=[ 9.80000019e-01])
train_episode: 734
At the end, own_hp 190: opp_hp 123. you win.
Episode 734: loss is 0.178, rewards is 3.92
Tensor(shape=[1], dtype=Float32, value=[ 9.81333375e-01])
train_episode: 735
At the end, own_hp 198: opp_hp 236. you lose.
Episode 735: loss is 0.032, rewards is -3.76
Tensor(shape=[1], dtype=Float32, value=[ 9.82666671e-01])
train_episode: 736
At the end, own_hp 0: opp_hp 325. you lose.
Episode 736: loss is 0.01, rewards is -20.28
Tensor(shape=[1], dtype=Float32, value=[ 9.83999968e-01])
train_episode: 737
At the end, own_hp 265: opp_hp 270. you lose.
Episode 737: loss is 0.0, rewards is -0.41
Tensor(shape=[1], dtype=Float32, value=[ 9.85333383e-01])
train_episode: 738
At the end, own_hp 0: opp_hp 290. you lose.
Episode 738: loss is 0.0, rewards is -19.89
Tensor(shape=[1], dtype=Float32, value=[ 9.86666679e-01])
train_episode: 739
can't receive signals within 60 seconds. let's terminate gym env.
Episode 739: loss is 0.008, rewards is -4.82
Tensor(shape=[1], dtype=Float32, value=[ 9.88000035e-01])
train_episode: 740
At the end, own_hp 181: opp_hp 221. you lose.
Episode 740: loss is 0.007, rewards is -4.92
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 275: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 740 total rewards is -19.230
Tensor(shape=[1], dtype=Float32, value=[ 9.89333332e-01])
-----------------------------------------
train_episode: 741
At the end, own_hp 240: opp_hp 245. you lose.
Episode 741: loss is 0.008, rewards is -1.36
Tensor(shape=[1], dtype=Float32, value=[ 9.90666628e-01])
train_episode: 742
At the end, own_hp 192: opp_hp 163. you win.
Episode 742: loss is 0.351, rewards is 3.16
Tensor(shape=[1], dtype=Float32, value=[ 9.92000043e-01])
train_episode: 743
At the end, own_hp 0: opp_hp 303. you lose.
Episode 743: loss is 0.033, rewards is -25.39
Tensor(shape=[1], dtype=Float32, value=[ 9.93333340e-01])
train_episode: 744
can't receive signals within 60 seconds. let's terminate gym env.
Episode 744: loss is 0.001, rewards is 0.09
Tensor(shape=[1], dtype=Float32, value=[ 9.94666696e-01])
train_episode: 745
At the end, own_hp 170: opp_hp 95. you win.
Episode 745: loss is 0.008, rewards is 6.73
Tensor(shape=[1], dtype=Float32, value=[ 9.95999992e-01])
train_episode: 746
At the end, own_hp 116: opp_hp 225. you lose.
Episode 746: loss is 0.008, rewards is -10.29
Tensor(shape=[1], dtype=Float32, value=[ 9.97333407e-01])
train_episode: 747
At the end, own_hp 0: opp_hp 325. you lose.
Episode 747: loss is 0.003, rewards is -30.88
Tensor(shape=[1], dtype=Float32, value=[ 9.98666704e-01])
train_episode: 748
At the end, own_hp 163: opp_hp 245. you lose.
Episode 748: loss is 0.161, rewards is -9.3
Tensor(shape=[1], dtype=Float32, value=[ 1.00000000e+00])
train_episode: 749
At the end, own_hp 192: opp_hp 233. you lose.
Episode 749: loss is 0.124, rewards is -4.31
Tensor(shape=[1], dtype=Float32, value=[ 1.00133336e+00])
train_episode: 750
At the end, own_hp 222: opp_hp 191. you win.
Episode 750: loss is 0.008, rewards is 3.25
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 280: opp_hp 400. you lose.
At the end, own_hp 327: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 750 total rewards is -5.080
Tensor(shape=[1], dtype=Float32, value=[ 1.00266671e+00])
-----------------------------------------
train_episode: 751
At the end, own_hp 175: opp_hp 199. you lose.
Episode 751: loss is 0.071, rewards is -3.09
Tensor(shape=[1], dtype=Float32, value=[ 1.00400007e+00])
train_episode: 752
At the end, own_hp 200: opp_hp 217. you lose.
Episode 752: loss is 0.203, rewards is -1.77
Tensor(shape=[1], dtype=Float32, value=[ 1.00533342e+00])
train_episode: 753
At the end, own_hp 0: opp_hp 345. you lose.
Episode 753: loss is 0.008, rewards is -32.53
Tensor(shape=[1], dtype=Float32, value=[ 1.00666666e+00])
train_episode: 754
At the end, own_hp 255: opp_hp 262. you lose.
Episode 754: loss is 0.032, rewards is -0.86
Tensor(shape=[1], dtype=Float32, value=[ 1.00800002e+00])
train_episode: 755
At the end, own_hp 185: opp_hp 175. you win.
Episode 755: loss is 0.061, rewards is 1.43
Tensor(shape=[1], dtype=Float32, value=[ 1.00933337e+00])
train_episode: 756
At the end, own_hp 242: opp_hp 235. you win.
Episode 756: loss is 0.008, rewards is 0.41
Tensor(shape=[1], dtype=Float32, value=[ 1.01066673e+00])
train_episode: 757
At the end, own_hp 205: opp_hp 166. you win.
Episode 757: loss is 0.193, rewards is 5.91
Tensor(shape=[1], dtype=Float32, value=[ 1.01200008e+00])
train_episode: 758
At the end, own_hp 212: opp_hp 226. you lose.
Episode 758: loss is 0.039, rewards is -1.92
Tensor(shape=[1], dtype=Float32, value=[ 1.01333332e+00])
train_episode: 759
At the end, own_hp 0: opp_hp 320. you lose.
Episode 759: loss is 0.008, rewards is -31.26
Tensor(shape=[1], dtype=Float32, value=[ 1.01466668e+00])
train_episode: 760
At the end, own_hp 145: opp_hp 77. you win.
Episode 760: loss is 0.0, rewards is 7.79
0
1
2
evaluate begin
At the end, own_hp 8: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 760 total rewards is -11.887
Tensor(shape=[1], dtype=Float32, value=[ 1.01600003e+00])
-----------------------------------------
train_episode: 761
At the end, own_hp 220: opp_hp 237. you lose.
Episode 761: loss is 0.0, rewards is -1.43
Tensor(shape=[1], dtype=Float32, value=[ 1.01733339e+00])
train_episode: 762
At the end, own_hp 210: opp_hp 240. you lose.
Episode 762: loss is 0.061, rewards is -3.41
Tensor(shape=[1], dtype=Float32, value=[ 1.01866674e+00])
train_episode: 763
At the end, own_hp 290: opp_hp 240. you win.
Episode 763: loss is 0.131, rewards is 4.05
Tensor(shape=[1], dtype=Float32, value=[ 1.01999998e+00])
train_episode: 764
can't receive signals within 60 seconds. let's terminate gym env.
Episode 764: loss is 0.0, rewards is 0.45
Tensor(shape=[1], dtype=Float32, value=[ 1.02133334e+00])
train_episode: 765
can't receive signals within 60 seconds. let's terminate gym env.
Episode 765: loss is 0.645, rewards is -0.04
Tensor(shape=[1], dtype=Float32, value=[ 1.02266669e+00])
train_episode: 766
can't receive signals within 60 seconds. let's terminate gym env.
Episode 766: loss is 0.503, rewards is 0.04
Tensor(shape=[1], dtype=Float32, value=[ 1.02400005e+00])
train_episode: 767
can't receive signals within 60 seconds. let's terminate gym env.
Episode 767: loss is 0.032, rewards is -0.47
Tensor(shape=[1], dtype=Float32, value=[ 1.02533340e+00])
train_episode: 768
At the end, own_hp 0: opp_hp 330. you lose.
Episode 768: loss is 0.0, rewards is -32.54
Tensor(shape=[1], dtype=Float32, value=[ 1.02666664e+00])
train_episode: 769
At the end, own_hp 0: opp_hp 235. you lose.
Episode 769: loss is 0.0, rewards is -23.16
Tensor(shape=[1], dtype=Float32, value=[ 1.02800012e+00])
train_episode: 770
At the end, own_hp 0: opp_hp 255. you lose.
Episode 770: loss is 0.046, rewards is -18.94
0
1
2
evaluate begin
At the end, own_hp 285: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 330: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 770 total rewards is -17.140
Tensor(shape=[1], dtype=Float32, value=[ 1.02933335e+00])
-----------------------------------------
train_episode: 771
At the end, own_hp 0: opp_hp 285. you lose.
Episode 771: loss is 0.199, rewards is -26.13
Tensor(shape=[1], dtype=Float32, value=[ 1.03066671e+00])
train_episode: 772
can't receive signals within 60 seconds. let's terminate gym env.
Episode 772: loss is 0.007, rewards is 5.1
Tensor(shape=[1], dtype=Float32, value=[ 1.03200006e+00])
train_episode: 773
At the end, own_hp 180: opp_hp 147. you win.
Episode 773: loss is 0.0, rewards is 2.46
Tensor(shape=[1], dtype=Float32, value=[ 1.03333330e+00])
train_episode: 774
can't receive signals within 60 seconds. let's terminate gym env.
Episode 774: loss is 0.0, rewards is 7.83
Tensor(shape=[1], dtype=Float32, value=[ 1.03466678e+00])
train_episode: 775
can't receive signals within 60 seconds. let's terminate gym env.
Episode 775: loss is 0.124, rewards is -3.93
Tensor(shape=[1], dtype=Float32, value=[ 1.03600001e+00])
train_episode: 776
can't receive signals within 60 seconds. let's terminate gym env.
Episode 776: loss is 0.072, rewards is -8.31
Tensor(shape=[1], dtype=Float32, value=[ 1.03733337e+00])
train_episode: 777
can't receive signals within 60 seconds. let's terminate gym env.
Episode 777: loss is 0.061, rewards is 0.24
Tensor(shape=[1], dtype=Float32, value=[ 1.03866673e+00])
train_episode: 778
At the end, own_hp 0: opp_hp 345. you lose.
Episode 778: loss is 0.063, rewards is -33.78
Tensor(shape=[1], dtype=Float32, value=[ 1.03999996e+00])
train_episode: 779
At the end, own_hp 0: opp_hp 390. you lose.
Episode 779: loss is 0.009, rewards is -30.51
Tensor(shape=[1], dtype=Float32, value=[ 1.04133344e+00])
train_episode: 780
At the end, own_hp 110: opp_hp 170. you lose.
Episode 780: loss is 0.049, rewards is -4.29
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 246: opp_hp 400. you lose.
At the end, own_hp 267: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 780 total rewards is -19.730
Tensor(shape=[1], dtype=Float32, value=[ 1.04266667e+00])
-----------------------------------------
train_episode: 781
At the end, own_hp 200: opp_hp 220. you lose.
Episode 781: loss is 0.12, rewards is -2.6
Tensor(shape=[1], dtype=Float32, value=[ 1.04400003e+00])
train_episode: 782
can't receive signals within 60 seconds. let's terminate gym env.
Episode 782: loss is 0.133, rewards is 0.47
Tensor(shape=[1], dtype=Float32, value=[ 1.04533339e+00])
train_episode: 783
At the end, own_hp 120: opp_hp 160. you lose.
Episode 783: loss is 0.047, rewards is -2.04
Tensor(shape=[1], dtype=Float32, value=[ 1.04666674e+00])
train_episode: 784
can't receive signals within 60 seconds. let's terminate gym env.
Episode 784: loss is 0.0, rewards is 1.51
Tensor(shape=[1], dtype=Float32, value=[ 1.04800010e+00])
train_episode: 785
At the end, own_hp 95: opp_hp 63. you win.
Episode 785: loss is 0.156, rewards is 3.56
Tensor(shape=[1], dtype=Float32, value=[ 1.04933333e+00])
train_episode: 786
can't receive signals within 60 seconds. let's terminate gym env.
Episode 786: loss is 0.023, rewards is -21.17
Tensor(shape=[1], dtype=Float32, value=[ 1.05066669e+00])
train_episode: 787
At the end, own_hp 0: opp_hp 100. you lose.
Episode 787: loss is 0.03, rewards is -7.93
Tensor(shape=[1], dtype=Float32, value=[ 1.05200005e+00])
train_episode: 788
At the end, own_hp 0: opp_hp 372. you lose.
Episode 788: loss is 0.04, rewards is -34.93
Tensor(shape=[1], dtype=Float32, value=[ 1.05333340e+00])
train_episode: 789
At the end, own_hp 293: opp_hp 200. you win.
Episode 789: loss is 0.008, rewards is 7.96
Tensor(shape=[1], dtype=Float32, value=[ 1.05466676e+00])
train_episode: 790
At the end, own_hp 145: opp_hp 213. you lose.
Episode 790: loss is 0.001, rewards is -7.5
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 790 total rewards is -36.097
Tensor(shape=[1], dtype=Float32, value=[ 1.05599999e+00])
-----------------------------------------
train_episode: 791
At the end, own_hp 0: opp_hp 305. you lose.
Episode 791: loss is 0.504, rewards is -28.22
Tensor(shape=[1], dtype=Float32, value=[ 1.05733335e+00])
train_episode: 792
At the end, own_hp 0: opp_hp 355. you lose.
Episode 792: loss is 0.008, rewards is -35.45
Tensor(shape=[1], dtype=Float32, value=[ 1.05866671e+00])
train_episode: 793
At the end, own_hp 225: opp_hp 198. you win.
Episode 793: loss is 0.008, rewards is 2.09
Tensor(shape=[1], dtype=Float32, value=[ 1.06000006e+00])
train_episode: 794
At the end, own_hp 253: opp_hp 275. you lose.
Episode 794: loss is 0.103, rewards is -2.85
Tensor(shape=[1], dtype=Float32, value=[ 1.06133342e+00])
train_episode: 795
At the end, own_hp 0: opp_hp 363. you lose.
Episode 795: loss is 0.052, rewards is -35.85
Tensor(shape=[1], dtype=Float32, value=[ 1.06266665e+00])
train_episode: 796
At the end, own_hp 0: opp_hp 285. you lose.
Episode 796: loss is 0.122, rewards is -26.38
Tensor(shape=[1], dtype=Float32, value=[ 1.06400001e+00])
train_episode: 797
can't receive signals within 60 seconds. let's terminate gym env.
Episode 797: loss is 0.148, rewards is 2.59
Tensor(shape=[1], dtype=Float32, value=[ 1.06533337e+00])
train_episode: 798
At the end, own_hp 135: opp_hp 245. you lose.
Episode 798: loss is 0.0, rewards is -11.49
Tensor(shape=[1], dtype=Float32, value=[ 1.06666672e+00])
train_episode: 799
At the end, own_hp 0: opp_hp 213. you lose.
Episode 799: loss is 0.071, rewards is -19.29
Tensor(shape=[1], dtype=Float32, value=[ 1.06800008e+00])
train_episode: 800
At the end, own_hp 156: opp_hp 75. you win.
Episode 800: loss is 0.501, rewards is 7.79
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 800 total rewards is -4.390
Tensor(shape=[1], dtype=Float32, value=[ 1.06933331e+00])
-----------------------------------------
train_episode: 801
can't receive signals within 60 seconds. let's terminate gym env.
Episode 801: loss is 0.199, rewards is 0.29
Tensor(shape=[1], dtype=Float32, value=[ 1.07066667e+00])
train_episode: 802
At the end, own_hp 0: opp_hp 335. you lose.
Episode 802: loss is 0.031, rewards is -32.05
Tensor(shape=[1], dtype=Float32, value=[ 1.07200003e+00])
train_episode: 803
can't receive signals within 60 seconds. let's terminate gym env.
Episode 803: loss is 0.162, rewards is -2.01
Tensor(shape=[1], dtype=Float32, value=[ 1.07333338e+00])
train_episode: 804
can't receive signals within 60 seconds. let's terminate gym env.
Episode 804: loss is 0.09, rewards is -4.62
Tensor(shape=[1], dtype=Float32, value=[ 1.07466674e+00])
train_episode: 805
At the end, own_hp 0: opp_hp 345. you lose.
Episode 805: loss is 0.212, rewards is -33.76
Tensor(shape=[1], dtype=Float32, value=[ 1.07599998e+00])
train_episode: 806
At the end, own_hp 0: opp_hp 335. you lose.
Episode 806: loss is 0.009, rewards is -28.25
Tensor(shape=[1], dtype=Float32, value=[ 1.07733345e+00])
train_episode: 807
At the end, own_hp 0: opp_hp 355. you lose.
Episode 807: loss is 0.257, rewards is -33.92
Tensor(shape=[1], dtype=Float32, value=[ 1.07866669e+00])
train_episode: 808
can't receive signals within 60 seconds. let's terminate gym env.
Episode 808: loss is 0.077, rewards is 0.09
Tensor(shape=[1], dtype=Float32, value=[ 1.08000004e+00])
train_episode: 809
At the end, own_hp 155: opp_hp 213. you lose.
Episode 809: loss is 0.0, rewards is -4.2
Tensor(shape=[1], dtype=Float32, value=[ 1.08133340e+00])
train_episode: 810
can't receive signals within 60 seconds. let's terminate gym env.
Episode 810: loss is 0.043, rewards is 2.56
0
1
2
evaluate begin
At the end, own_hp 260: opp_hp 400. you lose.
At the end, own_hp 248: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 810 total rewards is -8.160
Tensor(shape=[1], dtype=Float32, value=[ 1.08266664e+00])
-----------------------------------------
train_episode: 811
At the end, own_hp 310: opp_hp 236. you win.
Episode 811: loss is 0.235, rewards is 7.58
Tensor(shape=[1], dtype=Float32, value=[ 1.08400011e+00])
train_episode: 812
At the end, own_hp 0: opp_hp 355. you lose.
Episode 812: loss is 0.001, rewards is -35.49
Tensor(shape=[1], dtype=Float32, value=[ 1.08533335e+00])
train_episode: 813
At the end, own_hp 0: opp_hp 325. you lose.
Episode 813: loss is 0.0, rewards is -30.34
Tensor(shape=[1], dtype=Float32, value=[ 1.08666670e+00])
train_episode: 814
At the end, own_hp 0: opp_hp 390. you lose.
Episode 814: loss is 0.008, rewards is -30.44
Tensor(shape=[1], dtype=Float32, value=[ 1.08800006e+00])
train_episode: 815
can't receive signals within 60 seconds. let's terminate gym env.
Episode 815: loss is 0.045, rewards is 0.36
Tensor(shape=[1], dtype=Float32, value=[ 1.08933330e+00])
train_episode: 816
At the end, own_hp 0: opp_hp 245. you lose.
Episode 816: loss is 0.019, rewards is -23.5
Tensor(shape=[1], dtype=Float32, value=[ 1.09066677e+00])
train_episode: 817
At the end, own_hp 145: opp_hp 113. you win.
Episode 817: loss is 0.197, rewards is 3.12
Tensor(shape=[1], dtype=Float32, value=[ 1.09200001e+00])
train_episode: 818
can't receive signals within 60 seconds. let's terminate gym env.
Episode 818: loss is 0.214, rewards is 6.77
Tensor(shape=[1], dtype=Float32, value=[ 1.09333336e+00])
train_episode: 819
At the end, own_hp 0: opp_hp 358. you lose.
Episode 819: loss is 0.001, rewards is -31.67
Tensor(shape=[1], dtype=Float32, value=[ 1.09466672e+00])
train_episode: 820
At the end, own_hp 0: opp_hp 360. you lose.
Episode 820: loss is 0.03, rewards is -32.55
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 307: opp_hp 400. you lose.
At the end, own_hp 245: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 820 total rewards is -7.033
Tensor(shape=[1], dtype=Float32, value=[ 1.09600008e+00])
-----------------------------------------
train_episode: 821
At the end, own_hp 238: opp_hp 87. you win.
Episode 821: loss is 0.0, rewards is 12.07
Tensor(shape=[1], dtype=Float32, value=[ 1.09733343e+00])
train_episode: 822
At the end, own_hp 250: opp_hp 196. you win.
Episode 822: loss is 0.0, rewards is 4.35
Tensor(shape=[1], dtype=Float32, value=[ 1.09866667e+00])
train_episode: 823
At the end, own_hp 0: opp_hp 316. you lose.
Episode 823: loss is 0.044, rewards is -29.85
Tensor(shape=[1], dtype=Float32, value=[ 1.10000002e+00])
train_episode: 824
At the end, own_hp 0: opp_hp 318. you lose.
Episode 824: loss is 0.093, rewards is -31.47
Tensor(shape=[1], dtype=Float32, value=[ 1.10133338e+00])
train_episode: 825
can't receive signals within 60 seconds. let's terminate gym env.
Episode 825: loss is 0.123, rewards is 0.8
Tensor(shape=[1], dtype=Float32, value=[ 1.10266674e+00])
train_episode: 826
At the end, own_hp 0: opp_hp 372. you lose.
Episode 826: loss is 0.031, rewards is -35.53
Tensor(shape=[1], dtype=Float32, value=[ 1.10400009e+00])
train_episode: 827
At the end, own_hp 0: opp_hp 301. you lose.
Episode 827: loss is 0.0, rewards is -28.93
Tensor(shape=[1], dtype=Float32, value=[ 1.10533333e+00])
train_episode: 828
At the end, own_hp 0: opp_hp 378. you lose.
Episode 828: loss is 0.053, rewards is -36.58
Tensor(shape=[1], dtype=Float32, value=[ 1.10666668e+00])
train_episode: 829
At the end, own_hp 0: opp_hp 265. you lose.
Episode 829: loss is 0.124, rewards is -19.0
Tensor(shape=[1], dtype=Float32, value=[ 1.10800004e+00])
train_episode: 830
can't receive signals within 60 seconds. let's terminate gym env.
Episode 830: loss is 0.077, rewards is -0.57
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 255: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 830 total rewards is -27.490
Tensor(shape=[1], dtype=Float32, value=[ 1.10933340e+00])
-----------------------------------------
train_episode: 831
At the end, own_hp 115: opp_hp 138. you lose.
Episode 831: loss is 0.001, rewards is -1.83
Tensor(shape=[1], dtype=Float32, value=[ 1.11066675e+00])
train_episode: 832
At the end, own_hp 0: opp_hp 322. you lose.
Episode 832: loss is 0.088, rewards is -31.88
Tensor(shape=[1], dtype=Float32, value=[ 1.11199999e+00])
train_episode: 833
At the end, own_hp 0: opp_hp 320. you lose.
Episode 833: loss is 0.001, rewards is -30.47
Tensor(shape=[1], dtype=Float32, value=[ 1.11333334e+00])
train_episode: 834
At the end, own_hp 0: opp_hp 365. you lose.
Episode 834: loss is 0.248, rewards is -35.12
Tensor(shape=[1], dtype=Float32, value=[ 1.11466670e+00])
train_episode: 835
At the end, own_hp 0: opp_hp 338. you lose.
Episode 835: loss is 0.039, rewards is -33.35
Tensor(shape=[1], dtype=Float32, value=[ 1.11600006e+00])
train_episode: 836
At the end, own_hp 0: opp_hp 372. you lose.
Episode 836: loss is 0.0, rewards is -29.07
Tensor(shape=[1], dtype=Float32, value=[ 1.11733341e+00])
train_episode: 837
can't receive signals within 60 seconds. let's terminate gym env.
Episode 837: loss is 0.555, rewards is -0.45
Tensor(shape=[1], dtype=Float32, value=[ 1.11866665e+00])
train_episode: 838
At the end, own_hp 220: opp_hp 96. you win.
Episode 838: loss is 4.505, rewards is 12.53
Tensor(shape=[1], dtype=Float32, value=[ 1.12000000e+00])
train_episode: 839
At the end, own_hp 238: opp_hp 178. you win.
Episode 839: loss is 0.001, rewards is 6.5
Tensor(shape=[1], dtype=Float32, value=[ 1.12133336e+00])
train_episode: 840
At the end, own_hp 0: opp_hp 315. you lose.
Episode 840: loss is 0.007, rewards is -30.19
0
1
2
evaluate begin
At the end, own_hp 19: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 12: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 840 total rewards is -34.107
Tensor(shape=[1], dtype=Float32, value=[ 1.12266672e+00])
-----------------------------------------
train_episode: 841
At the end, own_hp 200: opp_hp 303. you lose.
Episode 841: loss is 0.008, rewards is -11.09
Tensor(shape=[1], dtype=Float32, value=[ 1.12400007e+00])
train_episode: 842
can't receive signals within 60 seconds. let's terminate gym env.
Episode 842: loss is 0.001, rewards is 1.01
Tensor(shape=[1], dtype=Float32, value=[ 1.12533331e+00])
train_episode: 843
At the end, own_hp 147: opp_hp 215. you lose.
Episode 843: loss is 0.033, rewards is -6.36
Tensor(shape=[1], dtype=Float32, value=[ 1.12666678e+00])
train_episode: 844
At the end, own_hp 0: opp_hp 313. you lose.
Episode 844: loss is 0.383, rewards is -28.13
Tensor(shape=[1], dtype=Float32, value=[ 1.12800002e+00])
train_episode: 845
At the end, own_hp 0: opp_hp 330. you lose.
Episode 845: loss is 0.001, rewards is -26.1
Tensor(shape=[1], dtype=Float32, value=[ 1.12933338e+00])
train_episode: 846
can't receive signals within 60 seconds. let's terminate gym env.
Episode 846: loss is 0.194, rewards is -5.36
Tensor(shape=[1], dtype=Float32, value=[ 1.13066673e+00])
train_episode: 847
At the end, own_hp 260: opp_hp 182. you win.
Episode 847: loss is 0.509, rewards is 7.51
Tensor(shape=[1], dtype=Float32, value=[ 1.13199997e+00])
train_episode: 848
At the end, own_hp 0: opp_hp 375. you lose.
Episode 848: loss is 0.075, rewards is -36.3
Tensor(shape=[1], dtype=Float32, value=[ 1.13333344e+00])
train_episode: 849
At the end, own_hp 0: opp_hp 350. you lose.
Episode 849: loss is 0.077, rewards is -31.98
Tensor(shape=[1], dtype=Float32, value=[ 1.13466668e+00])
train_episode: 850
At the end, own_hp 0: opp_hp 365. you lose.
Episode 850: loss is 0.001, rewards is -30.34
0
1
2
evaluate begin
At the end, own_hp 300: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 285: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 850 total rewards is -11.983
Tensor(shape=[1], dtype=Float32, value=[ 1.13600004e+00])
-----------------------------------------
train_episode: 851
At the end, own_hp 0: opp_hp 295. you lose.
Episode 851: loss is 0.043, rewards is -28.24
Tensor(shape=[1], dtype=Float32, value=[ 1.13733339e+00])
train_episode: 852
At the end, own_hp 0: opp_hp 375. you lose.
Episode 852: loss is 0.274, rewards is -35.86
Tensor(shape=[1], dtype=Float32, value=[ 1.13866663e+00])
train_episode: 853
At the end, own_hp 205: opp_hp 202. you win.
Episode 853: loss is 0.0, rewards is -0.27
Tensor(shape=[1], dtype=Float32, value=[ 1.14000010e+00])
train_episode: 854
At the end, own_hp 205: opp_hp 150. you win.
Episode 854: loss is 0.008, rewards is 5.07
Tensor(shape=[1], dtype=Float32, value=[ 1.14133334e+00])
train_episode: 855
At the end, own_hp 225: opp_hp 183. you win.
Episode 855: loss is 0.177, rewards is 4.75
Tensor(shape=[1], dtype=Float32, value=[ 1.14266670e+00])
train_episode: 856
can't receive signals within 60 seconds. let's terminate gym env.
Episode 856: loss is 0.626, rewards is -2.23
Tensor(shape=[1], dtype=Float32, value=[ 1.14400005e+00])
train_episode: 857
At the end, own_hp 0: opp_hp 324. you lose.
Episode 857: loss is 0.053, rewards is -31.41
Tensor(shape=[1], dtype=Float32, value=[ 1.14533341e+00])
train_episode: 858
At the end, own_hp 225: opp_hp 250. you lose.
Episode 858: loss is 0.211, rewards is -2.57
Tensor(shape=[1], dtype=Float32, value=[ 1.14666677e+00])
train_episode: 859
At the end, own_hp 0: opp_hp 390. you lose.
Episode 859: loss is 0.045, rewards is -38.72
Tensor(shape=[1], dtype=Float32, value=[ 1.14800000e+00])
train_episode: 860
At the end, own_hp 0: opp_hp 395. you lose.
Episode 860: loss is 0.043, rewards is -38.72
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 860 total rewards is -21.943
Tensor(shape=[1], dtype=Float32, value=[ 1.14933336e+00])
-----------------------------------------
train_episode: 861
can't receive signals within 60 seconds. let's terminate gym env.
Episode 861: loss is 0.087, rewards is -0.67
Tensor(shape=[1], dtype=Float32, value=[ 1.15066671e+00])
train_episode: 862
At the end, own_hp 165: opp_hp 220. you lose.
Episode 862: loss is 0.086, rewards is -4.27
Tensor(shape=[1], dtype=Float32, value=[ 1.15200007e+00])
train_episode: 863
can't receive signals within 60 seconds. let's terminate gym env.
Episode 863: loss is 0.132, rewards is 6.33
Tensor(shape=[1], dtype=Float32, value=[ 1.15333343e+00])
train_episode: 864
At the end, own_hp 0: opp_hp 400. you lose.
Episode 864: loss is 0.045, rewards is -38.14
Tensor(shape=[1], dtype=Float32, value=[ 1.15466666e+00])
train_episode: 865
can't receive signals within 60 seconds. let's terminate gym env.
Episode 865: loss is 0.001, rewards is 0.55
Tensor(shape=[1], dtype=Float32, value=[ 1.15600002e+00])
train_episode: 866
can't receive signals within 60 seconds. let's terminate gym env.
Episode 866: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 1.15733337e+00])
train_episode: 867
At the end, own_hp 0: opp_hp 185. you lose.
Episode 867: loss is 0.001, rewards is -10.17
Tensor(shape=[1], dtype=Float32, value=[ 1.15866673e+00])
train_episode: 868
can't receive signals within 60 seconds. let's terminate gym env.
Episode 868: loss is 0.0, rewards is -1.65
Tensor(shape=[1], dtype=Float32, value=[ 1.16000009e+00])
train_episode: 869
At the end, own_hp 157: opp_hp 41. you win.
Episode 869: loss is 4.478, rewards is 11.64
Tensor(shape=[1], dtype=Float32, value=[ 1.16133332e+00])
train_episode: 870
can't receive signals within 60 seconds. let's terminate gym env.
Episode 870: loss is 0.0, rewards is 17.64
0
1
2
evaluate begin
At the end, own_hp 185: opp_hp 400. you lose.
At the end, own_hp 255: opp_hp 400. you lose.
At the end, own_hp 272: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 870 total rewards is -13.417
Tensor(shape=[1], dtype=Float32, value=[ 1.16266668e+00])
-----------------------------------------
train_episode: 871
At the end, own_hp 0: opp_hp 380. you lose.
Episode 871: loss is 0.358, rewards is -36.73
Tensor(shape=[1], dtype=Float32, value=[ 1.16400003e+00])
train_episode: 872
can't receive signals within 60 seconds. let's terminate gym env.
Episode 872: loss is 0.046, rewards is -10.87
Tensor(shape=[1], dtype=Float32, value=[ 1.16533339e+00])
train_episode: 873
can't receive signals within 60 seconds. let's terminate gym env.
Episode 873: loss is 0.03, rewards is -0.16
Tensor(shape=[1], dtype=Float32, value=[ 1.16666675e+00])
train_episode: 874
At the end, own_hp 0: opp_hp 165. you lose.
Episode 874: loss is 0.085, rewards is -15.71
Tensor(shape=[1], dtype=Float32, value=[ 1.16799998e+00])
train_episode: 875
can't receive signals within 60 seconds. let's terminate gym env.
Episode 875: loss is 0.001, rewards is 3.2
Tensor(shape=[1], dtype=Float32, value=[ 1.16933334e+00])
train_episode: 876
At the end, own_hp 0: opp_hp 370. you lose.
Episode 876: loss is 0.044, rewards is -35.5
Tensor(shape=[1], dtype=Float32, value=[ 1.17066669e+00])
train_episode: 877
can't receive signals within 60 seconds. let's terminate gym env.
Episode 877: loss is 0.032, rewards is -1.09
Tensor(shape=[1], dtype=Float32, value=[ 1.17200005e+00])
train_episode: 878
At the end, own_hp 0: opp_hp 330. you lose.
Episode 878: loss is 0.045, rewards is -31.92
Tensor(shape=[1], dtype=Float32, value=[ 1.17333341e+00])
train_episode: 879
At the end, own_hp 0: opp_hp 195. you lose.
Episode 879: loss is 0.0, rewards is -12.62
Tensor(shape=[1], dtype=Float32, value=[ 1.17466664e+00])
train_episode: 880
can't receive signals within 60 seconds. let's terminate gym env.
Episode 880: loss is 0.038, rewards is -0.46
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 880 total rewards is -21.090
Tensor(shape=[1], dtype=Float32, value=[ 1.17600012e+00])
-----------------------------------------
train_episode: 881
At the end, own_hp 210: opp_hp 118. you win.
Episode 881: loss is 0.052, rewards is 10.92
Tensor(shape=[1], dtype=Float32, value=[ 1.17733335e+00])
train_episode: 882
At the end, own_hp 0: opp_hp 380. you lose.
Episode 882: loss is 0.0, rewards is -37.07
Tensor(shape=[1], dtype=Float32, value=[ 1.17866671e+00])
train_episode: 883
can't receive signals within 60 seconds. let's terminate gym env.
Episode 883: loss is 0.0, rewards is -9.65
Tensor(shape=[1], dtype=Float32, value=[ 1.18000007e+00])
train_episode: 884
At the end, own_hp 0: opp_hp 353. you lose.
Episode 884: loss is 0.0, rewards is -35.0
Tensor(shape=[1], dtype=Float32, value=[ 1.18133330e+00])
train_episode: 885
At the end, own_hp 188: opp_hp 167. you win.
Episode 885: loss is 0.099, rewards is 2.82
Tensor(shape=[1], dtype=Float32, value=[ 1.18266678e+00])
train_episode: 886
At the end, own_hp 205: opp_hp 168. you win.
Episode 886: loss is 0.0, rewards is 4.59
Tensor(shape=[1], dtype=Float32, value=[ 1.18400002e+00])
train_episode: 887
can't receive signals within 60 seconds. let's terminate gym env.
Episode 887: loss is 0.032, rewards is -18.14
Tensor(shape=[1], dtype=Float32, value=[ 1.18533337e+00])
train_episode: 888
At the end, own_hp 0: opp_hp 260. you lose.
Episode 888: loss is 0.27, rewards is -23.54
Tensor(shape=[1], dtype=Float32, value=[ 1.18666673e+00])
train_episode: 889
At the end, own_hp 0: opp_hp 343. you lose.
Episode 889: loss is 0.01, rewards is -33.21
Tensor(shape=[1], dtype=Float32, value=[ 1.18799996e+00])
train_episode: 890
At the end, own_hp 213: opp_hp 158. you win.
Episode 890: loss is 0.122, rewards is 5.02
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 279: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 890 total rewards is -13.723
Tensor(shape=[1], dtype=Float32, value=[ 1.18933344e+00])
-----------------------------------------
train_episode: 891
At the end, own_hp 157: opp_hp 170. you lose.
Episode 891: loss is 0.369, rewards is -5.46
Tensor(shape=[1], dtype=Float32, value=[ 1.19066668e+00])
train_episode: 892
At the end, own_hp 130: opp_hp 285. you lose.
Episode 892: loss is 0.307, rewards is -14.89
Tensor(shape=[1], dtype=Float32, value=[ 1.19200003e+00])
train_episode: 893
can't receive signals within 60 seconds. let's terminate gym env.
Episode 893: loss is 0.0, rewards is 8.7
Tensor(shape=[1], dtype=Float32, value=[ 1.19333339e+00])
train_episode: 894
At the end, own_hp 160: opp_hp 246. you lose.
Episode 894: loss is 0.032, rewards is -8.99
Tensor(shape=[1], dtype=Float32, value=[ 1.19466674e+00])
train_episode: 895
At the end, own_hp 0: opp_hp 345. you lose.
Episode 895: loss is 0.027, rewards is -28.02
Tensor(shape=[1], dtype=Float32, value=[ 1.19600010e+00])
train_episode: 896
At the end, own_hp 0: opp_hp 378. you lose.
Episode 896: loss is 0.508, rewards is -26.78
Tensor(shape=[1], dtype=Float32, value=[ 1.19733334e+00])
train_episode: 897
At the end, own_hp 0: opp_hp 340. you lose.
Episode 897: loss is 0.095, rewards is -23.58
Tensor(shape=[1], dtype=Float32, value=[ 1.19866669e+00])
train_episode: 898
can't receive signals within 60 seconds. let's terminate gym env.
Episode 898: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 1.20000005e+00])
train_episode: 899
can't receive signals within 60 seconds. let's terminate gym env.
Episode 899: loss is 4.519, rewards is 0.23
Tensor(shape=[1], dtype=Float32, value=[ 1.20133340e+00])
train_episode: 900
can't receive signals within 60 seconds. let's terminate gym env.
Episode 900: loss is 0.622, rewards is 0.13
0
1
2
evaluate begin
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 900 total rewards is -23.797
Tensor(shape=[1], dtype=Float32, value=[ 1.20266676e+00])
-----------------------------------------
train_episode: 901
At the end, own_hp 0: opp_hp 395. you lose.
Episode 901: loss is 0.0, rewards is -38.24
Tensor(shape=[1], dtype=Float32, value=[ 1.20400000e+00])
train_episode: 902
At the end, own_hp 0: opp_hp 295. you lose.
Episode 902: loss is 0.033, rewards is -28.47
Tensor(shape=[1], dtype=Float32, value=[ 1.20533335e+00])
train_episode: 903
can't receive signals within 60 seconds. let's terminate gym env.
Episode 903: loss is 0.063, rewards is -4.32
Tensor(shape=[1], dtype=Float32, value=[ 1.20666671e+00])
train_episode: 904
At the end, own_hp 0: opp_hp 290. you lose.
Episode 904: loss is 0.016, rewards is -24.93
Tensor(shape=[1], dtype=Float32, value=[ 1.20800006e+00])
train_episode: 905
At the end, own_hp 0: opp_hp 385. you lose.
Episode 905: loss is 0.001, rewards is -37.66
Tensor(shape=[1], dtype=Float32, value=[ 1.20933342e+00])
train_episode: 906
can't receive signals within 60 seconds. let's terminate gym env.
Episode 906: loss is 0.045, rewards is -5.13
Tensor(shape=[1], dtype=Float32, value=[ 1.21066666e+00])
train_episode: 907
can't receive signals within 60 seconds. let's terminate gym env.
Episode 907: loss is 0.009, rewards is -0.75
Tensor(shape=[1], dtype=Float32, value=[ 1.21200001e+00])
train_episode: 908
At the end, own_hp 0: opp_hp 323. you lose.
Episode 908: loss is 0.001, rewards is -30.54
Tensor(shape=[1], dtype=Float32, value=[ 1.21333337e+00])
train_episode: 909
At the end, own_hp 0: opp_hp 318. you lose.
Episode 909: loss is 0.069, rewards is -22.94
Tensor(shape=[1], dtype=Float32, value=[ 1.21466672e+00])
train_episode: 910
can't receive signals within 60 seconds. let's terminate gym env.
Episode 910: loss is 0.031, rewards is -1.03
0
1
2
evaluate begin
At the end, own_hp 247: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
At the end, own_hp 290: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 910 total rewards is -18.627
Tensor(shape=[1], dtype=Float32, value=[ 1.21600008e+00])
-----------------------------------------
train_episode: 911
can't receive signals within 60 seconds. let's terminate gym env.
Episode 911: loss is 0.159, rewards is 5.68
Tensor(shape=[1], dtype=Float32, value=[ 1.21733332e+00])
train_episode: 912
can't receive signals within 60 seconds. let's terminate gym env.
Episode 912: loss is 0.044, rewards is 0.07
Tensor(shape=[1], dtype=Float32, value=[ 1.21866667e+00])
train_episode: 913
At the end, own_hp 0: opp_hp 355. you lose.
Episode 913: loss is 0.02, rewards is -34.57
Tensor(shape=[1], dtype=Float32, value=[ 1.22000003e+00])
train_episode: 914
At the end, own_hp 105: opp_hp 90. you win.
Episode 914: loss is 0.307, rewards is 4.33
Tensor(shape=[1], dtype=Float32, value=[ 1.22133338e+00])
train_episode: 915
can't receive signals within 60 seconds. let's terminate gym env.
Episode 915: loss is 0.083, rewards is -0.05
Tensor(shape=[1], dtype=Float32, value=[ 1.22266674e+00])
train_episode: 916
can't receive signals within 60 seconds. let's terminate gym env.
Episode 916: loss is 0.034, rewards is 1.17
Tensor(shape=[1], dtype=Float32, value=[ 1.22399998e+00])
train_episode: 917
can't receive signals within 60 seconds. let's terminate gym env.
Episode 917: loss is 0.098, rewards is 0.01
Tensor(shape=[1], dtype=Float32, value=[ 1.22533345e+00])
train_episode: 918
can't receive signals within 60 seconds. let's terminate gym env.
Episode 918: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 1.22666669e+00])
train_episode: 919
At the end, own_hp 0: opp_hp 400. you lose.
Episode 919: loss is 0.157, rewards is -39.41
Tensor(shape=[1], dtype=Float32, value=[ 1.22800004e+00])
train_episode: 920
At the end, own_hp 0: opp_hp 288. you lose.
Episode 920: loss is 0.303, rewards is -25.41
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 920 total rewards is -20.220
Tensor(shape=[1], dtype=Float32, value=[ 1.22933340e+00])
-----------------------------------------
train_episode: 921
At the end, own_hp 110: opp_hp 98. you win.
Episode 921: loss is 0.153, rewards is 1.69
Tensor(shape=[1], dtype=Float32, value=[ 1.23066664e+00])
train_episode: 922
At the end, own_hp 0: opp_hp 325. you lose.
Episode 922: loss is 0.262, rewards is -31.73
Tensor(shape=[1], dtype=Float32, value=[ 1.23200011e+00])
train_episode: 923
At the end, own_hp 193: opp_hp 208. you lose.
Episode 923: loss is 0.008, rewards is -2.71
Tensor(shape=[1], dtype=Float32, value=[ 1.23333335e+00])
train_episode: 924
can't receive signals within 60 seconds. let's terminate gym env.
Episode 924: loss is 0.0, rewards is 4.46
Tensor(shape=[1], dtype=Float32, value=[ 1.23466671e+00])
train_episode: 925
At the end, own_hp 0: opp_hp 335. you lose.
Episode 925: loss is 0.035, rewards is -31.49
Tensor(shape=[1], dtype=Float32, value=[ 1.23600006e+00])
train_episode: 926
At the end, own_hp 0: opp_hp 318. you lose.
Episode 926: loss is 0.001, rewards is -30.36
Tensor(shape=[1], dtype=Float32, value=[ 1.23733330e+00])
train_episode: 927
can't receive signals within 60 seconds. let's terminate gym env.
Episode 927: loss is 0.009, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 1.23866677e+00])
train_episode: 928
At the end, own_hp 0: opp_hp 308. you lose.
Episode 928: loss is 0.077, rewards is -28.14
Tensor(shape=[1], dtype=Float32, value=[ 1.24000001e+00])
train_episode: 929
At the end, own_hp 0: opp_hp 368. you lose.
Episode 929: loss is 0.123, rewards is -35.97
Tensor(shape=[1], dtype=Float32, value=[ 1.24133337e+00])
train_episode: 930
At the end, own_hp 235: opp_hp 212. you win.
Episode 930: loss is 0.008, rewards is 0.56
0
1
2
evaluate begin
At the end, own_hp 229: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 930 total rewards is -16.690
Tensor(shape=[1], dtype=Float32, value=[ 1.24266672e+00])
-----------------------------------------
train_episode: 931
At the end, own_hp 197: opp_hp 205. you lose.
Episode 931: loss is 0.0, rewards is -1.39
Tensor(shape=[1], dtype=Float32, value=[ 1.24400008e+00])
train_episode: 932
At the end, own_hp 265: opp_hp 243. you win.
Episode 932: loss is 0.044, rewards is 1.53
Tensor(shape=[1], dtype=Float32, value=[ 1.24533343e+00])
train_episode: 933
can't receive signals within 60 seconds. let's terminate gym env.
Episode 933: loss is 0.008, rewards is 0.05
Tensor(shape=[1], dtype=Float32, value=[ 1.24666667e+00])
train_episode: 934
At the end, own_hp 191: opp_hp 242. you lose.
Episode 934: loss is 0.0, rewards is -6.61
Tensor(shape=[1], dtype=Float32, value=[ 1.24800003e+00])
train_episode: 935
At the end, own_hp 0: opp_hp 215. you lose.
Episode 935: loss is 4.625, rewards is -13.84
Tensor(shape=[1], dtype=Float32, value=[ 1.24933338e+00])
train_episode: 936
At the end, own_hp 0: opp_hp 375. you lose.
Episode 936: loss is 0.001, rewards is -36.67
Tensor(shape=[1], dtype=Float32, value=[ 1.25066674e+00])
train_episode: 937
At the end, own_hp 95: opp_hp 198. you lose.
Episode 937: loss is 0.008, rewards is -9.61
Tensor(shape=[1], dtype=Float32, value=[ 1.25200009e+00])
train_episode: 938
At the end, own_hp 0: opp_hp 342. you lose.
Episode 938: loss is 0.045, rewards is -25.56
Tensor(shape=[1], dtype=Float32, value=[ 1.25333333e+00])
train_episode: 939
At the end, own_hp 211: opp_hp 56. you win.
Episode 939: loss is 0.107, rewards is 15.53
Tensor(shape=[1], dtype=Float32, value=[ 1.25466669e+00])
train_episode: 940
At the end, own_hp 0: opp_hp 348. you lose.
Episode 940: loss is 0.001, rewards is -33.01
0
1
2
evaluate begin
At the end, own_hp 301: opp_hp 400. you lose.
At the end, own_hp 245: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 940 total rewards is -6.523
Tensor(shape=[1], dtype=Float32, value=[ 1.25600004e+00])
-----------------------------------------
train_episode: 941
can't receive signals within 60 seconds. let's terminate gym env.
Episode 941: loss is 0.053, rewards is 0.47
Tensor(shape=[1], dtype=Float32, value=[ 1.25733340e+00])
train_episode: 942
At the end, own_hp 245: opp_hp 223. you win.
Episode 942: loss is 0.044, rewards is 1.62
Tensor(shape=[1], dtype=Float32, value=[ 1.25866675e+00])
train_episode: 943
At the end, own_hp 0: opp_hp 378. you lose.
Episode 943: loss is 0.03, rewards is -36.28
Tensor(shape=[1], dtype=Float32, value=[ 1.25999999e+00])
train_episode: 944
At the end, own_hp 215: opp_hp 166. you win.
Episode 944: loss is 0.059, rewards is 3.81
Tensor(shape=[1], dtype=Float32, value=[ 1.26133335e+00])
train_episode: 945
can't receive signals within 60 seconds. let's terminate gym env.
Episode 945: loss is 0.122, rewards is 0.04
Tensor(shape=[1], dtype=Float32, value=[ 1.26266670e+00])
train_episode: 946
At the end, own_hp 0: opp_hp 315. you lose.
Episode 946: loss is 0.075, rewards is -28.85
Tensor(shape=[1], dtype=Float32, value=[ 1.26400006e+00])
train_episode: 947
At the end, own_hp 155: opp_hp 160. you lose.
Episode 947: loss is 0.017, rewards is 0.44
Tensor(shape=[1], dtype=Float32, value=[ 1.26533341e+00])
train_episode: 948
At the end, own_hp 0: opp_hp 332. you lose.
Episode 948: loss is 0.151, rewards is -31.89
Tensor(shape=[1], dtype=Float32, value=[ 1.26666665e+00])
train_episode: 949
At the end, own_hp 230: opp_hp 204. you win.
Episode 949: loss is 0.0, rewards is 2.09
Tensor(shape=[1], dtype=Float32, value=[ 1.26800001e+00])
train_episode: 950
At the end, own_hp 0: opp_hp 257. you lose.
Episode 950: loss is 0.045, rewards is -25.38
0
1
2
evaluate begin
At the end, own_hp 292: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 315: opp_hp 400. you lose.
-----------------------------------------
Evaluate for episode 950 total rewards is -16.040
Tensor(shape=[1], dtype=Float32, value=[ 1.26933336e+00])
-----------------------------------------
train_episode: 951
At the end, own_hp 220: opp_hp 133. you win.
Episode 951: loss is 0.0, rewards is 6.53
Tensor(shape=[1], dtype=Float32, value=[ 1.27066672e+00])
train_episode: 952
At the end, own_hp 0: opp_hp 390. you lose.
Episode 952: loss is 0.132, rewards is -37.61
Tensor(shape=[1], dtype=Float32, value=[ 1.27200007e+00])
train_episode: 953
At the end, own_hp 200: opp_hp 145. you win.
Episode 953: loss is 0.371, rewards is 5.78
Tensor(shape=[1], dtype=Float32, value=[ 1.27333331e+00])
train_episode: 954
At the end, own_hp 0: opp_hp 380. you lose.
Episode 954: loss is 0.001, rewards is -36.88
Tensor(shape=[1], dtype=Float32, value=[ 1.27466667e+00])
train_episode: 955
At the end, own_hp 220: opp_hp 205. you win.
Episode 955: loss is 0.031, rewards is 0.87
Tensor(shape=[1], dtype=Float32, value=[ 1.27600002e+00])
train_episode: 956
At the end, own_hp 191: opp_hp 208. you lose.
Episode 956: loss is 0.03, rewards is -2.31
Tensor(shape=[1], dtype=Float32, value=[ 1.27733338e+00])
train_episode: 957
At the end, own_hp 190: opp_hp 200. you lose.
Episode 957: loss is 0.0, rewards is -1.14
Tensor(shape=[1], dtype=Float32, value=[ 1.27866673e+00])
train_episode: 958
At the end, own_hp 185: opp_hp 213. you lose.
Episode 958: loss is 0.045, rewards is -2.9
Tensor(shape=[1], dtype=Float32, value=[ 1.27999997e+00])
train_episode: 959
At the end, own_hp 205: opp_hp 161. you win.
Episode 959: loss is 0.001, rewards is 4.1
Tensor(shape=[1], dtype=Float32, value=[ 1.28133345e+00])
train_episode: 960
At the end, own_hp 0: opp_hp 320. you lose.
Episode 960: loss is 0.008, rewards is -23.08
0
1
2
evaluate begin
At the end, own_hp 290: opp_hp 400. you lose.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 960 total rewards is -14.863
Tensor(shape=[1], dtype=Float32, value=[ 1.28266668e+00])
-----------------------------------------
train_episode: 961
At the end, own_hp 0: opp_hp 375. you lose.
Episode 961: loss is 0.071, rewards is -37.92
Tensor(shape=[1], dtype=Float32, value=[ 1.28400004e+00])
train_episode: 962
At the end, own_hp 0: opp_hp 390. you lose.
Episode 962: loss is 0.073, rewards is -36.11
Tensor(shape=[1], dtype=Float32, value=[ 1.28533340e+00])
train_episode: 963
At the end, own_hp 0: opp_hp 385. you lose.
Episode 963: loss is 0.0, rewards is -35.49
Tensor(shape=[1], dtype=Float32, value=[ 1.28666663e+00])
train_episode: 964
At the end, own_hp 0: opp_hp 307. you lose.
Episode 964: loss is 0.0, rewards is -29.96
Tensor(shape=[1], dtype=Float32, value=[ 1.28800011e+00])
train_episode: 965
At the end, own_hp 272: opp_hp 253. you win.
Episode 965: loss is 0.051, rewards is 2.35
Tensor(shape=[1], dtype=Float32, value=[ 1.28933334e+00])
train_episode: 966
can't receive signals within 60 seconds. let's terminate gym env.
Episode 966: loss is 0.125, rewards is 1.73
Tensor(shape=[1], dtype=Float32, value=[ 1.29066670e+00])
train_episode: 967
At the end, own_hp 0: opp_hp 375. you lose.
Episode 967: loss is 0.033, rewards is -27.5
Tensor(shape=[1], dtype=Float32, value=[ 1.29200006e+00])
train_episode: 968
At the end, own_hp 178: opp_hp 272. you lose.
Episode 968: loss is 0.03, rewards is -9.07
Tensor(shape=[1], dtype=Float32, value=[ 1.29333341e+00])
train_episode: 969
At the end, own_hp 0: opp_hp 375. you lose.
Episode 969: loss is 0.077, rewards is -36.58
Tensor(shape=[1], dtype=Float32, value=[ 1.29466677e+00])
train_episode: 970
At the end, own_hp 225: opp_hp 165. you win.
Episode 970: loss is 0.0, rewards is 7.51
0
1
2
evaluate begin
At the end, own_hp 28: opp_hp 400. you lose.
At the end, own_hp 312: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 970 total rewards is -17.593
Tensor(shape=[1], dtype=Float32, value=[ 1.29600000e+00])
-----------------------------------------
train_episode: 971
can't receive signals within 60 seconds. let's terminate gym env.
Episode 971: loss is 0.062, rewards is 0.26
Tensor(shape=[1], dtype=Float32, value=[ 1.29733336e+00])
train_episode: 972
can't receive signals within 60 seconds. let's terminate gym env.
Episode 972: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 1.29866672e+00])
train_episode: 973
can't receive signals within 60 seconds. let's terminate gym env.
Episode 973: loss is 0.008, rewards is -2.85
Tensor(shape=[1], dtype=Float32, value=[ 1.30000007e+00])
train_episode: 974
At the end, own_hp 133: opp_hp 165. you lose.
Episode 974: loss is 0.044, rewards is -3.13
Tensor(shape=[1], dtype=Float32, value=[ 1.30133343e+00])
train_episode: 975
At the end, own_hp 152: opp_hp 38. you win.
Episode 975: loss is 0.0, rewards is 10.42
Tensor(shape=[1], dtype=Float32, value=[ 1.30266666e+00])
train_episode: 976
At the end, own_hp 250: opp_hp 176. you win.
Episode 976: loss is 0.21, rewards is 7.78
Tensor(shape=[1], dtype=Float32, value=[ 1.30400002e+00])
train_episode: 977
can't receive signals within 60 seconds. let's terminate gym env.
Episode 977: loss is 0.157, rewards is 0.67
Tensor(shape=[1], dtype=Float32, value=[ 1.30533338e+00])
train_episode: 978
At the end, own_hp 195: opp_hp 221. you lose.
Episode 978: loss is 0.008, rewards is -2.96
Tensor(shape=[1], dtype=Float32, value=[ 1.30666673e+00])
train_episode: 979
can't receive signals within 60 seconds. let's terminate gym env.
Episode 979: loss is 0.008, rewards is 0.23
Tensor(shape=[1], dtype=Float32, value=[ 1.30800009e+00])
train_episode: 980
At the end, own_hp 0: opp_hp 315. you lose.
Episode 980: loss is 0.063, rewards is -29.64
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 980 total rewards is -3.893
Tensor(shape=[1], dtype=Float32, value=[ 1.30933332e+00])
-----------------------------------------
train_episode: 981
At the end, own_hp 0: opp_hp 355. you lose.
Episode 981: loss is 0.0, rewards is -33.52
Tensor(shape=[1], dtype=Float32, value=[ 1.31066668e+00])
train_episode: 982
can't receive signals within 60 seconds. let's terminate gym env.
Episode 982: loss is 0.227, rewards is 9.41
Tensor(shape=[1], dtype=Float32, value=[ 1.31200004e+00])
train_episode: 983
At the end, own_hp 232: opp_hp 136. you win.
Episode 983: loss is 0.076, rewards is 11.05
Tensor(shape=[1], dtype=Float32, value=[ 1.31333339e+00])
train_episode: 984
can't receive signals within 60 seconds. let's terminate gym env.
Episode 984: loss is 0.001, rewards is -16.69
Tensor(shape=[1], dtype=Float32, value=[ 1.31466675e+00])
train_episode: 985
At the end, own_hp 0: opp_hp 344. you lose.
Episode 985: loss is 0.071, rewards is -29.63
Tensor(shape=[1], dtype=Float32, value=[ 1.31599998e+00])
train_episode: 986
can't receive signals within 60 seconds. let's terminate gym env.
Episode 986: loss is 0.045, rewards is 0.19
Tensor(shape=[1], dtype=Float32, value=[ 1.31733334e+00])
train_episode: 987
can't receive signals within 60 seconds. let's terminate gym env.
Episode 987: loss is 0.03, rewards is 0.01
Tensor(shape=[1], dtype=Float32, value=[ 1.31866670e+00])
train_episode: 988
can't receive signals within 60 seconds. let's terminate gym env.
Episode 988: loss is 0.0, rewards is 0.0
Tensor(shape=[1], dtype=Float32, value=[ 1.32000005e+00])
train_episode: 989
At the end, own_hp 230: opp_hp 255. you lose.
Episode 989: loss is 0.636, rewards is -3.45
Tensor(shape=[1], dtype=Float32, value=[ 1.32133341e+00])
train_episode: 990
can't receive signals within 60 seconds. let's terminate gym env.
Episode 990: loss is 0.0, rewards is -0.88
0
1
2
evaluate begin
can't receive signals within 60 seconds. let's terminate gym env.
At the end, own_hp 0: opp_hp 400. you lose.
can't receive signals within 60 seconds. let's terminate gym env.
-----------------------------------------
Evaluate for episode 990 total rewards is -13.997
Tensor(shape=[1], dtype=Float32, value=[ 1.32266665e+00])
-----------------------------------------
train_episode: 991
can't receive signals within 60 seconds. let's terminate gym env.
Episode 991: loss is 0.038, rewards is -0.75
Tensor(shape=[1], dtype=Float32, value=[ 1.32400000e+00])
train_episode: 992
At the end, own_hp 0: opp_hp 395. you lose.
Episode 992: loss is 0.007, rewards is -38.75
Tensor(shape=[1], dtype=Float32, value=[ 1.32533336e+00])
train_episode: 993
At the end, own_hp 0: opp_hp 385. you lose.
Episode 993: loss is 0.151, rewards is -37.04
Tensor(shape=[1], dtype=Float32, value=[ 1.32666671e+00])
train_episode: 994
At the end, own_hp 0: opp_hp 300. you lose.
Episode 994: loss is 0.001, rewards is -28.54
Tensor(shape=[1], dtype=Float32, value=[ 1.32800007e+00])
train_episode: 995
At the end, own_hp 105: opp_hp 265. you lose.
Episode 995: loss is 0.009, rewards is -16.23
Tensor(shape=[1], dtype=Float32, value=[ 1.32933331e+00])
train_episode: 996
At the end, own_hp 0: opp_hp 370. you lose.
Episode 996: loss is 0.212, rewards is -36.44
Tensor(shape=[1], dtype=Float32, value=[ 1.33066678e+00])
train_episode: 997
At the end, own_hp 0: opp_hp 293. you lose.
Episode 997: loss is 0.046, rewards is -25.74
Tensor(shape=[1], dtype=Float32, value=[ 1.33200002e+00])
train_episode: 998
can't receive signals within 60 seconds. let's terminate gym env.
Episode 998: loss is 0.031, rewards is -25.87
Tensor(shape=[1], dtype=Float32, value=[ 1.33333337e+00])
train_episode: 999
At the end, own_hp 266: opp_hp 305. you lose.
Episode 999: loss is 0.031, rewards is -3.19
training end
